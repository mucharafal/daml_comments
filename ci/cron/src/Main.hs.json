[
  {
    "id" : "06b314eb-2a69-4f15-82c6-5aecca895132",
    "prId" : 7741,
    "comments" : [
      {
        "id" : "4a01fb5c-040c-4068-b8fa-1c68d5be3c55",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    req { HTTP.requestHeaders = (\"User-Agent\", \"DAML cron (team-daml-app-runtime@digitalasset.com)\")  : HTTP.requestHeaders req}\r\n```\r\nIf we call it `add_…` it seems more natural to not drop all existing headers.",
        "createdAt" : "2020-10-19T17:14:27Z",
        "updatedAt" : "2020-10-20T09:29:48Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "a26524b44704c561c8b513a6ba38a9810288b9ce",
    "line" : null,
    "diffHunk" : "@@ -79,12 +79,14 @@ robustly_download_nix_packages = do\n               _ | \"unexpected end-of-file\" `Data.List.isInfixOf` err -> h (n - 1)\n               _ -> die cmd exit out err\n \n+add_github_contact_header :: HTTP.Request -> HTTP.Request\n+add_github_contact_header req =\n+    req { HTTP.requestHeaders = [(\"User-Agent\", \"DAML cron (team-daml-app-runtime@digitalasset.com)\")] }"
  },
  {
    "id" : "9763d504-d3ff-40b6-acb4-deaaba3b5c66",
    "prId" : 7731,
    "comments" : [
      {
        "id" : "f77002b7-47e5-42cd-90b1-4779fc5a2cbf",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "You are basically reimplementing what `http-conduit` gives you. With that, you would end up with something like\r\n```\r\nrunResourceT $ HTTP.responseBody resp  $$ sinkFile (tmp </> …)`\r\n```\r\n\r\nI don’t particularly mind that so feel free to ignore that suggestion or to address it separately.",
        "createdAt" : "2020-10-19T11:17:03Z",
        "updatedAt" : "2020-10-19T16:41:05Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "c9364f8a-e1e8-4e96-a172-1c9a43cfc3b5",
        "parentId" : "f77002b7-47e5-42cd-90b1-4779fc5a2cbf",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I did come upon references to `conduit`, but it seemed to add a lot of concepts I do not know yet. I imagine it's not a lot of complexity once you know them, but this is also not very complex as it stands. I tend to be a bit reluctant to add dependencies for a single function. I'll take a closer look at conduit if it comes up again.",
        "createdAt" : "2020-10-19T16:36:12Z",
        "updatedAt" : "2020-10-19T16:41:05Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "18539687c40b5073ad751c690161bd6403d5927e",
    "line" : 28,
    "diffHunk" : "@@ -271,18 +272,25 @@ docs = do\n \n download_assets :: FilePath -> GitHubRelease -> IO ()\n download_assets tmp release = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n     tokens <- Control.Concurrent.QSem.newQSem 20\n     Control.Concurrent.Async.forConcurrently_ (map uri $ assets release) (\\url ->\n         Control.Exception.bracket_\n           (Control.Concurrent.QSem.waitQSem tokens)\n           (Control.Concurrent.QSem.signalQSem tokens)\n           (do\n-        shell_ $ unlines [\"bash -c '\",\n-            \"set -euo pipefail\",\n-            \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n-            \"cd \\\"\" <> tmp <> \"\\\"\",\n-            \"wget --quiet \\\"\" <> show url <> \"\\\"\",\n-            \"'\"]))\n+              req' <- HTTP.parseRequest (show url)\n+              let req = req' { HTTP.requestHeaders = [(\"User-Agent\", \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+              HTTP.withResponse req manager (\\resp -> do\n+                  let body = HTTP.responseBody resp"
  },
  {
    "id" : "5754654c-d02a-4fca-8489-128799b9a24c",
    "prId" : 7731,
    "comments" : [
      {
        "id" : "d00d0b7f-1822-4541-b02d-494dbfd59bce",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Maybe worth updating that email address but I guess it also doesn’t matter.",
        "createdAt" : "2020-10-19T11:17:21Z",
        "updatedAt" : "2020-10-19T16:41:05Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "5593bc3f-ad90-4c57-8fab-90203d2c9b58",
        "parentId" : "d00d0b7f-1822-4541-b02d-494dbfd59bce",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "What would you suggest instead? AFAIK this one still works and will still reach the relevant people.",
        "createdAt" : "2020-10-19T16:36:28Z",
        "updatedAt" : "2020-10-19T16:41:05Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "fe499fd3-f15b-4856-9e58-c6b1d90e8d09",
        "parentId" : "d00d0b7f-1822-4541-b02d-494dbfd59bce",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "afaik we are both not on this one `team-daml-app-runtime@digitalasset.com` should have everyone in the team.",
        "createdAt" : "2020-10-19T16:41:08Z",
        "updatedAt" : "2020-10-19T16:41:08Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "18539687c40b5073ad751c690161bd6403d5927e",
    "line" : 26,
    "diffHunk" : "@@ -271,18 +272,25 @@ docs = do\n \n download_assets :: FilePath -> GitHubRelease -> IO ()\n download_assets tmp release = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n     tokens <- Control.Concurrent.QSem.newQSem 20\n     Control.Concurrent.Async.forConcurrently_ (map uri $ assets release) (\\url ->\n         Control.Exception.bracket_\n           (Control.Concurrent.QSem.waitQSem tokens)\n           (Control.Concurrent.QSem.signalQSem tokens)\n           (do\n-        shell_ $ unlines [\"bash -c '\",\n-            \"set -euo pipefail\",\n-            \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n-            \"cd \\\"\" <> tmp <> \"\\\"\",\n-            \"wget --quiet \\\"\" <> show url <> \"\\\"\",\n-            \"'\"]))\n+              req' <- HTTP.parseRequest (show url)\n+              let req = req' { HTTP.requestHeaders = [(\"User-Agent\", \"DAML cron (team-daml-language@digitalasset.com)\")] }"
  },
  {
    "id" : "9a87801c-abcd-455f-b562-a89f94a626fc",
    "prId" : 7696,
    "comments" : [
      {
        "id" : "628916b4-1690-40ec-8ba7-e6c15d861005",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "`forConcurrently_` will spawn an unbounded number of threads. I guess we don’t care since the number of assets is small? If we do care, the easiest solution is usually just to throw a semaphore around the map function you pass to `forConcurrently_`.",
        "createdAt" : "2020-10-15T10:55:00Z",
        "updatedAt" : "2020-10-15T10:56:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "60839dfe-6d79-49bb-8ada-dbeb4bcdf8d3",
        "parentId" : "628916b4-1690-40ec-8ba7-e6c15d861005",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "The Bash code this replaces was also unbounded, so at least this is not getting worse. 🙂\r\n\r\nI'm not concerned; we're not going to have a very big number of files anyway. If you are concerned, I can add a semaphore with, say, 30 slots, so it won't change anything for the happy path (16 assets atm) but will shield against future issues. I'd prefer to do that in a future PR, though.",
        "createdAt" : "2020-10-15T11:56:07Z",
        "updatedAt" : "2020-10-15T11:56:07Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "5e49ccf685fe01d47ba85c7cc5215c6dc3607d86",
    "line" : 27,
    "diffHunk" : "@@ -269,21 +270,13 @@ docs = do\n \n download_assets :: FilePath -> GitHubRelease -> IO ()\n download_assets tmp release = do\n-    shell_ $ unlines [\"bash -c '\",\n-        \"set -euo pipefail\",\n-        \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n-        \"cd \\\"\" <> tmp <> \"\\\"\",\n-        \"PIDS=\\\"\\\"\",\n-        \"for ass in \" <> unwords (map (show . uri) $ assets release) <> \"; do\",\n-            \"{\",\n-                \"wget --quiet \\\"$ass\\\" &\",\n-            \"}\",\n-            \"PIDS=\\\"$PIDS $!\\\"\",\n-        \"done\",\n-        \"for pid in $PIDS; do\",\n-            \"wait $pid\",\n-        \"done\",\n-        \"'\"]\n+    Control.Concurrent.Async.forConcurrently_ (map uri $ assets release) (\\url -> do"
  },
  {
    "id" : "c7c5ee31-fe18-4bee-a32e-8d9c1d9d8abc",
    "prId" : 7696,
    "comments" : [
      {
        "id" : "284a02f7-16ec-417f-8a09-db9f98da6757",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Seems like we could just call `wget` directly and  `-o` to avoid the `cd` but I’ll leave that up to you.",
        "createdAt" : "2020-10-15T10:56:21Z",
        "updatedAt" : "2020-10-15T10:56:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "747d3194-4846-413c-adcc-747d3d5e2825",
        "parentId" : "284a02f7-16ec-417f-8a09-db9f98da6757",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "ì'm planning to remove wget in my next PR (perhaps next-next now, if the next one is the semaphore), so I don't see much point in trying to make the Bash code nicer. I would point though that we are not in the tmpdir in terms of Haskell process cwd as far as I can tell, so the `cd` there is not superfluous as it stands.",
        "createdAt" : "2020-10-15T11:57:35Z",
        "updatedAt" : "2020-10-15T11:57:35Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "5e49ccf685fe01d47ba85c7cc5215c6dc3607d86",
    "line" : 32,
    "diffHunk" : "@@ -269,21 +270,13 @@ docs = do\n \n download_assets :: FilePath -> GitHubRelease -> IO ()\n download_assets tmp release = do\n-    shell_ $ unlines [\"bash -c '\",\n-        \"set -euo pipefail\",\n-        \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n-        \"cd \\\"\" <> tmp <> \"\\\"\",\n-        \"PIDS=\\\"\\\"\",\n-        \"for ass in \" <> unwords (map (show . uri) $ assets release) <> \"; do\",\n-            \"{\",\n-                \"wget --quiet \\\"$ass\\\" &\",\n-            \"}\",\n-            \"PIDS=\\\"$PIDS $!\\\"\",\n-        \"done\",\n-        \"for pid in $PIDS; do\",\n-            \"wait $pid\",\n-        \"done\",\n-        \"'\"]\n+    Control.Concurrent.Async.forConcurrently_ (map uri $ assets release) (\\url -> do\n+        shell_ $ unlines [\"bash -c '\",\n+            \"set -euo pipefail\",\n+            \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n+            \"cd \\\"\" <> tmp <> \"\\\"\",\n+            \"wget --quiet \\\"\" <> show url <> \"\\\"\","
  },
  {
    "id" : "d9095b5b-b00b-416b-8b24-758934ca324d",
    "prId" : 7690,
    "comments" : [
      {
        "id" : "e1f4d54f-8e7e-4e9b-8db7-a0880aecac90",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Why did you replace `strOption` by `option auto`?",
        "createdAt" : "2020-10-15T07:17:44Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "d4d3f1fd-b774-4003-9d9f-aa09c111d598",
        "parentId" : "e1f4d54f-8e7e-4e9b-8db7-a0880aecac90",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "thinking about this, is this even equivalent? `auto` is based on `Read` but `Read` for `String` excepts a string literal including the quotes around it.",
        "createdAt" : "2020-10-15T07:25:59Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "cef3e0b2-6d5a-4bfa-a05d-a286649e6279",
        "parentId" : "e1f4d54f-8e7e-4e9b-8db7-a0880aecac90",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "You're right, it fails. There was no good reason to replace, either. At some point I hoped `option auto` would automatically handle the `Maybe`, but then I discovered `optional` and forgot to change back.",
        "createdAt" : "2020-10-15T09:44:03Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f67fe7b38bbe4aa91647520f20da0e3e6e55ed69",
    "line" : null,
    "diffHunk" : "@@ -373,9 +382,14 @@ parser = info \"This program is meant to be run by CI cron. You probably don't ha\n                      (Check <$> Opt.strOption (Opt.long \"bash-lib\"\n                                          <> Opt.metavar \"PATH\"\n                                          <> Opt.help \"Path to Bash library file.\")\n-                            <*> Opt.strOption (Opt.long \"gcp-creds\"\n+                            <*> (Opt.optional $\n+                                  Opt.option Opt.auto (Opt.long \"gcp-creds\""
  },
  {
    "id" : "1c6fc9eb-024c-49fa-99e7-5039b3c932aa",
    "prId" : 7690,
    "comments" : [
      {
        "id" : "130eef01-7061-44d7-9504-b78a4c0e9c17",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I guess cutting of within the pagination already is not worth the complexity since it’s fast enough?",
        "createdAt" : "2020-10-15T07:20:16Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "142498d6-59b2-4a47-9199-6bcb15df10ac",
        "parentId" : "130eef01-7061-44d7-9504-b78a4c0e9c17",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Exactly.",
        "createdAt" : "2020-10-15T09:44:50Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "f67fe7b38bbe4aa91647520f20da0e3e6e55ed69",
    "line" : 18,
    "diffHunk" : "@@ -341,26 +341,35 @@ push_to_gcp gcp_credentials bash_lib local_path remote_path = do\n         \"gcs \\\"$GCRED\\\" cp \\\"\" <> local_path <> \"\\\" \\\"\" <> remote_path <> \"\\\"\",\n         \"'\"]\n \n-check_releases :: String -> String -> IO ()\n-check_releases gcp_credentials bash_lib = do\n-    releases <- fetch_gh_paginated \"https://api.github.com/repos/digital-asset/daml/releases\"\n+check_releases :: Maybe String -> String -> Maybe Int -> IO ()\n+check_releases gcp_credentials bash_lib max_releases = do\n+    releases' <- fetch_gh_paginated \"https://api.github.com/repos/digital-asset/daml/releases\"\n+    let releases = case max_releases of"
  },
  {
    "id" : "f37acd14-147b-44d9-bca2-b030567508e8",
    "prId" : 7690,
    "comments" : [
      {
        "id" : "09fec40f-ce88-4ea9-8731-a48a4b9cf1f4",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            whenJust gcp_credentials $ \\gcred -> do\r\n```",
        "createdAt" : "2020-10-15T07:20:56Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "cf7f8456-93cc-41d2-bba7-fcc4db30e9f9",
        "parentId" : "09fec40f-ce88-4ea9-8731-a48a4b9cf1f4",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Thanks!",
        "createdAt" : "2020-10-15T10:09:33Z",
        "updatedAt" : "2020-10-15T10:12:57Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f67fe7b38bbe4aa91647520f20da0e3e6e55ed69",
    "line" : null,
    "diffHunk" : "@@ -341,26 +341,35 @@ push_to_gcp gcp_credentials bash_lib local_path remote_path = do\n         \"gcs \\\"$GCRED\\\" cp \\\"\" <> local_path <> \"\\\" \\\"\" <> remote_path <> \"\\\"\",\n         \"'\"]\n \n-check_releases :: String -> String -> IO ()\n-check_releases gcp_credentials bash_lib = do\n-    releases <- fetch_gh_paginated \"https://api.github.com/repos/digital-asset/daml/releases\"\n+check_releases :: Maybe String -> String -> Maybe Int -> IO ()\n+check_releases gcp_credentials bash_lib max_releases = do\n+    releases' <- fetch_gh_paginated \"https://api.github.com/repos/digital-asset/daml/releases\"\n+    let releases = case max_releases of\n+                     Nothing -> releases'\n+                     Just n -> take n releases'\n     Data.Foldable.for_ releases (\\release -> do\n         let v = show $ tag release\n         putStrLn $ \"Checking release \" <> v <> \" ...\"\n         IO.withTempDir $ \\temp_dir -> do\n             download_assets temp_dir release\n             verify_signatures bash_lib temp_dir v >>= putStrLn\n-            Directory.listDirectory temp_dir >>= Data.Foldable.traverse_ (\\f -> do\n-                let gcp_path = \"gs://daml-data/releases/\" <> v <> \"/github/\" <> f\n-                exists <- does_backup_exist gcp_credentials bash_lib gcp_path\n-                if exists then do\n-                    putStrLn $ gcp_path <> \" already exists.\"\n-                else do\n-                    putStr $ gcp_path <> \" does not exist; pushing...\"\n-                    push_to_gcp gcp_credentials bash_lib (temp_dir </> f) gcp_path\n-                    putStrLn \" done.\"))\n-\n-data CliArgs = Docs | Check { bash_lib :: String, gcp_credentials :: String }\n+            case gcp_credentials of\n+              Nothing -> return ()\n+              Just gcred -> do"
  },
  {
    "id" : "2a3f7744-46df-47c3-b405-f09644b13665",
    "prId" : 7616,
    "comments" : [
      {
        "id" : "01916584-0da9-4e94-ae98-4b796aa17f94",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Seems pretty close to the point where you can just kill the bash script and call `gcs` directly (assuming you are running this in dev-env which seems like a reasonable assumption and is one that we make for lots of other tools). Doesn’t have to be in this PR.",
        "createdAt" : "2020-10-09T06:56:25Z",
        "updatedAt" : "2020-10-09T07:33:16Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "52d97d3f-ed9c-4b77-a60d-19f9ccd37ae6",
        "parentId" : "01916584-0da9-4e94-ae98-4b796aa17f94",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "`gcs` is a [Bash function](https://github.com/digital-asset/daml/blob/master/ci/bash-lib.yml#L32-L51) so unless I'm missing something this is as close as I can get to calling it directly from Haskell.\r\n\r\nThis Bash function is needed by other Bash scripts so I don't think I could easily replace it with a Haskell version, and while I do believe its implementation is quite final at this point, I've been wrong about that before so not too keen on replicating the logic. I'll think about it a bit.",
        "createdAt" : "2020-10-09T10:00:14Z",
        "updatedAt" : "2020-10-09T10:00:14Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "aff2c5ce-43e1-4328-a047-48f658b4682e",
        "parentId" : "01916584-0da9-4e94-ae98-4b796aa17f94",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Oh I see, I missed the fact that this was a bash function. Make sense to keep it then.",
        "createdAt" : "2020-10-09T10:04:50Z",
        "updatedAt" : "2020-10-09T10:04:51Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "8991e6162889215df657db95e18f35a5a660ce3e",
    "line" : 8,
    "diffHunk" : "@@ -312,18 +312,49 @@ verify_signatures bash_lib tmp version_tag = do\n        \"done\",\n        \"'\"]\n \n-check_releases :: String -> IO ()\n-check_releases bash_lib = do\n+does_backup_exist :: String -> FilePath -> FilePath -> IO Bool\n+does_backup_exist gcp_credentials bash_lib path = do\n+    out <- shell $ unlines [\"bash -c '\","
  },
  {
    "id" : "d266a130-7b4d-4372-9a14-6325664c916b",
    "prId" : 7616,
    "comments" : [
      {
        "id" : "355d9d59-a7e6-4bb5-81e8-20088440028f",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Same here, the bash script doesn’t really do anyhing.",
        "createdAt" : "2020-10-09T06:56:37Z",
        "updatedAt" : "2020-10-09T07:33:16Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "8991e6162889215df657db95e18f35a5a660ce3e",
    "line" : 26,
    "diffHunk" : "@@ -312,18 +312,49 @@ verify_signatures bash_lib tmp version_tag = do\n        \"done\",\n        \"'\"]\n \n-check_releases :: String -> IO ()\n-check_releases bash_lib = do\n+does_backup_exist :: String -> FilePath -> FilePath -> IO Bool\n+does_backup_exist gcp_credentials bash_lib path = do\n+    out <- shell $ unlines [\"bash -c '\",\n+        \"set -euo pipefail\",\n+        \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n+        \"source \\\"\" <> bash_lib <> \"\\\"\",\n+        \"if gcs \\\"\" <> gcp_credentials <> \"\\\" ls \\\"\" <> path <> \"\\\"; then\",\n+            \"echo True\",\n+        \"else\",\n+            \"echo False\",\n+        \"fi\",\n+        \"'\"]\n+    return $ read out\n+\n+push_to_gcp :: String -> FilePath -> FilePath  -> FilePath -> IO ()\n+push_to_gcp gcp_credentials bash_lib local_path remote_path = do\n+    shell_ $ unlines [\"bash -c '\",\n+        \"set -euo pipefail\",\n+        \"eval \\\"$(dev-env/bin/dade assist)\\\"\",\n+        \"source \\\"\" <> bash_lib <> \"\\\"\",\n+        \"gcs \\\"\" <> gcp_credentials <> \"\\\" cp \\\"\" <> local_path <> \"\\\" \\\"\" <> remote_path <> \"\\\"\","
  },
  {
    "id" : "4420dfc4-8c1b-461d-adc3-daac5a0c83b9",
    "prId" : 7607,
    "comments" : [
      {
        "id" : "3ba2206c-71e2-4f4e-8324-cefd124c07e8",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "How much do we care about the output being quiet here? Seems useful to see why it failed when it fails.",
        "createdAt" : "2020-10-08T11:27:19Z",
        "updatedAt" : "2020-10-08T15:58:00Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "50bd57da-59d8-47a5-8365-7472c402a040",
        "parentId" : "3ba2206c-71e2-4f4e-8324-cefd124c07e8",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "In my (admittedly limited) testing GPG output is not all that useful and basically wouldn't tell us more than which file failed.",
        "createdAt" : "2020-10-08T11:29:52Z",
        "updatedAt" : "2020-10-08T15:58:00Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "16f0180e-aeea-404c-ad56-f35cf93f8fd6",
        "parentId" : "3ba2206c-71e2-4f4e-8324-cefd124c07e8",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Here's an example output:\r\n```\r\n$ gpg --homedir $TMP --verify hello.asc\r\ngpg: assuming signed data in 'hello'\r\ngpg: Signature made Thu Oct  8 13:33:39 2020 CEST\r\ngpg:                using RSA key 7694EDB3A8AD27451044EABBF00B70F12FAA72B4\r\ngpg: BAD signature from \"test signin (blabla) <a@b.c>\" [ultimate]\r\n```",
        "createdAt" : "2020-10-08T11:35:31Z",
        "updatedAt" : "2020-10-08T15:58:00Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "afeb146b-ede1-4493-9e3d-1088c114e817",
        "parentId" : "3ba2206c-71e2-4f4e-8324-cefd124c07e8",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I guess I was less thinking of a signature fail and more something like a broken file path, failure to read the file, … which we cannot easily reproduce locally. But patching the output when it fails to figure out why is probably also reasonable.",
        "createdAt" : "2020-10-08T11:37:38Z",
        "updatedAt" : "2020-10-08T15:58:00Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "a4a3648d-064e-4309-a203-15973638518e",
        "parentId" : "3ba2206c-71e2-4f4e-8324-cefd124c07e8",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Added a commit for that. Note that `shell` takes care of printing out all of stdout and stderr for the entire shell command on non-zero exit.",
        "createdAt" : "2020-10-08T12:24:11Z",
        "updatedAt" : "2020-10-08T15:58:00Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f4d4037cb9c0c8889d002694a6edea85093aa461",
    "line" : null,
    "diffHunk" : "@@ -299,7 +299,7 @@ verify_signatures bash_lib tmp version_tag = do\n             \"if ! test -f $f.asc; then\",\n                 \"echo $p: no signature file\",\n             \"else\",\n-                \"if gpg_verify $f.asc >$LOG 2>&1; then\",\n+                \"if gpg_verify $f.asc >/dev/null; then\","
  },
  {
    "id" : "0373ef5d-1c38-429b-82ee-3db8e7faf332",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "9fee0f95-151e-440e-957d-5bdc7540ecf1",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n              assets <- v JSON..: \"assets\"\r\n```\r\nunfortunately hlint still hates parentheses :disappointed: ",
        "createdAt" : "2020-10-06T18:16:09Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "0cf57b9e-08ad-4f01-b9b9-dc4120536e8a",
        "parentId" : "9fee0f95-151e-440e-957d-5bdc7540ecf1",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I'll fix that. 🙂",
        "createdAt" : "2020-10-07T07:59:19Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : null,
    "diffHunk" : "@@ -183,12 +184,20 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-data PreVersion = PreVersion { prerelease :: Bool, tag :: Version }\n-instance JSON.FromJSON PreVersion where\n-    parseJSON = JSON.withObject \"PreVersion\" $ \\v -> PreVersion\n-        <$> v JSON..: \"prerelease\"\n-        <*> let json_text = v JSON..: \"tag_name\"\n-            in (version . Text.tail <$> json_text)\n+data GitHubRelease = GitHubRelease { prerelease :: Bool, tag :: Version, assets :: [String] }\n+  deriving Show\n+instance JSON.FromJSON GitHubRelease where\n+    parseJSON = JSON.withObject \"GitHubRelease\" $ \\v -> GitHubRelease\n+        <$> (v JSON..: \"prerelease\")\n+        <*> (version . Text.tail <$> v JSON..: \"tag_name\")\n+        <*> (do\n+              assets <- (v JSON..: \"assets\")"
  },
  {
    "id" : "26839bc7-160d-4b9b-8fbb-edf80916363b",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "7a1e7437-5eba-4da2-a81f-2d134da0d252",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I would recommend to go directly for a `URI` here instead of a `String` to make it clear what you are storing.\r\nEDIT: Or the `Asset` type that I suggested below.",
        "createdAt" : "2020-10-06T18:17:50Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "772276da-9e9a-4437-b31b-75689f9a2b41",
        "parentId" : "7a1e7437-5eba-4da2-a81f-2d134da0d252",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I assume you mean [this one](https://hackage.haskell.org/package/network-uri-2.6.3.0/docs/Network-URI.html)?",
        "createdAt" : "2020-10-07T07:47:49Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "87ee667d-5a34-49f6-9bbf-ed86f649e734",
        "parentId" : "7a1e7437-5eba-4da2-a81f-2d134da0d252",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Yep, sorry should have qualified that.",
        "createdAt" : "2020-10-07T07:48:35Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : null,
    "diffHunk" : "@@ -183,12 +184,20 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-data PreVersion = PreVersion { prerelease :: Bool, tag :: Version }\n-instance JSON.FromJSON PreVersion where\n-    parseJSON = JSON.withObject \"PreVersion\" $ \\v -> PreVersion\n-        <$> v JSON..: \"prerelease\"\n-        <*> let json_text = v JSON..: \"tag_name\"\n-            in (version . Text.tail <$> json_text)\n+data GitHubRelease = GitHubRelease { prerelease :: Bool, tag :: Version, assets :: [String] }"
  },
  {
    "id" : "2f908618-71b5-4f46-926c-f05ea8c267e8",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "86caf969-13f9-44e3-adae-798bbe1edd58",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "If you define a data type (e.g. `newtype Asset = Asset URI`) and provide that with a `FromJSON` instance, this whole piece of code seems to collapse down to `assets <- v JSON..: \"assets\"` with the `FromJSON` instance for `[Asset]` doing all of the work for you.",
        "createdAt" : "2020-10-06T18:19:59Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "7787ad37-7aab-4ae4-94f9-f13cad23d2cc",
        "parentId" : "86caf969-13f9-44e3-adae-798bbe1edd58",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I'll try that.",
        "createdAt" : "2020-10-07T07:45:32Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : null,
    "diffHunk" : "@@ -183,12 +184,20 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-data PreVersion = PreVersion { prerelease :: Bool, tag :: Version }\n-instance JSON.FromJSON PreVersion where\n-    parseJSON = JSON.withObject \"PreVersion\" $ \\v -> PreVersion\n-        <$> v JSON..: \"prerelease\"\n-        <*> let json_text = v JSON..: \"tag_name\"\n-            in (version . Text.tail <$> json_text)\n+data GitHubRelease = GitHubRelease { prerelease :: Bool, tag :: Version, assets :: [String] }\n+  deriving Show\n+instance JSON.FromJSON GitHubRelease where\n+    parseJSON = JSON.withObject \"GitHubRelease\" $ \\v -> GitHubRelease\n+        <$> (v JSON..: \"prerelease\")\n+        <*> (version . Text.tail <$> v JSON..: \"tag_name\")\n+        <*> (do\n+              assets <- (v JSON..: \"assets\")\n+              JSON.withArray"
  },
  {
    "id" : "0c87f1df-2a56-4b2f-9bfb-ab3ae53b3b77",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "b5f1e617-0bb8-4057-b865-0af74a1179b5",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n                  \"for ass in \" <> unwords (assets release) <> \"; do\",\r\n```",
        "createdAt" : "2020-10-06T18:23:05Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "3efeaa36-d841-43fc-8a8d-83ddbfe9ac17",
        "parentId" : "b5f1e617-0bb8-4057-b865-0af74a1179b5",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Will do.",
        "createdAt" : "2020-10-07T07:45:03Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : null,
    "diffHunk" : "@@ -274,24 +287,18 @@ check_releases bash_lib = do\n \n               \"shopt -s extglob\", -- enable !() pattern: things that _don't_ match\n \n-              -- TODO: get all releases (GH paginates by 30)\n-              \"RELEASES=$(curl https://api.github.com/repos/digital-asset/daml/releases -s)\",\n-              \"for i in $(seq 1 $(echo \\\"$RELEASES\\\" | jq length)); do\",\n-                  \"VERSION=$(echo \\\"$RELEASES\\\" | jq -r \\\".[$i-1].tag_name\\\")\",\n-                  \"mkdir \\\"$VERSION\\\"\",\n-                  \"cd \\\"$VERSION\\\"\",\n                   \"PIDS=\\\"\\\"\",\n-                  \"for ass in $(seq 1 $(echo \\\"$RELEASES\\\" | jq \\\".[$i-1].assets | length\\\")); do\",\n+                  \"for ass in \" <> Data.List.intercalate \" \" (assets release) <> \"; do\","
  },
  {
    "id" : "c63b6a8a-ff60-4b9e-9094-42b72c0287d5",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "8700052e-0a7c-4ee8-a156-3ed4f2d56005",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "seems like this whole block maybe should be deindented now that it’s no longer in the loop.",
        "createdAt" : "2020-10-06T18:25:53Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "968e0df6-325b-4625-bc7b-5c8a69320266",
        "parentId" : "8700052e-0a7c-4ee8-a156-3ed4f2d56005",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Yes, but that made the diff really horrible to read.",
        "createdAt" : "2020-10-07T07:44:54Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "3338d2ad-28be-41b9-bc66-2dfbfe2e2c42",
        "parentId" : "8700052e-0a7c-4ee8-a156-3ed4f2d56005",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Though [ignoring whitespace changes](https://github.com/digital-asset/daml/pull/7586/files?w=1) recovers some of the readability.",
        "createdAt" : "2020-10-07T08:15:31Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "da792aa9-c338-4cd8-9bff-0a5a17a84663",
        "parentId" : "8700052e-0a7c-4ee8-a156-3ed4f2d56005",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Fair although github has an option to hide whitespace changes. That said, I don’t care at all about doing this in this PR or doing it at all given that I hope most of this bash script disappears in the future anyway.",
        "createdAt" : "2020-10-07T08:48:47Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : null,
    "diffHunk" : "@@ -274,24 +287,18 @@ check_releases bash_lib = do\n \n               \"shopt -s extglob\", -- enable !() pattern: things that _don't_ match\n \n-              -- TODO: get all releases (GH paginates by 30)\n-              \"RELEASES=$(curl https://api.github.com/repos/digital-asset/daml/releases -s)\",\n-              \"for i in $(seq 1 $(echo \\\"$RELEASES\\\" | jq length)); do\",\n-                  \"VERSION=$(echo \\\"$RELEASES\\\" | jq -r \\\".[$i-1].tag_name\\\")\",\n-                  \"mkdir \\\"$VERSION\\\"\",\n-                  \"cd \\\"$VERSION\\\"\",\n                   \"PIDS=\\\"\\\"\",\n-                  \"for ass in $(seq 1 $(echo \\\"$RELEASES\\\" | jq \\\".[$i-1].assets | length\\\")); do\",\n+                  \"for ass in \" <> Data.List.intercalate \" \" (assets release) <> \"; do\","
  },
  {
    "id" : "fd4250e7-ba64-4d88-8847-3450e910ac8b",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "95fe6a10-cf71-436c-8b1d-4a8ec2f7b2ba",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Nice!",
        "createdAt" : "2020-10-07T08:49:11Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : 75,
    "diffHunk" : "@@ -183,12 +185,19 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-data PreVersion = PreVersion { prerelease :: Bool, tag :: Version }\n-instance JSON.FromJSON PreVersion where\n-    parseJSON = JSON.withObject \"PreVersion\" $ \\v -> PreVersion\n-        <$> v JSON..: \"prerelease\"\n-        <*> let json_text = v JSON..: \"tag_name\"\n-            in (version . Text.tail <$> json_text)\n+data Asset = Asset { uri :: Network.URI.URI }\n+instance JSON.FromJSON Asset where\n+    parseJSON = JSON.withObject \"Asset\" $ \\v -> Asset\n+        <$> (do\n+            url_as_string <- v JSON..: \"browser_download_url\"\n+            return $ Data.Maybe.fromJust $ Network.URI.parseURI url_as_string)\n+\n+data GitHubRelease = GitHubRelease { prerelease :: Bool, tag :: Version, assets :: [Asset] }\n+instance JSON.FromJSON GitHubRelease where\n+    parseJSON = JSON.withObject \"GitHubRelease\" $ \\v -> GitHubRelease\n+        <$> (v JSON..: \"prerelease\")\n+        <*> (version . Text.tail <$> v JSON..: \"tag_name\")\n+        <*> (v JSON..: \"assets\")"
  },
  {
    "id" : "1c189959-4337-49ca-94fe-403ae928427a",
    "prId" : 7586,
    "comments" : [
      {
        "id" : "e31108f6-3ad6-42d0-9c7a-e22f35a78ce3",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            Just url <- Network.URI.parseUri <$> v JSON..: \"browser_download_url\"\r\n            return url)\r\n```\r\nThis will make the parser fail rather than crash the whole program on a parse error.",
        "createdAt" : "2020-10-07T08:51:03Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "445582b6-3e3e-48ba-9601-9ee5fbd96b19",
        "parentId" : "e31108f6-3ad6-42d0-9c7a-e22f35a78ce3",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Neat! I do want the program to crash here, though. I _believe_ the parser failing will achieve that, and with any luck we'll get a better error message than from `fromJust`. Also saves me one import.",
        "createdAt" : "2020-10-07T08:53:26Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "c458d618-8a3e-4a4c-a31b-25c068e64d39",
        "parentId" : "e31108f6-3ad6-42d0-9c7a-e22f35a78ce3",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Right, the program will still crash but the parser itself won’t which means you could compose it with other parsers, potentially get better errors, …. All not super important here but given that it’s not any longer and seems a bit cleaner, I don’t see a reason not to do it either.",
        "createdAt" : "2020-10-07T08:56:32Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "b1a49234-1e54-4a61-a6d9-01b05af4a299",
        "parentId" : "e31108f6-3ad6-42d0-9c7a-e22f35a78ce3",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Oh yes it's done. Sorry if that was not clear, I was actually listing arguments in favour. 🙂",
        "createdAt" : "2020-10-07T08:59:07Z",
        "updatedAt" : "2020-10-07T09:49:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "8ff0427fc5bfa77ffc7bddd4d68161481ec41107",
    "line" : null,
    "diffHunk" : "@@ -183,12 +185,19 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-data PreVersion = PreVersion { prerelease :: Bool, tag :: Version }\n-instance JSON.FromJSON PreVersion where\n-    parseJSON = JSON.withObject \"PreVersion\" $ \\v -> PreVersion\n-        <$> v JSON..: \"prerelease\"\n-        <*> let json_text = v JSON..: \"tag_name\"\n-            in (version . Text.tail <$> json_text)\n+data Asset = Asset { uri :: Network.URI.URI }\n+instance JSON.FromJSON Asset where\n+    parseJSON = JSON.withObject \"Asset\" $ \\v -> Asset\n+        <$> (do\n+            url_as_string <- v JSON..: \"browser_download_url\"\n+            return $ Data.Maybe.fromJust $ Network.URI.parseURI url_as_string)"
  },
  {
    "id" : "3cd292dd-d680-4949-9f74-526b5e55bd48",
    "prId" : 7585,
    "comments" : [
      {
        "id" : "8b424f8d-1a51-4931-aceb-f8f96828cb1e",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Seems like there is an extra level of shells here. If you are calling `bash`, you don’t need `shell`.",
        "createdAt" : "2020-10-06T15:35:37Z",
        "updatedAt" : "2020-10-06T16:04:33Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "ab32b672-3fef-4dd8-9920-d32e695689b9",
        "parentId" : "8b424f8d-1a51-4931-aceb-f8f96828cb1e",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I'm aware of the inefficiency here. `shell` is my own wrapper over `System.shell` (see lines 53 & 34), which happens to run `sh`, which would not run this script. I suppose it could be more efficient to just call `System.createProcess` here (and would allow me to pass in the current stdout directly, avoiding the buffering issue), but I don't think it's worth doing at this point.",
        "createdAt" : "2020-10-06T15:48:51Z",
        "updatedAt" : "2020-10-06T16:04:33Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "25e95d944350dcda6a806063ff63aae07e5647bc",
    "line" : 5,
    "diffHunk" : "@@ -262,7 +262,51 @@ docs = do\n \n check_releases :: String -> IO ()\n check_releases bash_lib = do\n-    putStrLn $ \"arg: \" <> bash_lib\n+    out <- shell $ unlines [\"bash -c '\","
  },
  {
    "id" : "28239539-9820-47db-8461-9899321c6f42",
    "prId" : 7570,
    "comments" : [
      {
        "id" : "10d7db85-9470-4049-a781-379504805b59",
        "parentId" : null,
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "This fixes a small issue: previously, after running the docs cron (which only CI does and always in ephemeral nodes, so the notion of \"after\" is a bit flimsy, but still), the cwd would end up with the right commit checked out but in detached HEAD state. By using the branch name here, we avoid that.\r\n\r\nOn the other hand, if run without a branch to start with, this resolves to `HEAD`, so maybe it's not that much better. 🤔",
        "createdAt" : "2020-10-05T16:09:17Z",
        "updatedAt" : "2020-10-05T16:30:52Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2eecea2d50b7d46f90a8685f6df29c931c1e2f07",
    "line" : null,
    "diffHunk" : "@@ -93,24 +93,21 @@ build_and_push temp versions = do\n             putStrLn $ \"Building \" <> show version <> \"...\"\n             build version\n             putStrLn $ \"Pushing \" <> show version <> \" to S3 (as subfolder)...\"\n-            push (temp </> show version) $ show version\n+            push version\n             putStrLn \"Done.\")\n     where\n         restore_sha io =\n-            Control.Exception.bracket (init <$> shell \"git rev-parse HEAD\")\n+            Control.Exception.bracket (init <$> shell \"git rev-parse --abbrev-ref HEAD\")"
  },
  {
    "id" : "9cfc7979-4a19-4417-a929-fb2eca2629cf",
    "prId" : 7570,
    "comments" : [
      {
        "id" : "3006916a-4858-4493-8a39-218e87b1a3b7",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            shell_ $ \"aws s3 cp \" <> (temp </> show version) </> \" \" <> \"s3://docs-daml-com\" </> show version </> \" --recursive --acl public-read\"\r\n```\r\nhlint hates parentheses",
        "createdAt" : "2020-10-05T16:21:22Z",
        "updatedAt" : "2020-10-05T16:30:52Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "ab50c3c1-e976-4927-a461-6f807ba52d19",
        "parentId" : "3006916a-4858-4493-8a39-218e87b1a3b7",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Yep, it caught it too.",
        "createdAt" : "2020-10-05T16:26:14Z",
        "updatedAt" : "2020-10-05T16:30:52Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2eecea2d50b7d46f90a8685f6df29c931c1e2f07",
    "line" : null,
    "diffHunk" : "@@ -93,24 +93,21 @@ build_and_push temp versions = do\n             putStrLn $ \"Building \" <> show version <> \"...\"\n             build version\n             putStrLn $ \"Pushing \" <> show version <> \" to S3 (as subfolder)...\"\n-            push (temp </> show version) $ show version\n+            push version\n             putStrLn \"Done.\")\n     where\n         restore_sha io =\n-            Control.Exception.bracket (init <$> shell \"git rev-parse HEAD\")\n+            Control.Exception.bracket (init <$> shell \"git symbolic-ref --short HEAD 2>/dev/null || git rev-parse HEAD\")\n                                       (\\cur_sha -> shell_ $ \"git checkout \" <> cur_sha)\n                                       (const io)\n         build version = do\n             shell_ $ \"git checkout v\" <> show version\n-            build_helper version\n-\n-        build_helper version = do\n             robustly_download_nix_packages\n             shell_ $ \"DAML_SDK_RELEASE_VERSION=\" <> show version <> \" bazel build //docs:docs\"\n             shell_ $ \"mkdir -p  \" <> temp </> show version\n             shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> temp </> show version\n-        push local remote =\n-            shell_ $ \"aws s3 cp \" <> local </> \" \" <> \"s3://docs-daml-com\" </> remote </> \" --recursive --acl public-read\"\n+        push version =\n+            shell_ $ \"aws s3 cp \" <> (temp </> show version) </> \" \" <> \"s3://docs-daml-com\" </> (show version) </> \" --recursive --acl public-read\""
  },
  {
    "id" : "2785fa80-800e-41bb-991a-effc4e113729",
    "prId" : 7570,
    "comments" : [
      {
        "id" : "7d8a6602-6dab-4fda-b12e-df908fa9af7a",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I’d prefer not to add this. It isn’t necessary now and if you shuffle things you might accidentally move this outside of `main` where it can be quite problematic or at least confusing. In other words, don’t make `main` more special than it is by relying on the fact that calling `exitSuccess` at the end doesn’t break things.",
        "createdAt" : "2020-10-05T16:23:52Z",
        "updatedAt" : "2020-10-05T16:30:52Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "d98566d8-cc95-44a4-9ec2-3d030f402c3d",
        "parentId" : "7d8a6602-6dab-4fda-b12e-df908fa9af7a",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Would you also remove it from line 246/249 then? I don't particularly care about the explicit exit, but I do think it's best if both branches are symmetric in that regard.",
        "createdAt" : "2020-10-05T16:28:02Z",
        "updatedAt" : "2020-10-05T16:30:52Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "25bf94e8-8851-4577-961c-a065283955ba",
        "parentId" : "7d8a6602-6dab-4fda-b12e-df908fa9af7a",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Good point, didn’t see that it was there already. Yes, best to remove it there as well.",
        "createdAt" : "2020-10-05T16:29:30Z",
        "updatedAt" : "2020-10-05T16:30:52Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "23f0ba30-bbb9-49af-9612-ead3a6bd8992",
        "parentId" : "7d8a6602-6dab-4fda-b12e-df908fa9af7a",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Done.",
        "createdAt" : "2020-10-05T16:30:55Z",
        "updatedAt" : "2020-10-05T16:30:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2eecea2d50b7d46f90a8685f6df29c931c1e2f07",
    "line" : null,
    "diffHunk" : "@@ -261,3 +258,4 @@ main = do\n             putStrLn \"Updating versions.json & hidden.json\"\n             update_s3 temp_dir gh_versions\n         reset_cloudfront\n+        Exit.exitSuccess"
  },
  {
    "id" : "aca8450a-8700-4ab7-8ce4-03aa845c06a1",
    "prId" : 7569,
    "comments" : [
      {
        "id" : "b1f531d1-2dfa-4d42-83b7-83dd68c6d56d",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Any reason not to use `optparse-applicative` here? IME it’s pretty cheap in terms of the extra effort it requires even for very simple things and it’s much more maintainable as things get more complex.",
        "createdAt" : "2020-10-05T16:43:43Z",
        "updatedAt" : "2020-10-05T16:44:01Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "206cb864-ad5a-488a-9019-39d8272fa788",
        "parentId" : "b1f531d1-2dfa-4d42-83b7-83dd68c6d56d",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I honestly don't expect this to get any more complex than this 2-way dispatch for a very long time, but I'll look at optparse next time I need to make any change there.",
        "createdAt" : "2020-10-05T17:34:59Z",
        "updatedAt" : "2020-10-05T17:34:59Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "574d1ae7672f0d8dffb77ae7c48a6a695f161c59",
    "line" : 28,
    "diffHunk" : "@@ -261,3 +262,13 @@ main = do\n             putStrLn \"Updating versions.json & hidden.json\"\n             update_s3 temp_dir gh_versions\n         reset_cloudfront\n+\n+check_signatures :: IO ()\n+check_signatures = do\n+    putStrLn \"FIXME\"\n+\n+main :: IO ()"
  },
  {
    "id" : "55dada64-a472-4509-a2bf-6bd9d8aea871",
    "prId" : 6817,
    "comments" : [
      {
        "id" : "4bad3e4f-66dc-4f50-8c83-34011de594dd",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Can we just use the `semver` library which we use in other places instead of trying to implement our own semver type and comparison?",
        "createdAt" : "2020-07-21T15:39:06Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "6e9a6fd4-180b-4beb-9310-983243790320",
        "parentId" : "4bad3e4f-66dc-4f50-8c83-34011de594dd",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "What I needed here was pretty simple and I knew how to implement it. It's also pretty short, and generally speaking I dislike relying on libraries when the equivalent code is short and simple.\r\n\r\nAlso, I can't figure out how to use the SemVer library from its documentation, and I did not care to learn about lenses just for this. Happy to give you a chance to change my mind if you want to volunteer some time to explain them to me.",
        "createdAt" : "2020-07-21T16:05:00Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "7171eab8-d43d-4d08-aab0-e028330e19b7",
        "parentId" : "4bad3e4f-66dc-4f50-8c83-34011de594dd",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Very happy to explain them to you. Let’s leave it out of this PR and then whenever you’re interested in, we can take a look at switching it over to `semver` together.",
        "createdAt" : "2020-07-21T16:24:15Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f559dc1deec75c37d0b4d6dc0434a23b859c510b",
    "line" : null,
    "diffHunk" : "@@ -90,24 +92,43 @@ http_get url = do\n       _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n                                show $ HTTP.responseBody response]\n \n-newtype Version = Version (Int, Int, Int, Maybe String)\n+data StringOrInt = I Int | S String"
  },
  {
    "id" : "d37f81ff-5c2d-45fd-bb5a-b530ba8d5ff8",
    "prId" : 6817,
    "comments" : [
      {
        "id" : "70fa71ee-d1d3-4917-ba88-c60b8a46b11a",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I would recommend to use `SemVer.Version` here instead of `String` so you don’t have to parse it everytime you use it.",
        "createdAt" : "2020-07-24T08:48:30Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "b1fbfda0-ba63-487e-954d-4889c3004a9a",
        "parentId" : "70fa71ee-d1d3-4917-ba88-c60b8a46b11a",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "SemVer.Version is a bit unwieldy (and imo dangerous in this case), but I did add more types so conversion to String happens later. Hope that's what you had in mind.\r\n\r\nI even turned some `String` strings into `FilePath` as human-reader-hint, though that one doesn't add safety.",
        "createdAt" : "2020-07-24T11:19:28Z",
        "updatedAt" : "2020-07-24T11:19:29Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f559dc1deec75c37d0b4d6dc0434a23b859c510b",
    "line" : null,
    "diffHunk" : "@@ -325,43 +238,62 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-fetch_gh_versions :: IO ([GitHubVersion], GitHubVersion)\n+data Versions = Versions { top :: String, all :: Set.Set String, dropdown :: [String] }"
  },
  {
    "id" : "6f3711c0-1509-4d0f-96a9-2b930a908f4e",
    "prId" : 6817,
    "comments" : [
      {
        "id" : "252efd15-f0d4-4327-b4dc-fa86d6b0d64a",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "This looks like a typo, `temp </> version` is probably not a function .",
        "createdAt" : "2020-07-24T08:49:20Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "81d1b7cd-e967-4dc8-a8f1-e0aba4301692",
        "parentId" : "252efd15-f0d4-4327-b4dc-fa86d6b0d64a",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Looks like you _just missed_ the version that actually compiles by about three minutes. Sorry about that.",
        "createdAt" : "2020-07-24T09:01:05Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f559dc1deec75c37d0b4d6dc0434a23b859c510b",
    "line" : null,
    "diffHunk" : "@@ -90,163 +89,90 @@ http_get url = do\n       _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n                                show $ HTTP.responseBody response]\n \n-newtype Version = Version (Int, Int, Int, Maybe String)\n-  deriving (Eq, Ord)\n-\n-instance Show Version where\n-    show (Version (a, b, c, q)) = show a <> \".\" <> show b <> \".\" <> show c <> Maybe.maybe \"\" (\\qual -> \"-\" <> qual) q\n-\n-to_v :: String -> Version\n-to_v s = case Split.splitOn \"-\" s of\n-    [prefix, qualifier] -> let (major, minor, patch) = parse_stable prefix\n-                           in Version (major, minor, patch, Just qualifier)\n-    [stable] -> let (major, minor, patch) = parse_stable stable\n-                in Version (major, minor, patch, Nothing)\n-    _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n-    where parse_stable s = case map read $ Split.splitOn \".\" s of\n-              [major, minor, patch] -> (major, minor, patch)\n-              _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n-\n-build_docs_folder :: String -> [GitHubVersion] -> String -> IO String\n-build_docs_folder path versions current = do\n+build_and_push :: String -> [String] -> IO ()\n+build_and_push temp versions = do\n     restore_sha $ do\n-        let old = path </> \"old\"\n-        let new = path </> \"new\"\n-        shell_ $ \"mkdir -p \" <> new\n-        shell_ $ \"mkdir -p \" <> old\n-        download_existing_site_from_s3 old\n-        documented_versions <- Maybe.catMaybes <$> Traversable.for versions (\\gh_version -> do\n-            let version = name gh_version\n+        Data.Foldable.for_ versions (\\version -> do\n             putStrLn $ \"Building \" <> version <> \"...\"\n-            putStrLn \"  Checking for existing folder...\"\n-            old_version_exists <- exists $ old </> version\n-            if to_v version < to_v \"0.13.36\"\n-            then do\n-                -- Maven has stopped accepting http requests and now requires\n-                -- https. We have a patch for 0.13.36 and above, which has been\n-                -- merged between 0.13.43 and 0.13.44.\n-                if old_version_exists\n-                then do\n-                    putStrLn \"  Found. Too old to rebuild, copying over...\"\n-                    copy (old </> version) $ new </> version\n-                    return $ Just (gh_version, False)\n-                else do\n-                    putStrLn \"  Too old to rebuild and no existing version. Skipping.\"\n-                    return Nothing\n-            else if to_v version < to_v \"0.13.45\"\n-            then do\n-                -- Versions prior to 0.13.45 do have a checksum file, and\n-                -- should be buildable with the Maven cherry-pick (see `build`\n-                -- function below), but their build is not reproducible\n-                -- (includes date of build) and therefore the checksum file is\n-                -- useless\n-                if old_version_exists\n-                then do\n-                    putStrLn \"  Found. No reliable checksum; copying over and hoping for the best...\"\n-                    copy (old </> version) $ new </> version\n-                    return $ Just (gh_version, False)\n-                else do\n-                    putStrLn \"  Not found. Building...\"\n-                    build version new\n-                    return $ Just (gh_version, True)\n-            else if old_version_exists\n-            then do\n-                -- Note: this checks for upload errors; this is NOT in any way\n-                -- a protection against tampering at the s3 level as we get the\n-                -- checksums from the s3 bucket.\n-                putStrLn \"  Found. Checking integrity...\"\n-                checksums_match <- checksums $ old </> version\n-                if checksums_match\n-                then do\n-                    putStrLn \"  Checks, reusing existing.\"\n-                    copy (old </> version) $ new </> version\n-                    return $ Just (gh_version, False)\n-                else do\n-                    putStrLn \"  Check failed. Rebuilding...\"\n-                    build version new\n-                    return $ Just (gh_version, True)\n-            else do\n-                putStrLn \"  Not found. Building...\"\n-                build version new\n-                return $ Just (gh_version, True))\n-        putStrLn $ \"Copying current (\" <> current <> \") to top-level...\"\n-        copy (new </> current </> \"*\") (new <> \"/\")\n-        putStrLn \"Creating versions.json...\"\n-        let (releases, snapshots) = List.partition (not . prerelease . fst) documented_versions\n-        create_versions_json (map fst releases) (new </> \"versions.json\")\n-        create_versions_json (map fst snapshots) (new </> \"snapshots.json\")\n-        -- Starting after 0.13.54, we have changed the way in which we trigger\n-        -- releases. Rather than releasing the current commit by changing the\n-        -- VERSION file, we now mark an existing commit as the source code for\n-        -- a release by changing the LATEST file. This raises the question of\n-        -- the release notes: as we tag a commit from the past, and keep the\n-        -- changelog outside of the worktree (in commit messages), that means\n-        -- that commit cannot contain its own release notes. We have decided to\n-        -- resolve that conundrum by always including the release notes from\n-        -- the most recent release in all releases.\n-        case filter snd documented_versions of\n-          ((newly_built,_):_) -> do\n-              putStrLn $ \"Copying release notes from \" <> name newly_built <> \" to all other versions...\"\n-              let p v = new </> name v </> \"support\" </> \"release-notes.html\"\n-              let top_level_release_notes = new </> \"support\" </> \"release-notes.html\"\n-              shell_ $ \"cp \" <> p newly_built <> \" \" <> top_level_release_notes\n-              Data.Foldable.for_ documented_versions $ \\(gh_version, _) -> do\n-                  shell_ $ \"cp \" <> top_level_release_notes <> \" \" <> p gh_version\n-          _ -> do\n-              putStrLn \"No version built, so no release page copied.\"\n-        return new\n+            build version\n+            putStrLn $ \"Pushing \" <> version <> \" to S3 (as subfolder)...\"\n+            push_to_s3 $ (temp </> version) version"
  },
  {
    "id" : "a732f661-ab1f-4677-94fb-725211f830e3",
    "prId" : 6817,
    "comments" : [
      {
        "id" : "29701752-17f0-47bb-b5cb-e75fbecc8731",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Is there a downside to sorting them? While it might not matter it still seems nice to sort things.",
        "createdAt" : "2020-07-24T08:52:12Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "9191915b-2b1e-41cd-aac4-16c93ac90712",
        "parentId" : "29701752-17f0-47bb-b5cb-e75fbecc8731",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "At this point they're `String`s so it's a bit unwieldy to sort them, and nobody is supposed to look at that file. Not much effort to add, though; I'll look into that.",
        "createdAt" : "2020-07-24T09:03:02Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "7375a5b1-a4fd-4d3a-87dc-bb9dbcfed6a2",
        "parentId" : "29701752-17f0-47bb-b5cb-e75fbecc8731",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "By keeping a `Version` type up to this point it's become fairly easy to sort them, so that's now done.",
        "createdAt" : "2020-07-24T11:20:00Z",
        "updatedAt" : "2020-07-24T11:20:00Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f559dc1deec75c37d0b4d6dc0434a23b859c510b",
    "line" : null,
    "diffHunk" : "@@ -90,163 +88,90 @@ http_get url = do\n       _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n                                show $ HTTP.responseBody response]\n \n-newtype Version = Version (Int, Int, Int, Maybe String)\n-  deriving (Eq, Ord)\n-\n-instance Show Version where\n-    show (Version (a, b, c, q)) = show a <> \".\" <> show b <> \".\" <> show c <> Maybe.maybe \"\" (\\qual -> \"-\" <> qual) q\n-\n-to_v :: String -> Version\n-to_v s = case Split.splitOn \"-\" s of\n-    [prefix, qualifier] -> let (major, minor, patch) = parse_stable prefix\n-                           in Version (major, minor, patch, Just qualifier)\n-    [stable] -> let (major, minor, patch) = parse_stable stable\n-                in Version (major, minor, patch, Nothing)\n-    _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n-    where parse_stable s = case map read $ Split.splitOn \".\" s of\n-              [major, minor, patch] -> (major, minor, patch)\n-              _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n-\n-build_docs_folder :: String -> [GitHubVersion] -> String -> IO String\n-build_docs_folder path versions current = do\n+build_and_push :: String -> [String] -> IO ()\n+build_and_push temp versions = do\n     restore_sha $ do\n-        let old = path </> \"old\"\n-        let new = path </> \"new\"\n-        shell_ $ \"mkdir -p \" <> new\n-        shell_ $ \"mkdir -p \" <> old\n-        download_existing_site_from_s3 old\n-        documented_versions <- Maybe.catMaybes <$> Traversable.for versions (\\gh_version -> do\n-            let version = name gh_version\n+        Data.Foldable.for_ versions (\\version -> do\n             putStrLn $ \"Building \" <> version <> \"...\"\n-            putStrLn \"  Checking for existing folder...\"\n-            old_version_exists <- exists $ old </> version\n-            if to_v version < to_v \"0.13.36\"\n-            then do\n-                -- Maven has stopped accepting http requests and now requires\n-                -- https. We have a patch for 0.13.36 and above, which has been\n-                -- merged between 0.13.43 and 0.13.44.\n-                if old_version_exists\n-                then do\n-                    putStrLn \"  Found. Too old to rebuild, copying over...\"\n-                    copy (old </> version) $ new </> version\n-                    return $ Just (gh_version, False)\n-                else do\n-                    putStrLn \"  Too old to rebuild and no existing version. Skipping.\"\n-                    return Nothing\n-            else if to_v version < to_v \"0.13.45\"\n-            then do\n-                -- Versions prior to 0.13.45 do have a checksum file, and\n-                -- should be buildable with the Maven cherry-pick (see `build`\n-                -- function below), but their build is not reproducible\n-                -- (includes date of build) and therefore the checksum file is\n-                -- useless\n-                if old_version_exists\n-                then do\n-                    putStrLn \"  Found. No reliable checksum; copying over and hoping for the best...\"\n-                    copy (old </> version) $ new </> version\n-                    return $ Just (gh_version, False)\n-                else do\n-                    putStrLn \"  Not found. Building...\"\n-                    build version new\n-                    return $ Just (gh_version, True)\n-            else if old_version_exists\n-            then do\n-                -- Note: this checks for upload errors; this is NOT in any way\n-                -- a protection against tampering at the s3 level as we get the\n-                -- checksums from the s3 bucket.\n-                putStrLn \"  Found. Checking integrity...\"\n-                checksums_match <- checksums $ old </> version\n-                if checksums_match\n-                then do\n-                    putStrLn \"  Checks, reusing existing.\"\n-                    copy (old </> version) $ new </> version\n-                    return $ Just (gh_version, False)\n-                else do\n-                    putStrLn \"  Check failed. Rebuilding...\"\n-                    build version new\n-                    return $ Just (gh_version, True)\n-            else do\n-                putStrLn \"  Not found. Building...\"\n-                build version new\n-                return $ Just (gh_version, True))\n-        putStrLn $ \"Copying current (\" <> current <> \") to top-level...\"\n-        copy (new </> current </> \"*\") (new <> \"/\")\n-        putStrLn \"Creating versions.json...\"\n-        let (releases, snapshots) = List.partition (not . prerelease . fst) documented_versions\n-        create_versions_json (map fst releases) (new </> \"versions.json\")\n-        create_versions_json (map fst snapshots) (new </> \"snapshots.json\")\n-        -- Starting after 0.13.54, we have changed the way in which we trigger\n-        -- releases. Rather than releasing the current commit by changing the\n-        -- VERSION file, we now mark an existing commit as the source code for\n-        -- a release by changing the LATEST file. This raises the question of\n-        -- the release notes: as we tag a commit from the past, and keep the\n-        -- changelog outside of the worktree (in commit messages), that means\n-        -- that commit cannot contain its own release notes. We have decided to\n-        -- resolve that conundrum by always including the release notes from\n-        -- the most recent release in all releases.\n-        case filter snd documented_versions of\n-          ((newly_built,_):_) -> do\n-              putStrLn $ \"Copying release notes from \" <> name newly_built <> \" to all other versions...\"\n-              let p v = new </> name v </> \"support\" </> \"release-notes.html\"\n-              let top_level_release_notes = new </> \"support\" </> \"release-notes.html\"\n-              shell_ $ \"cp \" <> p newly_built <> \" \" <> top_level_release_notes\n-              Data.Foldable.for_ documented_versions $ \\(gh_version, _) -> do\n-                  shell_ $ \"cp \" <> top_level_release_notes <> \" \" <> p gh_version\n-          _ -> do\n-              putStrLn \"No version built, so no release page copied.\"\n-        return new\n+            build version\n+            putStrLn $ \"Pushing \" <> version <> \" to S3 (as subfolder)...\"\n+            push (temp </> version) version\n+            putStrLn $ \"Done.\")\n     where\n         restore_sha io =\n             Control.Exception.bracket (init <$> shell \"git rev-parse HEAD\")\n                                       (\\cur_sha -> shell_ $ \"git checkout \" <> cur_sha)\n                                       (const io)\n-        download_existing_site_from_s3 path = do\n-            shell_ $ \"mkdir -p \" <> path\n-            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n-        exists dir = Directory.doesDirectoryExist dir\n-        checksums path = do\n-            let cmd = \"cd \" <> path <> \"; sed -i '/support\\\\/release-notes.html/d' checksum; sha256sum -c checksum\"\n-            (code, _, _) <- shell_exit_code cmd\n-            case code of\n-                Exit.ExitSuccess -> return True\n-                _ -> return False\n-        copy from to = do\n-            shell_ $ \"cp -r \" <> from <> \" \" <> to\n-        build version path = do\n+        build version = do\n             shell_ $ \"git checkout v\" <> version\n-            -- Maven does not accept http connections anymore; this patches the\n-            -- scala rules for Bazel to use https instead. This is not needed\n-            -- after 0.13.43.\n-            if to_v version < to_v \"0.13.44\"\n-            then do\n-                shell_ \"git -c user.name=CI -c user.email=CI@example.com cherry-pick 0c4f9d7f92c4f2f7e2a75a0d85db02e20cbb497b\"\n-                build_helper version path\n-            else do\n-                -- The release-triggering commit does not have a tag, so we\n-                -- need to find it by walking through the git history of the\n-                -- LATEST file.\n-                sha <- find_commit_for_version version\n-                Control.Exception.bracket_\n-                    (shell_ $ \"git checkout \" <> sha <> \" -- docs/source/support/release-notes.rst\")\n-                    (shell_ \"git reset --hard\")\n-                    (build_helper version path)\n-        build_helper version path = do\n-            robustly_download_nix_packages version\n+            -- The release-triggering commit does not have a tag, so we need to\n+            -- find it by walking through the git history of the LATEST file.\n+            sha <- find_commit_for_version version\n+            Control.Exception.bracket_\n+                (shell_ $ \"git checkout \" <> sha <> \" -- docs/source/support/release-notes.rst\")\n+                (shell_ \"git reset --hard\")\n+                (build_helper version)\n+        build_helper version = do\n+            robustly_download_nix_packages\n             shell_ $ \"DAML_SDK_RELEASE_VERSION=\" <> version <> \" bazel build //docs:docs\"\n-            shell_ $ \"mkdir -p  \" <> path </> version\n-            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path </> version\n-            checksums <- shell $ \"cd \" <> path </> version <> \"; find . -type f -exec sha256sum {} \\\\; | grep -v 'support/release-notes.html'\"\n-            writeFile (path </> version </> \"checksum\") checksums\n-        create_versions_json versions path = do\n+            shell_ $ \"mkdir -p  \" <> temp </> version\n+            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> temp </> version\n+\n+push :: String -> String -> IO ()\n+push local remote =\n+    shell_ $ \"aws s3 cp \" <> local <> \" \" <> \"s3://docs-daml-com\" </> remote <> \" --recursive\"\n+\n+fetch_if_missing :: String -> String -> IO ()\n+fetch_if_missing temp folder = do\n+    missing <- not <$> Directory.doesDirectoryExist (temp </> folder)\n+    if missing then do\n+        putStrLn $ \"Downloading \" <> folder <> \"...\"\n+        shell_ $ \"aws s3 cp s3://docs-daml-com\" </> folder <> \" \" <> temp </> folder <> \" --recursive\"\n+        putStrLn \"Done.\"\n+    else do\n+        putStrLn $ folder <> \" already present.\"\n+\n+update_s3 :: String -> Versions -> IO ()\n+update_s3 temp vs = do\n+    putStrLn \"Updating versions.json & hidden.json...\"\n+    create_versions_json (dropdown vs) (temp </> \"versions.json\")\n+    -- order does not matter for hidden ones\n+    create_versions_json (Set.toList $ all_versions vs `Set.difference` (Set.fromList $ dropdown vs)) (temp </> \"hidden.json\")"
  },
  {
    "id" : "a96e9684-899a-4134-8f10-c471a8fdedde",
    "prId" : 6817,
    "comments" : [
      {
        "id" : "4088d425-92af-4b1f-a6b9-b73ef07aa28e",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I would recommend to store `SemVer.Version` here to make it explicit and only parse once.",
        "createdAt" : "2020-07-24T08:54:10Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "a5cb8778-de85-46a9-b2b4-bd8b9c3ca8ef",
        "parentId" : "4088d425-92af-4b1f-a6b9-b73ef07aa28e",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "It's actually that exact same reasoning that led me to this representation: after the point where the `Versions` values are constructed, we only ever use them as `String`s.\r\n\r\nIf you look at all the calls to `parse` (there's only three of them), they never touch something extracted from a `Versions`. However, we do use the components of `Versions` as `String`s quite a bit, either to print for the user or to construct file paths.\r\n\r\nI'll have to check if this is still true after trying to sort the hidden ones, though.",
        "createdAt" : "2020-07-24T09:10:46Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "5a1fee74-6cd7-4272-a946-8324f844ac39",
        "parentId" : "4088d425-92af-4b1f-a6b9-b73ef07aa28e",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I generally try to only convert to `String`s at the edges and retain as much structure an types as possible. But I don’t feel strongly about this here so feel free to ignore this comment.",
        "createdAt" : "2020-07-24T09:14:00Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "6f0d6d56-3b43-4179-bc95-92d09ded5fa6",
        "parentId" : "4088d425-92af-4b1f-a6b9-b73ef07aa28e",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "@nickchapman-da pushed for that too, so I eventually admitted I may be wrong and tried it out. I kinda like how it turned out.",
        "createdAt" : "2020-07-24T11:21:05Z",
        "updatedAt" : "2020-07-24T11:21:05Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f559dc1deec75c37d0b4d6dc0434a23b859c510b",
    "line" : null,
    "diffHunk" : "@@ -325,43 +221,62 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-fetch_gh_versions :: IO ([GitHubVersion], GitHubVersion)\n+data Versions = Versions { top :: String, all_versions :: Set.Set String, dropdown :: [String] }"
  },
  {
    "id" : "0adf8a44-c86b-4293-bb1d-f41674378e96",
    "prId" : 6817,
    "comments" : [
      {
        "id" : "7211b1ef-a480-40d9-b287-e282054a3bf9",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Do we still need this filter?",
        "createdAt" : "2020-07-24T08:54:42Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "36c08cbd-7c05-41ae-a2ec-d1b4ba380628",
        "parentId" : "7211b1ef-a480-40d9-b287-e282054a3bf9",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I have a slight preference for keeping it. Keeping it means the combination of `versions.json` and `hidden.json` list all the versions for which we have docs on the docs site. Not keeping it means that same combination instead represents all the versions for which we are not going to try building the docs again. It's a small distinction but I like the former better.\r\n\r\nIf we did want to remove it (I could be persuaded, but not as part of this PR), we'd need some sort of plan with an intermediate state in this script to write the new, more complete `hidden.json` while not trying to build them.",
        "createdAt" : "2020-07-24T09:41:17Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "cfcd832d-bff3-4897-af71-810e53fd8ac0",
        "parentId" : "7211b1ef-a480-40d9-b287-e282054a3bf9",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Makes sense, let’s keep it then.",
        "createdAt" : "2020-07-24T09:46:04Z",
        "updatedAt" : "2020-07-24T11:14:30Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f559dc1deec75c37d0b4d6dc0434a23b859c510b",
    "line" : null,
    "diffHunk" : "@@ -325,43 +221,62 @@ fetch_gh_paginated url = do\n                 (_, _, _, [url, rel]) -> (rel, url)\n                 _ -> fail $ \"Assumption violated: link header entry did not match regex.\\nEntry: \" <> l\n \n-fetch_gh_versions :: IO ([GitHubVersion], GitHubVersion)\n+data Versions = Versions { top :: String, all_versions :: Set.Set String, dropdown :: [String] }\n+    deriving Eq\n+\n+versions :: [Version] -> Versions\n+versions vs =\n+    let to_strings = map (Data.SemVer.toString . tag)\n+        all_versions = Set.fromList $ to_strings vs\n+        dropdown = to_strings $ List.sortOn (Data.Ord.Down . tag) $ filter (\\v -> tag v >= parse (Text.pack \"1.0.0\") && not (prerelease v)) vs\n+        top = head dropdown\n+    in Versions {..}\n+\n+fetch_gh_versions :: IO Versions\n fetch_gh_versions = do\n-    resp <- fetch_gh_paginated \"https://api.github.com/repos/digital-asset/daml/releases\"\n-    let latest = List.maximumOn (to_v . name) $ filter (not . prerelease) resp\n-    return (resp, latest)\n+    response <- fetch_gh_paginated \"https://api.github.com/repos/digital-asset/daml/releases\"\n+    -- versions prior to 0.13.10 cannot be built anymore and are not present in\n+    -- the repo.\n+    return $ versions $ filter (\\v -> tag v >= parse (Text.pack \"0.13.10\")) response"
  },
  {
    "id" : "ac985ee1-d20a-41a0-8b7f-9a34a6a7ed7a",
    "prId" : 6285,
    "comments" : [
      {
        "id" : "ed5f6cdf-c7b5-4525-a585-f701366e4d1d",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n      _ -> fail $ \"Expected single commit to match release \" <> version <> \", but instead found: \" <> show matching\r\n```\r\nThat one crashes during execution rather than evaluation which is a bit more predictable (here `error` should be fine but I prefer going for the safe option).",
        "createdAt" : "2020-06-10T12:18:16Z",
        "updatedAt" : "2020-06-10T12:24:06Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "a5d8055ebdf950bbd27912a1c68d1c7b4f074262",
    "line" : 37,
    "diffHunk" : "@@ -241,6 +248,25 @@ build_docs_folder path versions current = do\n                                 & \\s -> \"{\" <> s <> \"}\"\n             writeFile path versions_json\n \n+find_commit_for_version :: String -> IO String\n+find_commit_for_version version = do\n+    ver_sha <- init <$> (shell $ \"git rev-parse v\" <> version)\n+    let expected = ver_sha <> \" \" <> version\n+    -- git log -G 'regex' returns all the commits for which 'regex' appears in\n+    -- the diff. To find out the commit that \"released\" the version. The commit\n+    -- we want is a commit that added a single line, which matches the version\n+    -- we are checking for.\n+    matching_commits <- lines <$> (shell $ \"git log --format=%H --all -G '\" <> ver_sha <> \"' -- LATEST\")\n+    matching <- Maybe.catMaybes <$> Traversable.for matching_commits (\\sha -> do\n+        after <- Set.fromList . lines <$> (shell $ \"git show \" <> sha <> \":LATEST\")\n+        before <- Set.fromList . lines <$> (shell $ \"git show \" <> sha <> \"~:LATEST\")\n+        return $ case Set.toList(after `Set.difference` before) of\n+                     [line] | line == expected -> Just sha\n+                     _ -> Nothing)\n+    case matching of\n+      [sha] -> return sha\n+      _ -> error $ \"Expected single commit to match release \" <> version <> \", but instead found: \" <> show matching"
  },
  {
    "id" : "e256e077-5b6a-49ca-ac8f-d7eeaa65d08f",
    "prId" : 6285,
    "comments" : [
      {
        "id" : "c24f7a7c-8af2-4fd1-a4ea-9d7673515d79",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Answering my own question: Even if we switch to a stable release without modifying the commit, we only get a single hit since we look for the exact line which includes both the version number and the hash not just the hash :+1:",
        "createdAt" : "2020-06-10T12:23:54Z",
        "updatedAt" : "2020-06-10T12:24:06Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "f9f0e750-3cf0-4598-a5aa-23cc9c6b2ebf",
        "parentId" : "c24f7a7c-8af2-4fd1-a4ea-9d7673515d79",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Spurious commits we would get in the `matching_commits` list include commits that remove that version line (whether by removing entirely or by changing the tag without changing the hash) and the one commit where LATEST suddenly became multi-line. As far as I'm aware that's all, and both cases will be filtered out by the set difference logic below.",
        "createdAt" : "2020-06-10T12:38:30Z",
        "updatedAt" : "2020-06-10T12:38:30Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "a5d8055ebdf950bbd27912a1c68d1c7b4f074262",
    "line" : 28,
    "diffHunk" : "@@ -241,6 +248,25 @@ build_docs_folder path versions current = do\n                                 & \\s -> \"{\" <> s <> \"}\"\n             writeFile path versions_json\n \n+find_commit_for_version :: String -> IO String\n+find_commit_for_version version = do\n+    ver_sha <- init <$> (shell $ \"git rev-parse v\" <> version)\n+    let expected = ver_sha <> \" \" <> version\n+    -- git log -G 'regex' returns all the commits for which 'regex' appears in\n+    -- the diff. To find out the commit that \"released\" the version. The commit\n+    -- we want is a commit that added a single line, which matches the version\n+    -- we are checking for.\n+    matching_commits <- lines <$> (shell $ \"git log --format=%H --all -G '\" <> ver_sha <> \"' -- LATEST\")"
  },
  {
    "id" : "69e14473-06d0-4bbe-b92e-2030812d77f3",
    "prId" : 6128,
    "comments" : [
      {
        "id" : "e6134b68-586f-49a3-b87b-9ff39764431c",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "CI is failing because `latest_sha` is now unusued.",
        "createdAt" : "2020-05-27T17:02:30Z",
        "updatedAt" : "2020-05-27T21:49:40Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "edc11ca5-f860-428a-92a2-840d8f8bfc60",
        "parentId" : "e6134b68-586f-49a3-b87b-9ff39764431c",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "🤦 ",
        "createdAt" : "2020-05-27T21:35:33Z",
        "updatedAt" : "2020-05-27T21:49:40Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "d4ce486d8f73768357213dc68f06e08efa068dea",
    "line" : 35,
    "diffHunk" : "@@ -176,6 +176,15 @@ build_docs_folder path versions current = do\n         let (releases, snapshots) = List.partition (not . prerelease . fst) documented_versions\n         create_versions_json (map fst releases) (new </> \"versions.json\")\n         create_versions_json (map fst snapshots) (new </> \"snapshots.json\")\n+        -- Starting after 0.13.54, we have changed the way in which we trigger"
  },
  {
    "id" : "eb0ebe1d-3ed9-4f2d-8001-d00a397eb32e",
    "prId" : 6016,
    "comments" : [
      {
        "id" : "5fb1c7fd-ffdc-4e3f-af5b-ab58f4270ab5",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "the meaning of latest hasn’t changed right? it’s still the latest release on github releases that is not a prerelease according to semver?",
        "createdAt" : "2020-05-19T07:57:44Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "489d24cd-2f1f-4dcb-8031-2ba6b2dcb77f",
        "parentId" : "5fb1c7fd-ffdc-4e3f-af5b-ab58f4270ab5",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "The meaning has actually changed, not as of this PR, but as of #5584, despite that variable not being touched in there. What we want here is not the latest version, but the highest-numbered one, i.e. if 1.0.1 is released after 1.1.0, we still want the top-level documentation to show 1.1.0. So I thought calling it `latest` here would be confusing, especially now that I added references to the \"latest\" release notes (which really are intended to be the latest, as in most recent).",
        "createdAt" : "2020-05-19T09:47:30Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "5f991d71059dcd0bad10906e5ddf2f510803c993",
    "line" : 13,
    "diffHunk" : "@@ -107,13 +108,14 @@ to_v s = case Split.splitOn \"-\" s of\n               _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n build_docs_folder :: String -> [GitHubVersion] -> String -> IO String\n-build_docs_folder path versions latest = do\n+build_docs_folder path versions current = do"
  },
  {
    "id" : "4ae9f4fa-06b7-4543-827d-a51ba611b2b0",
    "prId" : 6016,
    "comments" : [
      {
        "id" : "80950196-57cd-4eeb-afd4-b4cbbd57521e",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "fwiw bracket_ is the version of bracket where you don’t have a resource that you need to pass around which would save you a bit of \\_ -> .",
        "createdAt" : "2020-05-19T07:58:04Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "f669b5d2-125a-44a3-99c7-3495199ed044",
        "parentId" : "80950196-57cd-4eeb-afd4-b4cbbd57521e",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Not really part of this PR, but thanks for the clean-up.",
        "createdAt" : "2020-05-19T16:31:25Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "5f991d71059dcd0bad10906e5ddf2f510803c993",
    "line" : null,
    "diffHunk" : "@@ -207,25 +216,24 @@ build_docs_folder path versions latest = do\n             -- Starting after 0.13.54, we have changed the way in which we\n             -- trigger releases. Rather than releasing the current commit by\n             -- changing the VERSION file, we now mark an existing commit as the\n-            -- source code for a release by changing the LATEST file. However,\n-            -- release notes still need to be taken from the release commit\n-            -- (i.e. the one that changes the LATEST file, not the one being\n-            -- pointed to).\n+            -- source code for a release by changing the LATEST file. This\n+            -- raises the question of the release notes: as we tag a commit\n+            -- from the past, and keep the changelog outside of the worktree\n+            -- (in commit messages), that means that commit cannot contain its\n+            -- own release notes. We have decided to resolve that conundrum by\n+            -- always including the release notes from the most recent release\n+            -- in all releases.\n             else do\n-                -- The release-triggering commit does not have a tag, so we\n-                -- need to find it by walking through the git history of the\n-                -- LATEST file.\n-                sha <- find_commit_for_version version\n                 Control.Exception.bracket"
  },
  {
    "id" : "5dcd0f85-bf7b-4ff2-bf68-8ec057875826",
    "prId" : 6016,
    "comments" : [
      {
        "id" : "5bd045ef-50e2-4b17-9465-a5becc6331b3",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Do we check before somewhere that at least one version is being rebuilt? If not this could crash.",
        "createdAt" : "2020-05-19T08:00:32Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "60205f1f-21e4-4a20-9cb2-619f180f2d9c",
        "parentId" : "5bd045ef-50e2-4b17-9465-a5becc6331b3",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Unless I've made a horrible mistake somewhere, we should only enter this function if there is at least one release to build, so I decided otherwise crashing here would be the right thing to do.\r\n\r\nI guess technically this could run if we have removed a version, and then it would crash and not update the docs site to remove it. I'll have to think a bit more for a proper fix. I thought I could use this as a shortcut, but I guess I won't be able to avoid searching the git history for the latest release.",
        "createdAt" : "2020-05-19T09:58:23Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "8b7848bc-6043-4ba8-b997-785ec1ab8265",
        "parentId" : "5bd045ef-50e2-4b17-9465-a5becc6331b3",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Happy to keep it this way, maybe just add a comment why the `head` is safe.",
        "createdAt" : "2020-05-19T10:17:29Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "78998483-ba36-4230-90c0-ac8f74a42994",
        "parentId" : "5bd045ef-50e2-4b17-9465-a5becc6331b3",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Added a check.",
        "createdAt" : "2020-05-19T16:40:30Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "5f991d71059dcd0bad10906e5ddf2f510803c993",
    "line" : null,
    "diffHunk" : "@@ -159,21 +161,28 @@ build_docs_folder path versions latest = do\n                 then do\n                     putStrLn \"  Checks, reusing existing.\"\n                     copy (old </> version) $ new </> version\n-                    return $ Just gh_version\n+                    return $ Just (gh_version, False)\n                 else do\n                     putStrLn \"  Check failed. Rebuilding...\"\n-                    build version new\n-                    return $ Just gh_version\n+                    build version new latest_release_notes_sha\n+                    return $ Just (gh_version, True)\n             else do\n                 putStrLn \"  Not found. Building...\"\n-                build version new\n-                return $ Just gh_version)\n-        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n-        copy (new </> latest </> \"*\") (new <> \"/\")\n+                build version new latest_release_notes_sha\n+                return $ Just (gh_version, True))\n+        putStrLn $ \"Copying current (\" <> current <> \") to top-level...\"\n+        copy (new </> current </> \"*\") (new <> \"/\")\n         putStrLn \"Creating versions.json...\"\n-        let (releases, snapshots) = List.partition (not . prerelease) documented_versions\n-        create_versions_json releases (new </> \"versions.json\")\n-        create_versions_json snapshots (new </> \"snapshots.json\")\n+        let (releases, snapshots) = List.partition (not . prerelease . fst) documented_versions\n+        create_versions_json (map fst releases) (new </> \"versions.json\")\n+        create_versions_json (map fst snapshots) (new </> \"snapshots.json\")\n+        let newly_built = fst $ head $ filter snd documented_versions"
  },
  {
    "id" : "424bdec7-e844-469b-885d-2967f02c5c41",
    "prId" : 6016,
    "comments" : [
      {
        "id" : "919fefd9-9394-4278-987a-766a41d7eaad",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "“from the most recent release” isn’t quite right as far as I can tell. You take it from the state of `master` and then build the `.html` file of the release for which you do not have docs (in theory there could be more than one and then you’ll end up with a somewhat random one but there shouldn’t be a meaningful difference since the state of `master` is the same). Any reason why we are not using the release commit?",
        "createdAt" : "2020-05-19T08:03:01Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "87648164-63ce-40ec-80f9-83e9f463f33f",
        "parentId" : "919fefd9-9394-4278-987a-766a41d7eaad",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Under the (unverified, but so far true) assumption that we do not change the release notes file outside of a release cycle (and that if we do, then there is no release so this script will not run until there actually is a release), the latest commit that changes the release notes on master _is_ the release commit of the latest release. This could only be a different commit if we committed changes to the release notes file in-between merging a release commit to master and the cron job running. This could be actually useful for last-minute typo corrections I suppose.\r\n\r\nThis could be made slightly safer by pinning it to the LATEST file instead of the release notes one.",
        "createdAt" : "2020-05-19T10:04:55Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "3897c351-dee1-415c-806e-04707ef48545",
        "parentId" : "919fefd9-9394-4278-987a-766a41d7eaad",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "It’s not true if you look at https://github.com/digital-asset/daml/commits/master/docs/source/support/release-notes.rst. I don’t think we’ve changed it sufficiently quickly that it would matter but it can change.",
        "createdAt" : "2020-05-19T10:18:54Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "b5dd8dd7-6782-49cd-b80c-74f092a99760",
        "parentId" : "919fefd9-9394-4278-987a-766a41d7eaad",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Changed to check LATEST, which should be closer to the last release. I don't really want to duplicate the entire logic of determining whether that commit was a release commit, especially given that this only runs if a version was actually added to GitHub.",
        "createdAt" : "2020-05-19T16:44:19Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "5f991d71059dcd0bad10906e5ddf2f510803c993",
    "line" : 119,
    "diffHunk" : "@@ -207,25 +216,24 @@ build_docs_folder path versions latest = do\n             -- Starting after 0.13.54, we have changed the way in which we\n             -- trigger releases. Rather than releasing the current commit by\n             -- changing the VERSION file, we now mark an existing commit as the\n-            -- source code for a release by changing the LATEST file. However,\n-            -- release notes still need to be taken from the release commit\n-            -- (i.e. the one that changes the LATEST file, not the one being\n-            -- pointed to).\n+            -- source code for a release by changing the LATEST file. This\n+            -- raises the question of the release notes: as we tag a commit\n+            -- from the past, and keep the changelog outside of the worktree\n+            -- (in commit messages), that means that commit cannot contain its\n+            -- own release notes. We have decided to resolve that conundrum by"
  },
  {
    "id" : "c1f5f07f-0c9a-4b2d-bc46-e48f0df22985",
    "prId" : 6016,
    "comments" : [
      {
        "id" : "8d4fab24-2179-43b4-a241-d19da0395336",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Do you need a space here?\r\n\r\n```suggestion\r\n        shell_ $ \"cp \" <> p newly_built <> \" \" <> top_level_release_notes\r\n```",
        "createdAt" : "2020-05-19T08:23:05Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "aefc0a40-8326-4644-9d70-f1dfbf58e677",
        "parentId" : "8d4fab24-2179-43b4-a241-d19da0395336",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Yes, thanks!",
        "createdAt" : "2020-05-19T10:07:31Z",
        "updatedAt" : "2020-05-19T16:49:55Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "5f991d71059dcd0bad10906e5ddf2f510803c993",
    "line" : null,
    "diffHunk" : "@@ -159,21 +161,28 @@ build_docs_folder path versions latest = do\n                 then do\n                     putStrLn \"  Checks, reusing existing.\"\n                     copy (old </> version) $ new </> version\n-                    return $ Just gh_version\n+                    return $ Just (gh_version, False)\n                 else do\n                     putStrLn \"  Check failed. Rebuilding...\"\n-                    build version new\n-                    return $ Just gh_version\n+                    build version new latest_release_notes_sha\n+                    return $ Just (gh_version, True)\n             else do\n                 putStrLn \"  Not found. Building...\"\n-                build version new\n-                return $ Just gh_version)\n-        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n-        copy (new </> latest </> \"*\") (new <> \"/\")\n+                build version new latest_release_notes_sha\n+                return $ Just (gh_version, True))\n+        putStrLn $ \"Copying current (\" <> current <> \") to top-level...\"\n+        copy (new </> current </> \"*\") (new <> \"/\")\n         putStrLn \"Creating versions.json...\"\n-        let (releases, snapshots) = List.partition (not . prerelease) documented_versions\n-        create_versions_json releases (new </> \"versions.json\")\n-        create_versions_json snapshots (new </> \"snapshots.json\")\n+        let (releases, snapshots) = List.partition (not . prerelease . fst) documented_versions\n+        create_versions_json (map fst releases) (new </> \"versions.json\")\n+        create_versions_json (map fst snapshots) (new </> \"snapshots.json\")\n+        let newly_built = fst $ head $ filter snd documented_versions\n+        putStrLn $ \"Copying release notes from \" <> name newly_built <> \" to all other versions...\"\n+        let p v = new </> name v </> \"support\" </> \"release-notes.html\"\n+        let top_level_release_notes = new </> \"support\" </> \"release-notes.html\"\n+        shell_ $ \"cp \" <> p newly_built <> top_level_release_notes"
  },
  {
    "id" : "05f83d25-63c8-452d-a09c-5cd89ad3c72f",
    "prId" : 5584,
    "comments" : [
      {
        "id" : "84985836-45a5-40a5-8437-df547caa65d6",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Applying this to master as well doesn’t do any harm or at least not more harm than only applying it here right? It seems nicer to not have those go needlessly out of sync.",
        "createdAt" : "2020-04-16T15:18:13Z",
        "updatedAt" : "2020-04-16T15:18:25Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "2b9ce0bd-e8f1-4136-9e3e-33263ee2c625",
        "parentId" : "84985836-45a5-40a5-8437-df547caa65d6",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "This one is the master one.",
        "createdAt" : "2020-04-16T15:20:28Z",
        "updatedAt" : "2020-04-16T15:20:28Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "8fb57f9e-50c4-4c58-81ea-25f278cade95",
        "parentId" : "84985836-45a5-40a5-8437-df547caa65d6",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "branches are confusing :facepalm: my question still stands: can we apply this to both? if not, maybe worth adding a comment in the code?",
        "createdAt" : "2020-04-16T15:24:16Z",
        "updatedAt" : "2020-04-16T15:24:16Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "2ad265d2-96ed-4e4c-81f9-f51a4880e8d9",
        "parentId" : "84985836-45a5-40a5-8437-df547caa65d6",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "The Azure cron only runs the latest master commit, so there is little point in changing this code on the 1.0 release branch.\r\n\r\nThe whole point of release branches being that they get the absolute minimum amount of changes to fix bugs, I'm somewhat reluctant to change anything I don't absolutely have to over there.",
        "createdAt" : "2020-04-16T15:30:37Z",
        "updatedAt" : "2020-04-16T15:30:37Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "522622c1-8213-4124-a5db-dc844191ac05",
        "parentId" : "84985836-45a5-40a5-8437-df547caa65d6",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Oh makes sense, forgot that the cron job will always be based on master.",
        "createdAt" : "2020-04-16T15:48:01Z",
        "updatedAt" : "2020-04-16T15:48:01Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "5826d207fd2b3d9ba9c0f704e80c487466f1116e",
    "line" : 5,
    "diffHunk" : "@@ -240,7 +240,7 @@ build_docs_folder path versions latest = do\n \n find_commit_for_version :: String -> IO String\n find_commit_for_version version = do\n-    release_commits <- lines <$> shell \"git log --format=%H origin/master -- LATEST\"\n+    release_commits <- lines <$> shell \"git log --format=%H --branches='*' -- LATEST\""
  },
  {
    "id" : "cab8c6cc-07ad-4461-a188-f43116a64d19",
    "prId" : 4976,
    "comments" : [
      {
        "id" : "69cf888f-368b-424c-9381-2c9bdb546216",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I think this would be clearer if you first split the versions via `partition` instead of filtering twice once with the negated condition (and it’s faster but that’s hardly relevant here).",
        "createdAt" : "2020-03-12T18:21:42Z",
        "updatedAt" : "2020-03-12T18:29:29Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "97df6cb2-a3d4-46cf-b19e-74fdaba85190",
        "parentId" : "69cf888f-368b-424c-9381-2c9bdb546216",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Did not know about the partition function, will amend.",
        "createdAt" : "2020-03-12T18:26:32Z",
        "updatedAt" : "2020-03-12T18:29:29Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3fafcb2de8ca9728165057297c6cf92ba2b71489",
    "line" : null,
    "diffHunk" : "@@ -150,19 +159,20 @@ build_docs_folder path versions latest = do\n                 then do\n                     putStrLn \"  Checks, reusing existing.\"\n                     copy (old </> version) $ new </> version\n-                    return $ Just version\n+                    return $ Just gh_version\n                 else do\n                     putStrLn \"  Check failed. Rebuilding...\"\n                     build version new\n-                    return $ Just version\n+                    return $ Just gh_version\n             else do\n                 putStrLn \"  Not found. Building...\"\n                 build version new\n-                return $ Just version)\n+                return $ Just gh_version)\n         putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n         copy (new </> latest </> \"*\") (new <> \"/\")\n         putStrLn \"Creating versions.json...\"\n-        create_versions_json documented_versions new\n+        create_versions_json (filter (not . prerelease) documented_versions) (new </> \"versions.json\")"
  },
  {
    "id" : "97e8bb4c-5001-4ab2-82fe-717381a41067",
    "prId" : 4976,
    "comments" : [
      {
        "id" : "ea34eea6-88ae-48ff-b158-e71144545477",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Is `snapshots.json` used for anything atm or is this just preparation so we could use it in the future?",
        "createdAt" : "2020-03-12T18:21:59Z",
        "updatedAt" : "2020-03-12T18:29:29Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "658e0aa6-611d-4f0e-a230-37945dc8cfb3",
        "parentId" : "ea34eea6-88ae-48ff-b158-e71144545477",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "The script used to decide whether to run or not based on whether the most recent published release had changed. If we want to publish documentation for snapshot releases that won't work anymore.\r\n\r\nBecause we do not want prereleases in the drop-down, they cannot be in versions.json, but we still need to know which ones we have published already, so we need to keep track of them _somewhere_.\r\n\r\nWe also need to know, for each docs version we have built, whether we built it as prerelease or not, because if a version changes (we publish a stable release after this has run), we still need to rerun.\r\n\r\nThis is why we need this snapshots.json, and why it is fetched by `fetch_s3_versions`.",
        "createdAt" : "2020-03-12T18:35:58Z",
        "updatedAt" : "2020-03-12T18:35:58Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "64ea3a8d-6d22-4df0-b2f3-8a3340f883c1",
        "parentId" : "ea34eea6-88ae-48ff-b158-e71144545477",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Thanks for the explanation! Makes a lot of sense.",
        "createdAt" : "2020-03-12T18:37:10Z",
        "updatedAt" : "2020-03-12T18:37:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3fafcb2de8ca9728165057297c6cf92ba2b71489",
    "line" : null,
    "diffHunk" : "@@ -150,19 +159,20 @@ build_docs_folder path versions latest = do\n                 then do\n                     putStrLn \"  Checks, reusing existing.\"\n                     copy (old </> version) $ new </> version\n-                    return $ Just version\n+                    return $ Just gh_version\n                 else do\n                     putStrLn \"  Check failed. Rebuilding...\"\n                     build version new\n-                    return $ Just version\n+                    return $ Just gh_version\n             else do\n                 putStrLn \"  Not found. Building...\"\n                 build version new\n-                return $ Just version)\n+                return $ Just gh_version)\n         putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n         copy (new </> latest </> \"*\") (new <> \"/\")\n         putStrLn \"Creating versions.json...\"\n-        create_versions_json documented_versions new\n+        create_versions_json (filter (not . prerelease) documented_versions) (new </> \"versions.json\")\n+        create_versions_json (filter prerelease documented_versions) (new </> \"snapshots.json\")"
  },
  {
    "id" : "e44c2f87-f649-44d2-a79c-5ec299ccbcb7",
    "prId" : 4976,
    "comments" : [
      {
        "id" : "edb72579-5f12-4112-8ede-a81da8a5bd19",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I’m struggling to understand what changed to require this now. Can you help me out?",
        "createdAt" : "2020-03-12T18:23:10Z",
        "updatedAt" : "2020-03-12T18:29:29Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "d6f9a6a1-ef54-47be-b680-a7471f908cc6",
        "parentId" : "edb72579-5f12-4112-8ede-a81da8a5bd19",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "The \"main loop\" is now returning `[GitHubVersion]` instead of `[String]` because we need to track which ones are prereleases.",
        "createdAt" : "2020-03-12T18:35:29Z",
        "updatedAt" : "2020-03-12T18:36:59Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "d2b55761-5edb-44a9-9ea2-2ef30ad7af9e",
        "parentId" : "edb72579-5f12-4112-8ede-a81da8a5bd19",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : ":man_facepalming: Thanks for the explanation!",
        "createdAt" : "2020-03-12T18:36:58Z",
        "updatedAt" : "2020-03-12T18:36:58Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "f6e9c4f0-f6b8-419c-8483-0425b88b672e",
        "parentId" : "edb72579-5f12-4112-8ede-a81da8a5bd19",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I should probably type my subfunctions. It would have made the change much clearer, and @nickchapman-da would stop telling me to do it. I'll add type annotations next time I need to touch this script.",
        "createdAt" : "2020-03-12T18:38:21Z",
        "updatedAt" : "2020-03-12T18:38:22Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "050ec9a5-2a17-4ffa-bd49-84c6b52c859b",
        "parentId" : "edb72579-5f12-4112-8ede-a81da8a5bd19",
        "author" : {
          "login" : "nickchapman-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/49153372?v=4"
        },
        "body" : "Yeah. More types!",
        "createdAt" : "2020-03-16T09:12:51Z",
        "updatedAt" : "2020-03-16T09:12:51Z",
        "lastEditedBy" : {
          "login" : "nickchapman-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/49153372?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "3fafcb2de8ca9728165057297c6cf92ba2b71489",
    "line" : 121,
    "diffHunk" : "@@ -220,11 +230,12 @@ build_docs_folder path versions latest = do\n             -- Not going through Aeson because it represents JSON objects as\n             -- unordered maps, and here order matters.\n             let versions_json = versions\n+                                & map name"
  },
  {
    "id" : "fd5c19f2-d22c-42e1-bb5a-9ec81bdd1772",
    "prId" : 4513,
    "comments" : [
      {
        "id" : "c2dd8f6b-8011-4c25-85d7-a1250ebf86db",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "What part of this PR requires this now? Happy to have it either way, I just want to understand if this is required by other changes in this PR.",
        "createdAt" : "2020-02-19T10:01:39Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "e5967f50-9a4c-4293-a050-261fdb08676f",
        "parentId" : "c2dd8f6b-8011-4c25-85d7-a1250ebf86db",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "This is to undo the checkout of the release notes file. Maybe I should move that to be closer so it's more obvious.",
        "createdAt" : "2020-02-19T12:33:07Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "829bd1ce-59c9-4ccd-a596-9a1d866f326b",
        "parentId" : "c2dd8f6b-8011-4c25-85d7-a1250ebf86db",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "or just add a comment.",
        "createdAt" : "2020-02-19T15:13:56Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "35dbf572-b744-40ec-ad96-6559466d4858",
        "parentId" : "c2dd8f6b-8011-4c25-85d7-a1250ebf86db",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I've restructured the code around this such that the `git checkout` and the corresponding `git reset` are part of the same `bracket` call, which should hopefully make it clear.",
        "createdAt" : "2020-02-24T19:05:17Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "81246bd2733ace93653cb663dca5a0cdaf7c11e9",
    "line" : null,
    "diffHunk" : "@@ -203,13 +203,29 @@ build_docs_folder path versions latest = do\n             shell_ $ \"cp -r \" <> from <> \" \" <> to\n         build version path = do\n             shell_ $ \"git checkout v\" <> version\n+            shell_ \"git reset --hard\""
  },
  {
    "id" : "b7468640-6ca6-405a-b8f3-ddcad133fbf8",
    "prId" : 4513,
    "comments" : [
      {
        "id" : "087c5a88-d431-4bf1-814a-c82bd1b69fbc",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Only checking out new release notes sounds dangerous. What if the release notes have a link to a section somewhere else that does not exist if you only checkout the release notes for this commit?",
        "createdAt" : "2020-02-19T10:03:25Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "3c6575b4-4ce1-487e-b66c-9bf86af76f14",
        "parentId" : "087c5a88-d431-4bf1-814a-c82bd1b69fbc",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "The idea is that, when making the release, you have taken the release notes up to the source commit and put that in the release commit. So that should work out, as the release notes in the release commit are really as of the source commit and therefore cannot have references to things that came out after it.",
        "createdAt" : "2020-02-19T12:35:28Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "6db781cc-28dd-4722-a2ca-429ade4e4768",
        "parentId" : "087c5a88-d431-4bf1-814a-c82bd1b69fbc",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I get the intention what I’m a bit worried about is that this is not what `bazel build //docs` checks. But I’m fine with this for now.",
        "createdAt" : "2020-02-19T15:15:50Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "5ece46ab-c6fa-46f7-b802-5c9d8b73c749",
        "parentId" : "087c5a88-d431-4bf1-814a-c82bd1b69fbc",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I'm happy to consider any suggestion on how to improve this, but I can't see any way out of it myself.",
        "createdAt" : "2020-02-24T19:02:18Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "81246bd2733ace93653cb663dca5a0cdaf7c11e9",
    "line" : null,
    "diffHunk" : "@@ -203,13 +203,29 @@ build_docs_folder path versions latest = do\n             shell_ $ \"cp -r \" <> from <> \" \" <> to\n         build version path = do\n             shell_ $ \"git checkout v\" <> version\n+            shell_ \"git reset --hard\"\n             -- Maven does not accept http connections anymore; this patches the\n             -- scala rules for Bazel to use https instead. This is not needed\n             -- after 0.13.43.\n             if to_v version < to_v \"0.13.44\"\n             then do\n                 shell_ \"git -c user.name=CI -c user.email=CI@example.com cherry-pick 0c4f9d7f92c4f2f7e2a75a0d85db02e20cbb497b\"\n             else pure ()\n+            -- Starting with 0.13.54, we have changed the way in which we\n+            -- trigger releases. Rather than releasing the current commit by\n+            -- changing the VERSION file, we now mark an existing commit as the\n+            -- source code for a release by changing the LATEST file. However,\n+            -- release notes still need to be taken from the release commit\n+            -- (i.e. the one that changes the LATEST file, not the one being\n+            -- pointed to).\n+            if to_v version > to_v \"0.13.53\"\n+            then do\n+                -- The release-triggering commit does not have a tag, so we\n+                -- need to find it by walking through the git history of the\n+                -- LATEST file.\n+                sha <- find_commit_for_version version\n+                shell_ $ \"git checkout \" <> sha <> \" -- docs/source/support/release-notes.rst\""
  },
  {
    "id" : "5c0de1a5-f7ea-4895-85a7-8381b889523d",
    "prId" : 4513,
    "comments" : [
      {
        "id" : "ec75574c-fc13-419d-8d43-9a719d9703c6",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Before merging this we should check this again.",
        "createdAt" : "2020-02-19T10:06:46Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "e57f6c6f-730c-4699-b5ca-20f6a196fb6b",
        "parentId" : "ec75574c-fc13-419d-8d43-9a719d9703c6",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Yes, definitely.",
        "createdAt" : "2020-02-19T12:33:39Z",
        "updatedAt" : "2020-02-25T14:08:02Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "81246bd2733ace93653cb663dca5a0cdaf7c11e9",
    "line" : null,
    "diffHunk" : "@@ -203,13 +203,29 @@ build_docs_folder path versions latest = do\n             shell_ $ \"cp -r \" <> from <> \" \" <> to\n         build version path = do\n             shell_ $ \"git checkout v\" <> version\n+            shell_ \"git reset --hard\"\n             -- Maven does not accept http connections anymore; this patches the\n             -- scala rules for Bazel to use https instead. This is not needed\n             -- after 0.13.43.\n             if to_v version < to_v \"0.13.44\"\n             then do\n                 shell_ \"git -c user.name=CI -c user.email=CI@example.com cherry-pick 0c4f9d7f92c4f2f7e2a75a0d85db02e20cbb497b\"\n             else pure ()\n+            -- Starting with 0.13.54, we have changed the way in which we\n+            -- trigger releases. Rather than releasing the current commit by\n+            -- changing the VERSION file, we now mark an existing commit as the\n+            -- source code for a release by changing the LATEST file. However,\n+            -- release notes still need to be taken from the release commit\n+            -- (i.e. the one that changes the LATEST file, not the one being\n+            -- pointed to).\n+            if to_v version > to_v \"0.13.53\""
  },
  {
    "id" : "d65daf1e-3386-4310-9fc1-36f5ad41ea00",
    "prId" : 4123,
    "comments" : [
      {
        "id" : "5fada32c-8e94-468c-8c4c-af42ea27ed1c",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "```suggestion\r\n    if prev_latest == to_v (name gh_latest)\r\n```",
        "createdAt" : "2020-01-21T10:46:57Z",
        "updatedAt" : "2020-01-21T11:30:25Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "1106988861f94eb12d169c6f17adbb492269ab47",
    "line" : null,
    "diffHunk" : "@@ -344,7 +350,8 @@ main = do\n     putStrLn \"Checking for new version...\"\n     (gh_versions, gh_latest) <- fetch_gh_versions\n     s3_versions_before <- fetch_s3_versions\n-    if s3_versions_before == gh_versions\n+    let prev_latest = List.maximum $ Set.toList s3_versions_before\n+    if prev_latest == (to_v $ name gh_latest)"
  },
  {
    "id" : "93e66b2b-04f5-4909-90d6-213c6f6341d4",
    "prId" : 4115,
    "comments" : [
      {
        "id" : "a15f1b0d-cf5a-42f2-a23b-fcbb16e24c97",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n      (200, Just body) -> return (body, response & HTTP.responseHeaders & map (\\(n, v) -> (n & CI.foldedCase & BS.toString, BS.toString v)) & Map.fromList)\r\n```",
        "createdAt" : "2020-01-20T15:59:54Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "2a0d2f33-237f-497b-9753-85dd90805242",
        "parentId" : "a15f1b0d-cf5a-42f2-a23b-fcbb16e24c97",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Not sure how I missed that in the docs. I do remember specifically looking for it. Thanks!",
        "createdAt" : "2020-01-20T16:49:45Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2509981f093277864ac664b385dad4a97aa5f8fb",
    "line" : null,
    "diffHunk" : "@@ -82,7 +85,7 @@ http_get url = do\n     let body = JSON.decode $ HTTP.responseBody response\n     let status = Status.statusCode $ HTTP.responseStatus response\n     case (status, body) of\n-      (200, Just body) -> return body\n+      (200, Just body) -> return (body, response & HTTP.responseHeaders & map (\\(n, v) -> (n & CI.foldedCase & BS.toString, BS.toString v)) & foldl (\\m (k,v) -> Map.insert k v m) Map.empty)"
  },
  {
    "id" : "36707948-a1e1-4fcd-a1fd-967f834c62f1",
    "prId" : 4115,
    "comments" : [
      {
        "id" : "d6e468f8-3975-4167-a8f7-b564dd0d2d6e",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    case parse_next =<< Map.lookup \"link\" headers of\r\n```",
        "createdAt" : "2020-01-20T16:01:01Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "29828b1e-53a9-439a-ac8d-7d6e133d7c06",
        "parentId" : "d6e468f8-3975-4167-a8f7-b564dd0d2d6e",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "🤔 ",
        "createdAt" : "2020-01-20T16:52:53Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2509981f093277864ac664b385dad4a97aa5f8fb",
    "line" : null,
    "diffHunk" : "@@ -308,9 +311,32 @@ instance JSON.FromJSON GitHubVersion where\n name :: GitHubVersion -> String\n name gh = tail $ tag_name gh\n \n+fetch_gh_paginated :: JSON.FromJSON a => String -> IO [a]\n+fetch_gh_paginated url = do\n+    (resp_0, headers) <- http_get url\n+    case parse_next $ Map.lookup \"link\" headers of"
  },
  {
    "id" : "899e1fc2-e00e-4ef3-bec3-a7b3ad5c5f66",
    "prId" : 4115,
    "comments" : [
      {
        "id" : "24184c2e-b571-401f-8347-87fb7fef692e",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n          parse_next header = take_next $ concatMap parse_link $ split header\r\n```",
        "createdAt" : "2020-01-20T16:01:15Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "40c38d0e-ab1d-4094-a305-813a939fbe2e",
        "parentId" : "24184c2e-b571-401f-8347-87fb7fef692e",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Oh, nice! Thanks for that.",
        "createdAt" : "2020-01-20T16:53:03Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2509981f093277864ac664b385dad4a97aa5f8fb",
    "line" : null,
    "diffHunk" : "@@ -308,9 +311,32 @@ instance JSON.FromJSON GitHubVersion where\n name :: GitHubVersion -> String\n name gh = tail $ tag_name gh\n \n+fetch_gh_paginated :: JSON.FromJSON a => String -> IO [a]\n+fetch_gh_paginated url = do\n+    (resp_0, headers) <- http_get url\n+    case parse_next $ Map.lookup \"link\" headers of\n+      Nothing -> return resp_0\n+      Just next -> do\n+          rest <- fetch_gh_paginated next\n+          return $ resp_0 ++ rest\n+    where parse_next Nothing = Nothing\n+          parse_next (Just header) = take_next $ concatMap parse_link $ split header"
  },
  {
    "id" : "4e0cd95a-7b20-45ed-8e59-b88627e3b5aa",
    "prId" : 4115,
    "comments" : [
      {
        "id" : "508777bd-7893-4866-aeb9-7ad1b25d584a",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    where\r\n```",
        "createdAt" : "2020-01-20T16:01:24Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2509981f093277864ac664b385dad4a97aa5f8fb",
    "line" : null,
    "diffHunk" : "@@ -308,9 +311,32 @@ instance JSON.FromJSON GitHubVersion where\n name :: GitHubVersion -> String\n name gh = tail $ tag_name gh\n \n+fetch_gh_paginated :: JSON.FromJSON a => String -> IO [a]\n+fetch_gh_paginated url = do\n+    (resp_0, headers) <- http_get url\n+    case parse_next $ Map.lookup \"link\" headers of\n+      Nothing -> return resp_0\n+      Just next -> do\n+          rest <- fetch_gh_paginated next\n+          return $ resp_0 ++ rest\n+    where parse_next Nothing = Nothing"
  },
  {
    "id" : "4485c7f0-7288-4907-a8d2-2c063add0810",
    "prId" : 4115,
    "comments" : [
      {
        "id" : "94d921c9-adbb-492e-a048-1d298d8f94df",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "`take_next = lookup \"next\"",
        "createdAt" : "2020-01-20T16:07:55Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "2a3190d7-7c6f-429b-a77a-2dd1960bc09b",
        "parentId" : "94d921c9-adbb-492e-a048-1d298d8f94df",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Thanks, did not know about that one.",
        "createdAt" : "2020-01-20T16:54:18Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2509981f093277864ac664b385dad4a97aa5f8fb",
    "line" : null,
    "diffHunk" : "@@ -308,9 +311,32 @@ instance JSON.FromJSON GitHubVersion where\n name :: GitHubVersion -> String\n name gh = tail $ tag_name gh\n \n+fetch_gh_paginated :: JSON.FromJSON a => String -> IO [a]\n+fetch_gh_paginated url = do\n+    (resp_0, headers) <- http_get url\n+    case parse_next $ Map.lookup \"link\" headers of\n+      Nothing -> return resp_0\n+      Just next -> do\n+          rest <- fetch_gh_paginated next\n+          return $ resp_0 ++ rest\n+    where parse_next Nothing = Nothing\n+          parse_next (Just header) = take_next $ concatMap parse_link $ split header\n+          split h = Split.splitOn \", \" h\n+          link_regex = \"<(.*)>; rel=\\\"(.*)\\\"\" :: String\n+          parse_link l =\n+              let typed_regex :: (String, String, String, [String])\n+                  typed_regex = l Regex.=~ link_regex\n+              in\n+              case typed_regex of\n+                (_, _, _, [url, rel]) -> [(rel, url)]\n+                _ -> []\n+          take_next [] = Nothing"
  },
  {
    "id" : "789eea51-8619-44c8-b743-460faa97ff79",
    "prId" : 4115,
    "comments" : [
      {
        "id" : "59c35e60-5675-4982-a811-2f13b7df5c49",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "When do we expect to fall into this case? If the answer is “never”, maybe calling “error” would be better so we know if this fails?",
        "createdAt" : "2020-01-20T16:11:51Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "26550b3d-ec39-4223-9232-8ecc3c1ad5ce",
        "parentId" : "59c35e60-5675-4982-a811-2f13b7df5c49",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I'm actually not sure; the RFC allows for more attributes than `rel`, but I haven't seen any other in GH examples. They do not document their use of the format, that I could find. I guess you're right on the fact that it's better if we get told when that assumption gets invalidated.",
        "createdAt" : "2020-01-20T17:07:36Z",
        "updatedAt" : "2020-01-20T17:12:35Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "2509981f093277864ac664b385dad4a97aa5f8fb",
    "line" : null,
    "diffHunk" : "@@ -308,9 +311,32 @@ instance JSON.FromJSON GitHubVersion where\n name :: GitHubVersion -> String\n name gh = tail $ tag_name gh\n \n+fetch_gh_paginated :: JSON.FromJSON a => String -> IO [a]\n+fetch_gh_paginated url = do\n+    (resp_0, headers) <- http_get url\n+    case parse_next $ Map.lookup \"link\" headers of\n+      Nothing -> return resp_0\n+      Just next -> do\n+          rest <- fetch_gh_paginated next\n+          return $ resp_0 ++ rest\n+    where parse_next Nothing = Nothing\n+          parse_next (Just header) = take_next $ concatMap parse_link $ split header\n+          split h = Split.splitOn \", \" h\n+          link_regex = \"<(.*)>; rel=\\\"(.*)\\\"\" :: String\n+          parse_link l =\n+              let typed_regex :: (String, String, String, [String])\n+                  typed_regex = l Regex.=~ link_regex\n+              in\n+              case typed_regex of\n+                (_, _, _, [url, rel]) -> [(rel, url)]\n+                _ -> []"
  },
  {
    "id" : "dfee0620-c2fd-4161-9dea-13d666689046",
    "prId" : 4058,
    "comments" : [
      {
        "id" : "2a5b1ebe-13e4-486c-bdfb-73cdb8d78995",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Maybe it would make more sense to just do a `git cherry-pick` of https://github.com/digital-asset/daml/commit/0c4f9d7f92c4f2f7e2a75a0d85db02e20cbb497b? That should be faster (not that this matters much given that we only build it once) but more importantly it should work regardless of what Bazel does wtr to caching. The obvious downside is that the docs are not build from the actual release commit but for this particular change this seems acceptable especially given that all the artifacts have hashes afaik so if the URL change resulted in unrelated changes the build would fail.",
        "createdAt" : "2020-01-15T19:06:20Z",
        "updatedAt" : "2020-01-15T20:17:54Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "986e6c9fa08a1574eac563d6f996b07517d81a3b",
    "line" : null,
    "diffHunk" : "@@ -168,6 +168,14 @@ build_docs_folder path versions latest = do\n         copy from to = do\n             shell_ $ \"cp -r \" <> from <> \" \" <> to\n         build version path = do\n+            case version of\n+              \"0.13.43\" -> do\n+                  shell_ \"git checkout 0c4f9d7f92c4f2f7e2a75a0d85db02e20cbb497b\""
  },
  {
    "id" : "a84d50bb-98c6-4ac1-a270-68396b03449a",
    "prId" : 4058,
    "comments" : [
      {
        "id" : "740e13a8-f184-478d-9ef2-f94ed65fd522",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Also we should add a comment that explains why we need this. I’m definitely going to forget this :slightly_smiling_face: ",
        "createdAt" : "2020-01-15T19:06:48Z",
        "updatedAt" : "2020-01-15T20:17:54Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "986e6c9fa08a1574eac563d6f996b07517d81a3b",
    "line" : null,
    "diffHunk" : "@@ -168,6 +168,14 @@ build_docs_folder path versions latest = do\n         copy from to = do\n             shell_ $ \"cp -r \" <> from <> \" \" <> to\n         build version path = do\n+            case version of\n+              \"0.13.43\" -> do\n+                  shell_ \"git checkout 0c4f9d7f92c4f2f7e2a75a0d85db02e20cbb497b\"\n+                  robustly_download_nix_packages"
  },
  {
    "id" : "85da3882-0e1f-4614-a231-466da1168757",
    "prId" : 4058,
    "comments" : [
      {
        "id" : "01f74514-ee96-4496-b204-146bb98453e5",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Would be good to also add a comment here.",
        "createdAt" : "2020-01-15T19:43:29Z",
        "updatedAt" : "2020-01-15T20:17:54Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "986e6c9fa08a1574eac563d6f996b07517d81a3b",
    "line" : null,
    "diffHunk" : "@@ -131,9 +131,9 @@ build_docs_folder path versions latest = do\n                 -- checksums from the s3 bucket.\n                 putStrLn \"  Found. Checking integrity...\"\n                 checksums_match <- checksums old version\n-                if checksums_match\n+                if checksums_match || (to_v version < to_v \"0.13.36\")"
  },
  {
    "id" : "1394da6a-8679-4c4c-a8e1-3c4a189af0ce",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "92eecb8e-f07f-4e35-861b-d4516ab08b2a",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "You probably want to use `bracket` here to restore the old sha in the case of an exception. Not super important here probably since you will just crash the whole program but it’s generally good practice and imho also makes the intent clearer.",
        "createdAt" : "2020-01-03T15:28:57Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "a18de1ca-e1a2-4918-ae89-248705b1f28f",
        "parentId" : "92eecb8e-f07f-4e35-861b-d4516ab08b2a",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Thanks, I did not know about bracket. I assume that's `Control.Exception.bracket`?",
        "createdAt" : "2020-01-03T16:49:28Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "af97c3ad-0af8-400f-a392-093269fc8a76",
        "parentId" : "92eecb8e-f07f-4e35-861b-d4516ab08b2a",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "exactly!",
        "createdAt" : "2020-01-03T16:49:58Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\""
  },
  {
    "id" : "178c899e-c079-493e-aaa3-8516177cf070",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "f30374a5-f696-49f7-a66f-e50621160b9d",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            dir_exists <- Directory.doesDirectoryExist $ dir </> name\r\n```",
        "createdAt" : "2020-01-03T15:30:40Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "d7872349-99f5-44d6-886c-615f90a8c05c",
        "parentId" : "f30374a5-f696-49f7-a66f-e50621160b9d",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "`</>` seems dangerous:\r\n```\r\n\"home\" </> \"/bob\" == \"/bob\"\r\n```\r\nbut I'll trust you on this.",
        "createdAt" : "2020-01-03T16:50:16Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "2691af7e-7742-4fe2-870e-4138bfa7c2be",
        "parentId" : "f30374a5-f696-49f7-a66f-e50621160b9d",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Yeah, I don’t like that behavior. I would much rather have it crash in that case. But I think the readability benefits of being able to easily spot where you are appending file paths and where you are just manipulating strings outweigh the downsides here.",
        "createdAt" : "2020-01-03T17:05:47Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name"
  },
  {
    "id" : "9beb76be-4291-4f0c-9aa5-9b2131e9c860",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "bc04768b-2773-4cbd-aeec-e28bc51f5a5c",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            dir_has_checksum_file <- Directory.doesFileExist $ dir </> name </> \"checksum\"\r\n```",
        "createdAt" : "2020-01-03T15:31:01Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\""
  },
  {
    "id" : "034e4448-8ca9-40b8-abec-5dc7143a95cc",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "c413acb0-6c13-44e3-937f-43ba4a5ed1d0",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n        copy (new </> latest </> \"*\") (new <> \"/\")\r\n```",
        "createdAt" : "2020-01-03T15:34:04Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")"
  },
  {
    "id" : "3910302b-3592-4d12-8acb-edf84768a818",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "b9b7b12d-b95d-4861-aa63-52b2693ce206",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Order-sensitive JSON maps seem quite unintuitive to me. Can we use an array of key-value pairs instead?",
        "createdAt" : "2020-01-03T15:36:20Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "dc59bb22-021c-40ef-a525-dfc87fbff39b",
        "parentId" : "b9b7b12d-b95d-4861-aa63-52b2693ce206",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "It's the js bit on the website that is order-sensitive in its JSON parsing. I'm not a big fan either, but I don't have a viable plan for changing that without breaking all the past docs.\r\n\r\nFun fact: we only need an ordered list of versions, so a list of strings would work here, we don't even need it to be pairs.",
        "createdAt" : "2020-01-03T17:32:54Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : 121,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\"\n+            return $ dir_exists && dir_has_checksum_file\n+        checksums path version = do\n+            let cmd = \"cd \" <> path <> \"/\" <> version <> \"; sha256sum -c checksum\"\n+            (code, _, _) <- shell_exit_code cmd\n+            case code of\n+                Exit.ExitSuccess -> return True\n+                _ -> return False\n+        copy from to = do\n+            shell_ $ \"cp -r \" <> from <> \" \" <> to\n+        build version path = do\n+            shell_ $ \"git checkout v\" <> version\n+            robustly_download_nix_packages\n+            shell_ \"bazel build //docs:docs\"\n+            shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n+            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n+            checksums <- shell $ \"cd \" <> path <> \"/\" <> version <> \"; find . -type f -exec sha256sum {} \\\\;\"\n+            writeFile (path <> \"/\" <> version <> \"/checksum\") checksums\n+        create_versions_json versions path = do\n+            -- Not going through Aeson because it represents JSON objects as\n+            -- unordered maps, and here order matters.\n+            let versions_json = versions"
  },
  {
    "id" : "2a37733d-aea3-44a7-9658-e850e7f96be4",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "e51a54f8-9865-48ff-9219-4af5f3dfe79d",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            let cmd = \"cd \" <> path </> version <> \"; sha256sum -c checksum\"\r\n```",
        "createdAt" : "2020-01-03T15:37:05Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\"\n+            return $ dir_exists && dir_has_checksum_file\n+        checksums path version = do\n+            let cmd = \"cd \" <> path <> \"/\" <> version <> \"; sha256sum -c checksum\""
  },
  {
    "id" : "d8fd36b7-9209-4c04-abed-7b6a8c2d1e67",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "aee46a2d-ca4a-49f9-8798-3dac37b0f24e",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            shell_ $ \"mkdir -p  \" <> path </> version\r\n```",
        "createdAt" : "2020-01-03T15:38:09Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\"\n+            return $ dir_exists && dir_has_checksum_file\n+        checksums path version = do\n+            let cmd = \"cd \" <> path <> \"/\" <> version <> \"; sha256sum -c checksum\"\n+            (code, _, _) <- shell_exit_code cmd\n+            case code of\n+                Exit.ExitSuccess -> return True\n+                _ -> return False\n+        copy from to = do\n+            shell_ $ \"cp -r \" <> from <> \" \" <> to\n+        build version path = do\n+            shell_ $ \"git checkout v\" <> version\n+            robustly_download_nix_packages\n+            shell_ \"bazel build //docs:docs\"\n+            shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version"
  },
  {
    "id" : "b154282b-106a-4e2e-9b77-3c614bc8c3f6",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "c5d48627-ab19-45d0-a1f6-0f69a4f88623",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path </> version\r\n```",
        "createdAt" : "2020-01-03T15:38:21Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\"\n+            return $ dir_exists && dir_has_checksum_file\n+        checksums path version = do\n+            let cmd = \"cd \" <> path <> \"/\" <> version <> \"; sha256sum -c checksum\"\n+            (code, _, _) <- shell_exit_code cmd\n+            case code of\n+                Exit.ExitSuccess -> return True\n+                _ -> return False\n+        copy from to = do\n+            shell_ $ \"cp -r \" <> from <> \" \" <> to\n+        build version path = do\n+            shell_ $ \"git checkout v\" <> version\n+            robustly_download_nix_packages\n+            shell_ \"bazel build //docs:docs\"\n+            shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n+            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version"
  },
  {
    "id" : "b8cb858d-d61f-4cd7-bd09-a9e55a5f5477",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "62ce0c1f-cfee-4b2b-a73f-725054955c8b",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            checksums <- shell $ \"cd \" <> path </> version <> \"; find . -type f -exec sha256sum {} \\\\;\"\r\n```",
        "createdAt" : "2020-01-03T15:38:34Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\"\n+            return $ dir_exists && dir_has_checksum_file\n+        checksums path version = do\n+            let cmd = \"cd \" <> path <> \"/\" <> version <> \"; sha256sum -c checksum\"\n+            (code, _, _) <- shell_exit_code cmd\n+            case code of\n+                Exit.ExitSuccess -> return True\n+                _ -> return False\n+        copy from to = do\n+            shell_ $ \"cp -r \" <> from <> \" \" <> to\n+        build version path = do\n+            shell_ $ \"git checkout v\" <> version\n+            robustly_download_nix_packages\n+            shell_ \"bazel build //docs:docs\"\n+            shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n+            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n+            checksums <- shell $ \"cd \" <> path <> \"/\" <> version <> \"; find . -type f -exec sha256sum {} \\\\;\""
  },
  {
    "id" : "20495ee5-b6ad-4128-9fca-79156a14410e",
    "prId" : 3944,
    "comments" : [
      {
        "id" : "43b140c6-2745-4cf1-9793-b959a6d4fa7d",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n            writeFile (path </> \"versions.json\") versions_json\r\n```",
        "createdAt" : "2020-01-03T15:39:48Z",
        "updatedAt" : "2020-01-08T11:38:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "bf786c0d63f033042cf2f5196bb5ac6f5b24d5d1",
    "line" : null,
    "diffHunk" : "@@ -113,34 +113,77 @@ to_v s = case map read $ Split.splitOn \".\" s of\n     [major, minor, patch] -> Version (major, minor, patch)\n     _ -> error $ \"Invalid data, needs manual repair. Got this for a version string: \" <> s\n \n-build_docs_folder :: String -> [String] -> IO ()\n-build_docs_folder path versions = do\n-    out <- shell \"git rev-parse HEAD\"\n-    let cur_sha = init out -- remove ending newline\n-    shell_ $ \"mkdir -p \" <> path\n-    let latest = head versions\n-    putStrLn $ \"Building latest docs: \" <> latest\n-    shell_ $ \"git checkout v\" <> latest\n-    robustly_download_nix_packages\n-    shell_ \"bazel build //docs:docs\"\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path\n-    -- Not going through Aeson because it represents JSON objects as unordered\n-    -- maps, and here order matters.\n-    let versions_json = versions\n-                        & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n-                        & \\s -> \"{\" <> s <> \"}\"\n-    writeFile (path <> \"/versions.json\") versions_json\n-    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n-    shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n-    Foldable.for_ (tail versions) $ \\version -> do\n-        putStrLn $ \"Building older docs: \" <> version\n-        shell_ $ \"git checkout v\" <> version\n-        robustly_download_nix_packages\n-        shell_ \"bazel build //docs:docs\"\n-        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n-        shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n-    shell_ $ \"git checkout \" <> cur_sha\n+build_docs_folder :: String -> [String] -> String -> IO String\n+build_docs_folder path versions latest = do\n+    restore_sha $ do\n+        let old = path <> \"/old\"\n+        let new = path <> \"/new\"\n+        download_existing_site_from_s3 old\n+        Foldable.for_ versions $ \\version -> do\n+            putStrLn $ \"Building \" <> version <> \"...\"\n+            putStrLn \"  Checking for existing folder...\"\n+            old_version_exists <- exists old version\n+            if old_version_exists\n+            then do\n+                -- Note: this checks for upload errors; this is NOT in any way\n+                -- a protection against tampering at the s3 level as we get the\n+                -- checksums from the s3 bucket.\n+                putStrLn \"  Found. Checking integrity...\"\n+                checksums_match <- checksums old version\n+                if checksums_match\n+                then do\n+                    putStrLn \"  Checks, reusing existing.\"\n+                    copy (old <> \"/\" <> version) $ new <> \"/\" <> version\n+                else do\n+                    putStrLn \"  Check failed. Rebuilding...\"\n+                    build version new\n+            else do\n+                putStrLn \"  Not found. Building...\"\n+                build version new\n+            putStrLn $ \"Done \" <> version <> \".\"\n+        putStrLn $ \"Copying latest (\" <> latest <> \") to top-level...\"\n+        copy (new <> \"/\" <> latest <> \"/*\") (new <> \"/\")\n+        putStrLn \"Creating versions.json...\"\n+        create_versions_json versions new\n+        return new\n+    where\n+        restore_sha io = do\n+            cur_sha <- init <$> shell \"git rev-parse HEAD\"\n+            result <- io\n+            shell_ $ \"git checkout \" <> cur_sha\n+            return result\n+        download_existing_site_from_s3 path = do\n+            shell_ $ \"mkdir -p \" <> path\n+            shell_ $ \"aws s3 sync s3://docs-daml-com/ \" <> path\n+        exists dir name = do\n+            dir_exists <- Directory.doesDirectoryExist $ dir <> \"/\" <> name\n+            dir_has_checksum_file <- Directory.doesFileExist $ dir <> \"/\" <> name <> \"/checksum\"\n+            return $ dir_exists && dir_has_checksum_file\n+        checksums path version = do\n+            let cmd = \"cd \" <> path <> \"/\" <> version <> \"; sha256sum -c checksum\"\n+            (code, _, _) <- shell_exit_code cmd\n+            case code of\n+                Exit.ExitSuccess -> return True\n+                _ -> return False\n+        copy from to = do\n+            shell_ $ \"cp -r \" <> from <> \" \" <> to\n+        build version path = do\n+            shell_ $ \"git checkout v\" <> version\n+            robustly_download_nix_packages\n+            shell_ \"bazel build //docs:docs\"\n+            shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n+            shell_ $ \"tar xzf bazel-bin/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n+            checksums <- shell $ \"cd \" <> path <> \"/\" <> version <> \"; find . -type f -exec sha256sum {} \\\\;\"\n+            writeFile (path <> \"/\" <> version <> \"/checksum\") checksums\n+        create_versions_json versions path = do\n+            -- Not going through Aeson because it represents JSON objects as\n+            -- unordered maps, and here order matters.\n+            let versions_json = versions\n+                                & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n+                                & List.join \", \"\n+                                & \\s -> \"{\" <> s <> \"}\"\n+            writeFile (path <> \"/versions.json\") versions_json"
  },
  {
    "id" : "6c1205f3-fb87-424e-95b7-7d149245cb76",
    "prId" : 3943,
    "comments" : [
      {
        "id" : "79408589-abcc-48db-b0fc-2af1dcd74aaa",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I removed the dependency on `MissingH` since we already depend on enough other kitchen sink libraries and it doesn’t buy us anything.",
        "createdAt" : "2020-01-03T16:27:26Z",
        "updatedAt" : "2020-01-04T00:29:01Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "2ee4b31ae031ed1c21e1110225732a5c520aa53c",
    "line" : 13,
    "diffHunk" : "@@ -128,7 +127,7 @@ build_docs_folder path versions = do\n     -- maps, and here order matters.\n     let versions_json = versions\n                         & map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n-                        & List.join \", \"\n+                        & List.intercalate \", \""
  },
  {
    "id" : "ca9fdd54-a8cd-4135-a165-375e4d2196da",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "368fcd62-bc0f-4882-8090-90af3f1b171b",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Newtypes around tuples are usually not very useful. Either just make it a proper datatype, i..e, `data Version = Version Int Int Int` or use the tuple.",
        "createdAt" : "2019-10-28T19:05:22Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : 20,
    "diffHunk" : "@@ -106,11 +107,13 @@ docs_versions :: H.HashMap String String -> Set.Set String\n docs_versions json =\n     Set.fromList $ H.keys json\n \n-compare_versions :: GitHubVersion -> GitHubVersion -> Ordering\n-compare_versions v1 v2 =\n-    let t :: GitHubVersion -> [Integer]\n-        t v = map read $ Split.splitOn \".\" $ name v\n-    in compare (t v1) (t v2)\n+newtype Version = Version (Int, Int, Int)"
  },
  {
    "id" : "234aad1f-52e2-4a3e-a04e-dc87a21870b3",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "51109da6-86b7-498c-aba8-ce43696e0923",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Do you know that `gh_resp` will be non-empty? Otherwise `maximumBy` will crash.",
        "createdAt" : "2019-10-28T19:06:22Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "22fc8eba-9dc2-4adb-90a9-6e1e79a0a8fa",
        "parentId" : "51109da6-86b7-498c-aba8-ce43696e0923",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "We sort `gh_resp` above in descending order. The maximum will be at the head of this list.",
        "createdAt" : "2019-10-28T19:21:09Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "06e73887-8b68-4d4b-a7e2-7fb27102e90c",
        "parentId" : "51109da6-86b7-498c-aba8-ce43696e0923",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I'm fine with the script crashing if it is empty. That would mean something is really wrong and requires manual fixing.",
        "createdAt" : "2019-10-29T12:36:33Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "7887510d-d1a0-46b6-9d14-8b40dded5626",
        "parentId" : "51109da6-86b7-498c-aba8-ce43696e0923",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "> We sort gh_resp above in descending order. The maximum will be at the head of this list.\r\n\r\nAs written, that sorted list is not saved (and is a list of strings, whereas here I want the full data objects).",
        "createdAt" : "2019-10-29T12:41:00Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : null,
    "diffHunk" : "@@ -243,5 +246,11 @@ main = do\n                 Exit.exitSuccess\n             else do\n                 push_to_s3 docs_folder\n-                let latest = Foldable.maximumBy compare_versions gh_resp\n-                tell_hubspot latest\n+                let gh_latest = Foldable.maximumBy (compare `Function.on` to_v . name) gh_resp"
  },
  {
    "id" : "33e0f6a8-f556-44f8-9c1b-7a3c48c1bd0e",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "be2e7c6c-39c9-4016-b5a6-afed10a6d3a2",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Same question for `docs_resp`.",
        "createdAt" : "2019-10-28T19:06:41Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "c2fbf5df-2988-419f-aef8-f312c9e7f87d",
        "parentId" : "be2e7c6c-39c9-4016-b5a6-afed10a6d3a2",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Same answer: the script should crash loudly if that's the case.",
        "createdAt" : "2019-10-29T12:36:50Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : null,
    "diffHunk" : "@@ -243,5 +246,11 @@ main = do\n                 Exit.exitSuccess\n             else do\n                 push_to_s3 docs_folder\n-                let latest = Foldable.maximumBy compare_versions gh_resp\n-                tell_hubspot latest\n+                let gh_latest = Foldable.maximumBy (compare `Function.on` to_v . name) gh_resp\n+                    docs_latest = Foldable.maximumBy (compare `Function.on` to_v) docs_resp"
  },
  {
    "id" : "f2470010-7db0-4506-95d1-fc7df49becf7",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "7e562165-e313-43ef-bd17-848a78334339",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "`Data.List.Extra` has a `maximumOn` function that works nicely here.",
        "createdAt" : "2019-10-28T19:07:02Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "66b8f2ea-d04d-44c6-9a4f-2826d035c2f6",
        "parentId" : "7e562165-e313-43ef-bd17-848a78334339",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Thanks!",
        "createdAt" : "2019-10-29T12:36:58Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : null,
    "diffHunk" : "@@ -243,5 +246,11 @@ main = do\n                 Exit.exitSuccess\n             else do\n                 push_to_s3 docs_folder\n-                let latest = Foldable.maximumBy compare_versions gh_resp\n-                tell_hubspot latest\n+                let gh_latest = Foldable.maximumBy (compare `Function.on` to_v . name) gh_resp"
  },
  {
    "id" : "669e5c07-986f-42eb-8f37-fc7053b098c4",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "9c058689-fc74-41d2-8821-71c60fd35c70",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "I find this unnecessarily hard to read because I have to scan from both sides. Could you please either use `$` or `&` but not both. I generally prefer `$` because it it gives you the same order as function application.\r\nAlso:\r\n```suggestion\r\n            build_docs_folder docs_folder $ gh_resp & map name & List.sortOn (Down . to_v)\r\n```\r\nwhere `Down` is from `Data.Ord`.",
        "createdAt" : "2019-10-28T19:15:37Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "90280e88-1e51-41b5-9db8-8ea069544843",
        "parentId" : "9c058689-fc74-41d2-8821-71c60fd35c70",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Done.",
        "createdAt" : "2019-10-29T12:44:50Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : null,
    "diffHunk" : "@@ -234,7 +237,7 @@ main = do\n     else do\n         Temp.withTempDir $ \\docs_folder -> do\n             putStrLn \"Building docs listing\"\n-            build_docs_folder docs_folder $ gh_resp & List.sortBy compare_versions & reverse & map name\n+            build_docs_folder docs_folder $ gh_resp & map name & List.sortOn to_v & reverse"
  },
  {
    "id" : "7be443c0-b1cd-4cfe-a434-0579fe6a89dc",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "35cbdb1b-4ecb-4953-8a4d-4f1b9158ed4a",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "```suggestion\r\n                let docs_latest = Foldable.maximumBy (compare `Function.on` to_v) docs_resp\r\n```\r\nEven though this `let` is not required it stops you from accidentally writing mutually recursive let bindings.",
        "createdAt" : "2019-10-28T19:18:36Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "88819537-9261-4c1a-89b6-e44f2dfa812e",
        "parentId" : "35cbdb1b-4ecb-4953-8a4d-4f1b9158ed4a",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Ok.",
        "createdAt" : "2019-10-29T12:45:07Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : null,
    "diffHunk" : "@@ -243,5 +246,11 @@ main = do\n                 Exit.exitSuccess\n             else do\n                 push_to_s3 docs_folder\n-                let latest = Foldable.maximumBy compare_versions gh_resp\n-                tell_hubspot latest\n+                let gh_latest = Foldable.maximumBy (compare `Function.on` to_v . name) gh_resp\n+                    docs_latest = Foldable.maximumBy (compare `Function.on` to_v) docs_resp"
  },
  {
    "id" : "12957547-87c8-4245-a49a-d2a604fcaa4e",
    "prId" : 3266,
    "comments" : [
      {
        "id" : "33db7087-5851-4bf6-8bc6-84c8b5054a0b",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "```suggestion\r\n                if to_v (name gh_latest) > to_v docs_latest\r\n```",
        "createdAt" : "2019-10-28T19:18:57Z",
        "updatedAt" : "2019-10-29T12:49:26Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3d8004236e212354b2410fbd307d630888aa266e",
    "line" : null,
    "diffHunk" : "@@ -243,5 +246,11 @@ main = do\n                 Exit.exitSuccess\n             else do\n                 push_to_s3 docs_folder\n-                let latest = Foldable.maximumBy compare_versions gh_resp\n-                tell_hubspot latest\n+                let gh_latest = Foldable.maximumBy (compare `Function.on` to_v . name) gh_resp\n+                    docs_latest = Foldable.maximumBy (compare `Function.on` to_v) docs_resp\n+                if (to_v . name) gh_latest > to_v docs_latest"
  },
  {
    "id" : "05158069-5df2-4501-998e-344dc20ac41c",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "98fa628e-2b62-401e-b5a8-cb3ab80c06c8",
        "parentId" : null,
        "author" : null,
        "body" : "Can `Data.Function.(&)` be used here?",
        "createdAt" : "2019-10-18T19:21:31Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : null,
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "1cea84d4-3b51-4263-8351-2493f362beff",
        "parentId" : "98fa628e-2b62-401e-b5a8-cb3ab80c06c8",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "It can and it should if you want flipped application. Reinventing functions from the standard library with a different name only makes your code harder to understand. That said, I find neither of the usecases here particularly compelling so I would personally just go for regular function application. Given that I don’t feel particularly strongly about this, I’m happy to leave this to you but if you want to go for flipped application, let’s go with `&`.",
        "createdAt" : "2019-10-21T18:46:24Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "42a86a83-b1c3-48a4-8711-87b8f419f5be",
        "parentId" : "98fa628e-2b62-401e-b5a8-cb3ab80c06c8",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Yes indeed. I was not aware of that.",
        "createdAt" : "2019-10-25T17:13:40Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x"
  },
  {
    "id" : "d9d2af3d-7776-42f2-9887-884595ffc730",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "198ddc66-3d7d-4fe8-b861-59927bc4e0dc",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I guess you care about this being bash which is why you use this instead of creating the `CreateProcess` using `shell`? If so, worth pointing out in a comment.",
        "createdAt" : "2019-10-21T18:48:15Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "b409d6d3-d8ef-4fc6-8a8c-a19d8dc83cba",
        "parentId" : "198ddc66-3d7d-4fe8-b861-59927bc4e0dc",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I wrote that fairly early and wanted to use Bash to ensure I kept the same parsing rules for quotes. Reading through the code again, I don't think I need it anymore. Most of the quoting was in the cURL commands, which I have replaced with direct HTTP calls from Haskell.",
        "createdAt" : "2019-10-25T17:25:17Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\""
  },
  {
    "id" : "8c0b3765-f606-445f-a5b9-a7d928f1e058",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "f3a8b5a0-363a-4c2f-9b60-251788033672",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "for better or for worse, we use camelcase as the naming convention for all other Haskell code so I think it would be better to be consistent here.",
        "createdAt" : "2019-10-21T18:49:12Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "9880db13-270f-477d-a55e-05d55d619129",
        "parentId" : "f3a8b5a0-363a-4c2f-9b60-251788033672",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I disagree. I do believe snake case is better, and I do not think consistency within a monorepo matters much for a top-level application file (i.e. not a library that would \"pollute\" modules that import it), so I would rather keep those.",
        "createdAt" : "2019-10-25T19:32:35Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "186152f1-7d94-4f9d-938d-1369c0b6df63",
        "parentId" : "f3a8b5a0-363a-4c2f-9b60-251788033672",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Given that basically all Haskell libraries use camelCase this isn’t just about consistency within a repo but also about consistency with the names used by your dependencies.",
        "createdAt" : "2019-10-25T19:35:52Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "949b6327-2581-4bc5-bbca-bb5f40fdb0f9",
        "parentId" : "f3a8b5a0-363a-4c2f-9b60-251788033672",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I actually like that inconsistency, as it tells me at a glance where an identifier comes from. We all have our quirks, I suppose.",
        "createdAt" : "2019-10-27T18:56:40Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : 28,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)"
  },
  {
    "id" : "d6cdf66f-6d3b-4348-b5b7-88438addf405",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "01bd13ec-69da-4412-b034-cc3983cce732",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "same comment about camelCase.",
        "createdAt" : "2019-10-21T18:49:36Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : 58,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()"
  },
  {
    "id" : "54c0070a-5639-404c-a31b-d69c150289fa",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "3b6104dd-d737-4fcc-81be-902d33e7c9ae",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```\r\nh n = do\r\n  (exit, out, err) <- shell_exit_code cmd\r\n  case exit of\r\n    Exit.ExitSuccess -> pure ()\r\n    _ | n == 0 -> die cmd exit out err\r\n    _ | \"unexpected end-of-file\" `isInfixOf` err -> h (n - 1)\r\n   _ | otherwise -> die cmd exit out err\r\n```",
        "createdAt" : "2019-10-21T18:55:49Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "1991d3c8-519a-414e-a2fc-3e6efbbe445b",
        "parentId" : "3b6104dd-d737-4fcc-81be-902d33e7c9ae",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Nice, thanks!",
        "createdAt" : "2019-10-25T19:33:03Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of"
  },
  {
    "id" : "76946073-99a5-47e1-b8ca-702f07ee87df",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "2f314944-fda1-4d27-830e-70fe5db4bf7f",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    case (statusCode $ responseStatus response, body) of\r\n```",
        "createdAt" : "2019-10-21T19:00:00Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "74bba4da-1698-47b3-a7b9-a8d87d48b972",
        "parentId" : "2f314944-fda1-4d27-830e-70fe5db4bf7f",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "👍 ",
        "createdAt" : "2019-10-25T19:41:47Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : 80,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of"
  },
  {
    "id" : "90a5af99-d0b0-4490-9504-f9ba0d479a8c",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "30d443d1-0b4e-44dc-a80e-526f95896674",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    else die cmd exit out err\r\n```",
        "createdAt" : "2019-10-21T20:08:38Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "a711f427-08cc-4f8c-8fde-e40398d9a46c",
        "parentId" : "30d443d1-0b4e-44dc-a80e-526f95896674",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Thanks.",
        "createdAt" : "2019-10-25T19:42:05Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do"
  },
  {
    "id" : "f4cfef2a-d3e7-469b-9950-f4fea18bf7b0",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "7a792776-2202-4b90-a65b-326d572c51ec",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    void $ shell cmd\r\n```",
        "createdAt" : "2019-10-21T20:09:16Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "cf47c722-f8dd-4f6d-8c6f-27a4e0aabbc9",
        "parentId" : "7a792776-2202-4b90-a65b-326d572c51ec",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Thanks.",
        "createdAt" : "2019-10-25T19:42:13Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd"
  },
  {
    "id" : "7460c806-d430-4b54-9d00-1f937422039b",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "7432ffe7-baef-47ed-a5d1-076c0beee0c4",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    let request = request' { HTTP.requestHeaders = [(\"User-Agent\", \"DAML cron (team-daml-language@digitalasset.com)\")] }\r\n```",
        "createdAt" : "2019-10-21T20:10:29Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "71237269-00a3-4338-b989-dd81183ba6fa",
        "parentId" : "7432ffe7-baef-47ed-a5d1-076c0beee0c4",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Interesting. I'm pretty sure I added those because the type system complained... 🤔\r\n\r\nSeems to work, though. Thanks!",
        "createdAt" : "2019-10-25T19:44:27Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }"
  },
  {
    "id" : "1cf85383-f7e8-4968-bd1c-fa0a9b9b928d",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "47e1ad83-8ec8-4944-bcd7-0b0117fdc713",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "It seems a bit like you are reinventing a high-level HTTP API. I think it’s small enough that this is fine here but if it gets more complex, it might be worth looking into a library. I’ve liked https://hackage.haskell.org/package/req-2.1.0/docs/Network-HTTP-Req.html in the past.",
        "createdAt" : "2019-10-21T20:12:54Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "15ac49eb-25b5-4553-ac6d-13f47719c258",
        "parentId" : "47e1ad83-8ec8-4944-bcd7-0b0117fdc713",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Agreed.",
        "createdAt" : "2019-10-25T19:45:15Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of\n+      (200, Just body) -> return body\n+      _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n+                               show $ HTTP.responseBody response]\n+\n+http_post :: String -> [(String, String)] -> LBS.ByteString -> IO LBS.ByteString"
  },
  {
    "id" : "aaf2b1b0-9758-4cbb-b29d-5bd2fcc9507b",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "67de4440-e165-48a9-ad1f-acec634e5e9c",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    let request = request' { HTTP.requestHeaders =\r\n```",
        "createdAt" : "2019-10-21T20:13:10Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "4e68012c-4fb9-40d5-8027-b45fea7daa5c",
        "parentId" : "67de4440-e165-48a9-ad1f-acec634e5e9c",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "Again, weird. But thanks!",
        "createdAt" : "2019-10-25T19:48:12Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of\n+      (200, Just body) -> return body\n+      _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n+                               show $ HTTP.responseBody response]\n+\n+http_post :: String -> [(String, String)] -> LBS.ByteString -> IO LBS.ByteString\n+http_post url headers body = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = map (\\(n, v) -> (Insensitive.mk (BS.fromString n), BS.fromString v))"
  },
  {
    "id" : "5efa2eb5-da85-4fd0-87cd-70c5bdc819d3",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "c9b77f74-1871-4a6d-800c-7f08af351392",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\nhttp_post :: String -> RequestHeaders -> LBS.ByteString -> IO LBS.ByteString\r\n```",
        "createdAt" : "2019-10-21T20:13:46Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of\n+      (200, Just body) -> return body\n+      _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n+                               show $ HTTP.responseBody response]\n+\n+http_post :: String -> [(String, String)] -> LBS.ByteString -> IO LBS.ByteString"
  },
  {
    "id" : "0dc59d09-545f-4c4d-a34d-7476d958afb3",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "c779ab1b-8360-4dd4-ba73-6b37dab11463",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Can we just accept a `[Text]` here and rely on the `FromJSON` instance to implement `to_list` at the callsite?",
        "createdAt" : "2019-10-21T20:15:15Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "3a2d0639-e7c5-486d-810f-0afc0bf4d5f9",
        "parentId" : "c779ab1b-8360-4dd4-ba73-6b37dab11463",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I don't understand what you mean here.",
        "createdAt" : "2019-10-25T19:49:59Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : 106,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of\n+      (200, Just body) -> return body\n+      _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n+                               show $ HTTP.responseBody response]\n+\n+http_post :: String -> [(String, String)] -> LBS.ByteString -> IO LBS.ByteString\n+http_post url headers body = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = map (\\(n, v) -> (Insensitive.mk (BS.fromString n), BS.fromString v))\n+                                                       $ (\"User-Agent\", \"DAML cron (team-daml-language@digitalasset.com)\") : headers,\n+                             HTTP.method = \"POST\",\n+                             HTTP.requestBody = HTTP.RequestBodyBS $ BS.fromString $ LBS.toString body }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    case status `quot` 100 of\n+      2 -> return $ HTTP.responseBody response\n+      _ -> Exit.die $ \"POST \" <> url <> \" failed with \" <> show status <> \".\"\n+\n+github_versions :: [GitHubVersion] -> Set.Set String\n+github_versions vs = Set.fromList $ map name vs\n+\n+remove_prereleases :: [GitHubVersion] -> [GitHubVersion]\n+remove_prereleases = filter (\\v -> prerelease v == False)\n+\n+docs_versions :: JSON.Value -> Set.Set String\n+docs_versions json ="
  },
  {
    "id" : "490b8aea-b824-4ac6-bc17-cc0d7329366a",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "7a327743-189f-49ad-aff2-ecccaff90884",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I would import `.=` unqualified. It’s sufficiently common that the costs of not littering the code with qualified imports are lower than the costs of learning the operator imho.",
        "createdAt" : "2019-10-21T20:17:05Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "e5fd224b-160e-4efd-ae01-d33f3c9b2a2e",
        "parentId" : "7a327743-189f-49ad-aff2-ecccaff90884",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "I personally think the cost of having import qualifiers is way lower than the cost of not having them. (You have to learn the operator either way.)",
        "createdAt" : "2019-10-25T19:50:45Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : 183,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of\n+      (200, Just body) -> return body\n+      _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n+                               show $ HTTP.responseBody response]\n+\n+http_post :: String -> [(String, String)] -> LBS.ByteString -> IO LBS.ByteString\n+http_post url headers body = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = map (\\(n, v) -> (Insensitive.mk (BS.fromString n), BS.fromString v))\n+                                                       $ (\"User-Agent\", \"DAML cron (team-daml-language@digitalasset.com)\") : headers,\n+                             HTTP.method = \"POST\",\n+                             HTTP.requestBody = HTTP.RequestBodyBS $ BS.fromString $ LBS.toString body }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    case status `quot` 100 of\n+      2 -> return $ HTTP.responseBody response\n+      _ -> Exit.die $ \"POST \" <> url <> \" failed with \" <> show status <> \".\"\n+\n+github_versions :: [GitHubVersion] -> Set.Set String\n+github_versions vs = Set.fromList $ map name vs\n+\n+remove_prereleases :: [GitHubVersion] -> [GitHubVersion]\n+remove_prereleases = filter (\\v -> prerelease v == False)\n+\n+docs_versions :: JSON.Value -> Set.Set String\n+docs_versions json =\n+    Set.fromList $ to_list json\n+    where to_list json =\n+            case json of\n+              JSON.Object obj -> obj |> H.toList |> map fst |> map Text.unpack\n+              _ -> []\n+\n+compare_versions :: GitHubVersion -> GitHubVersion -> Ordering\n+compare_versions v1 v2 =\n+    let t :: GitHubVersion -> [Integer]\n+        t v = map read $ Split.splitOn \".\" $ name v\n+    in compare (t v1) (t v2)\n+\n+build_docs_folder :: String -> [String] -> IO ()\n+build_docs_folder path versions = do\n+    out <- shell \"git rev-parse HEAD\"\n+    let cur_sha = init out -- remove ending newline\n+    shell_ $ \"mkdir -p \" <> path\n+    let latest = head versions\n+    putStrLn $ \"Building latest docs: \" <> latest\n+    shell_ $ \"git checkout v\" <> latest\n+    robustly_download_nix_packages\n+    shell_ \"bazel build //docs:docs\"\n+    shell_ $ \"tar xzf bazel-genfiles/docs/html.tar.gz --strip-components=1 -C\" <> path\n+    -- Not going through Aeson because it represents JSON objects as unordered\n+    -- maps, and here order matters.\n+    let versions_json = versions\n+                        |> map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n+                        |> List.join \", \"\n+                        |> \\s -> \"{\" <> s <> \"}\"\n+    writeFile (path <> \"/versions.json\") versions_json\n+    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n+    shell_ $ \"tar xzf bazel-genfiles/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n+    Foldable.for_ (tail versions) $ \\version -> do\n+        putStrLn $ \"Building older docs: \" <> version\n+        shell_ $ \"git checkout v\" <> version\n+        robustly_download_nix_packages\n+        shell_ \"bazel build //docs:docs\"\n+        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n+        shell_ $ \"tar xzf bazel-genfiles/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n+    shell_ $ \"git checkout \" <> cur_sha\n+\n+check_s3_versions :: Set.Set String -> IO Bool\n+check_s3_versions gh_versions = do\n+    temp <- shell \"mktemp\"\n+    shell_ $ \"aws s3 cp s3://docs-daml-com/versions.json \" <> temp\n+    s3_raw <- shell $ \"cat \" <> temp\n+    case JSON.decode $ LBS.fromString s3_raw of\n+      Just s3_json -> return $ (docs_versions s3_json) == gh_versions\n+      Nothing -> Exit.die \"Failed to get versions from s3\"\n+\n+push_to_s3 :: String -> IO ()\n+push_to_s3 doc_folder = do\n+    putStrLn \"Pushing new versions file first...\"\n+    shell_ $ \"aws s3 cp \" <> doc_folder <> \"/versions.json s3://docs-daml-com/versions.json --acl public-read\"\n+    putStrLn \"Pushing to S3 bucket...\"\n+    shell_ $ \"aws s3 sync \" <> doc_folder\n+             <> \" s3://docs-daml-com/\"\n+             <> \" --delete\"\n+             <> \" --acl public-read\"\n+             <> \" --exclude '*.doctrees/*'\"\n+             <> \" --exclude '*.buildinfo'\"\n+    putStrLn \"Refreshing CloudFront cache...\"\n+    shell_ $ \"aws cloudfront create-invalidation\"\n+             <> \" --distribution-id E1U753I56ERH55\"\n+             <> \" --paths '/*'\"\n+\n+data BlogId = BlogId { blog_id :: Integer } deriving Show\n+instance JSON.FromJSON BlogId where\n+    parseJSON = JSON.withObject \"BlogId\" $ \\v -> BlogId\n+        <$> v JSON..: (Text.pack \"id\")\n+\n+data SubmitBlog = SubmitBlog {\n+                      body :: String,\n+                      date :: Integer,\n+                      summary :: String,\n+                      version :: String\n+                  } deriving Show\n+instance JSON.ToJSON SubmitBlog where\n+    toJSON SubmitBlog{body, date, summary, version} =\n+    -- content_group_id and blog_author_id reference existing items in HubSpot\n+        JSON.object [\"name\" JSON..= (\"Release of DAML SDK \" <> version),"
  },
  {
    "id" : "8d6dc899-993e-4076-86bc-775539860b3d",
    "prId" : 3235,
    "comments" : [
      {
        "id" : "0f50d04a-e0a4-4851-b757-8bf77c94f1eb",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Afaik, we mostly use the functionality from `extra` in other places, i.e., `withTempDir` from `System.IO.Extra` so I would recommend to also use this here.",
        "createdAt" : "2019-10-21T20:18:14Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "c2594d80-73cb-44f8-ae3c-9bdc286e2261",
        "parentId" : "0f50d04a-e0a4-4851-b757-8bf77c94f1eb",
        "author" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "body" : "How would it be different? What would it buy me in this code? Is this not working as is?",
        "createdAt" : "2019-10-25T19:51:11Z",
        "updatedAt" : "2019-10-28T16:38:32Z",
        "lastEditedBy" : {
          "login" : "garyverhaegen-da",
          "name" : "Gary Verhaegen",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/45561385?u=eb17386ea66edbd0cd449e33b2d291bf5a1b51cb&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "dae75011a452f0dfe7fecf83ff973bc5c6dbdfbb",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,254 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+\n+module Main (main) where\n+\n+import qualified Data.Aeson as JSON\n+import qualified Data.ByteString.UTF8 as BS\n+import qualified Data.ByteString.Lazy.UTF8 as LBS\n+import qualified Data.CaseInsensitive as Insensitive\n+import qualified Data.Foldable as Foldable\n+import qualified Data.HashMap.Strict as H\n+import qualified Data.List as List\n+import qualified Data.List.Utils as List\n+import qualified Data.List.Split as Split\n+import qualified Data.Set as Set\n+import qualified Data.Text as Text\n+import qualified Network.HTTP.Client as HTTP\n+import qualified Network.HTTP.Client.TLS as TLS\n+import qualified Network.HTTP.Types.Status\n+import qualified System.Environment as Env\n+import qualified System.Exit as Exit\n+import qualified System.IO.Temp as Temp\n+import qualified System.Process as System\n+\n+(|>) :: a -> (a -> b) -> b\n+(|>) x f = f x\n+\n+shell_exit_code :: String -> IO (Exit.ExitCode, String, String)\n+shell_exit_code cmd = do\n+    System.readProcessWithExitCode \"bash\" [\"-c\", cmd] \"\"\n+\n+die :: String -> Exit.ExitCode -> String -> String -> IO a\n+die cmd (Exit.ExitFailure exit) out err =\n+    Exit.die $ unlines [\"Subprocess:\",\n+                         cmd,\n+                        \"failed with exit code \" <> show exit <> \"; output:\",\n+                        \"---\",\n+                        out,\n+                        \"---\",\n+                        \"err:\",\n+                        \"---\",\n+                        err,\n+                        \"---\"]\n+die _ _ _ _ = Exit.die \"Type system too weak.\"\n+\n+\n+shell :: String -> IO String\n+shell cmd = do\n+    (exit, out, err) <- shell_exit_code cmd\n+    if exit == Exit.ExitSuccess\n+    then return out\n+    else do\n+        die cmd exit out err\n+\n+shell_ :: String -> IO ()\n+shell_ cmd = do\n+    _ <- shell cmd\n+    return ()\n+\n+robustly_download_nix_packages :: IO ()\n+robustly_download_nix_packages = do\n+    h (10 :: Integer)\n+    where\n+        cmd = \"nix-build nix -A tools -A cached\"\n+        h n = do\n+            (exit, out, err) <- shell_exit_code cmd\n+            case (exit, n, \"unexpected end-of-file\" `List.isInfixOf` err) of\n+              (Exit.ExitSuccess, _, _) -> return ()\n+              (_, 0, _) -> die cmd exit out err\n+              (_, _, True) -> h (n - 1)\n+              (_, _, False) -> die cmd exit out err\n+\n+http_get :: JSON.FromJSON a => String -> IO a\n+http_get url = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = [(Insensitive.mk (BS.fromString \"User-Agent\"), BS.fromString \"DAML cron (team-daml-language@digitalasset.com)\")] }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    let body = JSON.decode $ HTTP.responseBody response\n+    case (status, body) of\n+      (200, Just body) -> return body\n+      _ -> Exit.die $ unlines [\"GET \\\"\" <> url <> \"\\\" returned status code \" <> show status <> \".\",\n+                               show $ HTTP.responseBody response]\n+\n+http_post :: String -> [(String, String)] -> LBS.ByteString -> IO LBS.ByteString\n+http_post url headers body = do\n+    manager <- HTTP.newManager TLS.tlsManagerSettings\n+    request' <- HTTP.parseRequest url\n+    -- Be polite\n+    let request = request' { HTTP.requestHeaders = map (\\(n, v) -> (Insensitive.mk (BS.fromString n), BS.fromString v))\n+                                                       $ (\"User-Agent\", \"DAML cron (team-daml-language@digitalasset.com)\") : headers,\n+                             HTTP.method = \"POST\",\n+                             HTTP.requestBody = HTTP.RequestBodyBS $ BS.fromString $ LBS.toString body }\n+    response <- HTTP.httpLbs request manager\n+    let Network.HTTP.Types.Status.Status { Network.HTTP.Types.Status.statusCode = status } = HTTP.responseStatus response\n+    case status `quot` 100 of\n+      2 -> return $ HTTP.responseBody response\n+      _ -> Exit.die $ \"POST \" <> url <> \" failed with \" <> show status <> \".\"\n+\n+github_versions :: [GitHubVersion] -> Set.Set String\n+github_versions vs = Set.fromList $ map name vs\n+\n+remove_prereleases :: [GitHubVersion] -> [GitHubVersion]\n+remove_prereleases = filter (\\v -> prerelease v == False)\n+\n+docs_versions :: JSON.Value -> Set.Set String\n+docs_versions json =\n+    Set.fromList $ to_list json\n+    where to_list json =\n+            case json of\n+              JSON.Object obj -> obj |> H.toList |> map fst |> map Text.unpack\n+              _ -> []\n+\n+compare_versions :: GitHubVersion -> GitHubVersion -> Ordering\n+compare_versions v1 v2 =\n+    let t :: GitHubVersion -> [Integer]\n+        t v = map read $ Split.splitOn \".\" $ name v\n+    in compare (t v1) (t v2)\n+\n+build_docs_folder :: String -> [String] -> IO ()\n+build_docs_folder path versions = do\n+    out <- shell \"git rev-parse HEAD\"\n+    let cur_sha = init out -- remove ending newline\n+    shell_ $ \"mkdir -p \" <> path\n+    let latest = head versions\n+    putStrLn $ \"Building latest docs: \" <> latest\n+    shell_ $ \"git checkout v\" <> latest\n+    robustly_download_nix_packages\n+    shell_ \"bazel build //docs:docs\"\n+    shell_ $ \"tar xzf bazel-genfiles/docs/html.tar.gz --strip-components=1 -C\" <> path\n+    -- Not going through Aeson because it represents JSON objects as unordered\n+    -- maps, and here order matters.\n+    let versions_json = versions\n+                        |> map (\\s -> \"\\\"\" <> s <> \"\\\": \\\"\" <> s <> \"\\\"\")\n+                        |> List.join \", \"\n+                        |> \\s -> \"{\" <> s <> \"}\"\n+    writeFile (path <> \"/versions.json\") versions_json\n+    shell_ $ \"mkdir -p  \" <> path <> \"/\" <> latest\n+    shell_ $ \"tar xzf bazel-genfiles/docs/html.tar.gz --strip-components=1 -C \" <> path <> \"/\" <> latest\n+    Foldable.for_ (tail versions) $ \\version -> do\n+        putStrLn $ \"Building older docs: \" <> version\n+        shell_ $ \"git checkout v\" <> version\n+        robustly_download_nix_packages\n+        shell_ \"bazel build //docs:docs\"\n+        shell_ $ \"mkdir -p  \" <> path <> \"/\" <> version\n+        shell_ $ \"tar xzf bazel-genfiles/docs/html.tar.gz --strip-components=1 -C\" <> path <> \"/\" <> version\n+    shell_ $ \"git checkout \" <> cur_sha\n+\n+check_s3_versions :: Set.Set String -> IO Bool\n+check_s3_versions gh_versions = do\n+    temp <- shell \"mktemp\"\n+    shell_ $ \"aws s3 cp s3://docs-daml-com/versions.json \" <> temp\n+    s3_raw <- shell $ \"cat \" <> temp\n+    case JSON.decode $ LBS.fromString s3_raw of\n+      Just s3_json -> return $ (docs_versions s3_json) == gh_versions\n+      Nothing -> Exit.die \"Failed to get versions from s3\"\n+\n+push_to_s3 :: String -> IO ()\n+push_to_s3 doc_folder = do\n+    putStrLn \"Pushing new versions file first...\"\n+    shell_ $ \"aws s3 cp \" <> doc_folder <> \"/versions.json s3://docs-daml-com/versions.json --acl public-read\"\n+    putStrLn \"Pushing to S3 bucket...\"\n+    shell_ $ \"aws s3 sync \" <> doc_folder\n+             <> \" s3://docs-daml-com/\"\n+             <> \" --delete\"\n+             <> \" --acl public-read\"\n+             <> \" --exclude '*.doctrees/*'\"\n+             <> \" --exclude '*.buildinfo'\"\n+    putStrLn \"Refreshing CloudFront cache...\"\n+    shell_ $ \"aws cloudfront create-invalidation\"\n+             <> \" --distribution-id E1U753I56ERH55\"\n+             <> \" --paths '/*'\"\n+\n+data BlogId = BlogId { blog_id :: Integer } deriving Show\n+instance JSON.FromJSON BlogId where\n+    parseJSON = JSON.withObject \"BlogId\" $ \\v -> BlogId\n+        <$> v JSON..: (Text.pack \"id\")\n+\n+data SubmitBlog = SubmitBlog {\n+                      body :: String,\n+                      date :: Integer,\n+                      summary :: String,\n+                      version :: String\n+                  } deriving Show\n+instance JSON.ToJSON SubmitBlog where\n+    toJSON SubmitBlog{body, date, summary, version} =\n+    -- content_group_id and blog_author_id reference existing items in HubSpot\n+        JSON.object [\"name\" JSON..= (\"Release of DAML SDK \" <> version),\n+                     \"post_body\" JSON..= body,\n+                     \"content_group_id\" JSON..= (11411412838 :: Integer),\n+                     \"publish_date\" JSON..= date,\n+                     \"post_summary\" JSON..= summary,\n+                     \"slug\" JSON..= version,\n+                     \"blog_author_id\" JSON..= (11513309969 :: Integer),\n+                     \"meta_description\" JSON..= summary]\n+\n+tell_hubspot :: GitHubVersion -> IO ()\n+tell_hubspot latest = do\n+    putStrLn $ \"Publishing \"<> (name latest) <> \" to Hubspot...\"\n+    desc <- http_post \"https://api.github.com/markdown/raw\" [(\"Content-Type\", \"text/plain\")] (LBS.fromString $ notes latest)\n+    date <- read <$> (<> \"000\") <$> init <$> (shell $ \"date -d \" <> (published_at latest) <> \" +%s\")\n+    let summary = \"Release notes for version \" <> (name latest) <> \".\"\n+    token <- Env.getEnv \"HUBSPOT_TOKEN\"\n+    submit_blog <- http_post (\"https://api.hubapi.com/content/api/v2/blog-posts?hapikey=\" <> token)\n+                             [(\"Content-Type\", \"application.json\")]\n+                             (JSON.encode $ SubmitBlog { body = LBS.toString desc,\n+                                                         date,\n+                                                         summary,\n+                                                         version = (name latest) })\n+    case JSON.decode submit_blog of\n+      Nothing -> Exit.die $ \"No blog id from HubSpot: \\n\" <> LBS.toString submit_blog\n+      Just (BlogId { blog_id }) -> do\n+          _ <- http_post (\"https://api.hubapi.com/content/api/v2/blog-posts/\" <> show blog_id <> \"/publish-action?hapikey=\" <> token)\n+                         [(\"Content-Type\", \"application.json\")]\n+                         (JSON.encode $ JSON.object [(\"action\", \"schedule-publish\")])\n+          return ()\n+\n+data GitHubVersion = GitHubVersion { prerelease :: Bool, tag_name :: String, notes :: String, published_at :: String } deriving Show\n+instance JSON.FromJSON GitHubVersion where\n+    parseJSON = JSON.withObject \"GitHubVersion\" $ \\v -> GitHubVersion\n+        <$> v JSON..: (Text.pack \"prerelease\")\n+        <*> v JSON..: (Text.pack \"tag_name\")\n+        <*> v JSON..:? (Text.pack \"body\") JSON..!= \"\"\n+        <*> v JSON..: (Text.pack \"published_at\")\n+\n+name :: GitHubVersion -> String\n+name gh = tail $ tag_name gh\n+\n+main :: IO ()\n+main = do\n+    robustly_download_nix_packages\n+    putStrLn \"Checking for new version...\"\n+    gh_resp <- remove_prereleases <$> http_get \"https://api.github.com/repos/digital-asset/daml/releases\"\n+    docs_resp <- docs_versions <$> http_get \"https://docs.daml.com/versions.json\"\n+    if (github_versions gh_resp) == docs_resp\n+    then do\n+        putStrLn \"No new version found, skipping.\"\n+        Exit.exitSuccess\n+    else do\n+        Temp.withSystemTempDirectory \"docs\" $ \\docs_folder -> do"
  }
]