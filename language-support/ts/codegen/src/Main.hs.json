[
  {
    "id" : "ae05c7e3-2a9e-467e-9eb6-6826ebe5cad9",
    "prId" : 3852,
    "comments" : [
      {
        "id" : "40ce5a06-f8da-49b8-9343-5788d2e8364e",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "I'd prefer to add these exceptions in a very targeted way to the lines they apply to.",
        "createdAt" : "2019-12-13T19:34:02Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "723eb693-6d11-406c-a19f-fb7f6b4da676",
        "parentId" : "40ce5a06-f8da-49b8-9343-5788d2e8364e",
        "author" : {
          "login" : "robin-da",
          "name" : "Robin Krom",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/14074936?u=1b47fdbdfd82ea534219fc1b94d646873c56a7d7&v=4"
        },
        "body" : "Is it possible to add those exceptions right in front of the namespace declaration? ",
        "createdAt" : "2019-12-14T15:46:18Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "robin-da",
          "name" : "Robin Krom",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/14074936?u=1b47fdbdfd82ea534219fc1b94d646873c56a7d7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3a68182d583d7fd2decf473c86963a606d73ecc7",
    "line" : null,
    "diffHunk" : "@@ -92,8 +92,14 @@ genModule mod\n             [\"// Generated from \" <> T.intercalate \"/\" (unModuleName curModName) <> \".daml\"\n             ,\"/* eslint-disable @typescript-eslint/camelcase */\"\n             ,\"/* eslint-disable @typescript-eslint/no-use-before-define */\"\n-            ,\"import * as daml from '@digitalasset/daml-json-types';\"\n+            ,\"/* eslint-disable @typescript-eslint/no-namespace */\""
  },
  {
    "id" : "45360868-4447-47ae-86c1-ee2102a5406e",
    "prId" : 3852,
    "comments" : [
      {
        "id" : "583cd242-2fb3-409a-9522-30058dc50518",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "Why do we need this? I'd be very much in favor of dropping this exception.",
        "createdAt" : "2019-12-13T19:34:55Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "7375a449-6943-4d91-983e-fc74d301dea5",
        "parentId" : "583cd242-2fb3-409a-9522-30058dc50518",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "I think I know what the problem is. This could hit us on other modules too. Let's definitely drop this exception and instead add a way to assert that the generated object for the enum type implements the `Serializable` interface. This will make the \"unused imports\" warning go away and give us more certainty that we don't accidentally break the codegen.",
        "createdAt" : "2019-12-13T19:50:36Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "cb6edb09-bf87-4d33-acfd-ff244bdbb98d",
        "parentId" : "583cd242-2fb3-409a-9522-30058dc50518",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "Unfortunately, we can't declare that a namespace implements an interface. The best I could come up with to work around this fact is as follows:\r\n1. Add a function `const STATIC_IMPLEMENTS_SERIALIZABLE_CHECK = <T>(_: Serializable<T>) => { }` to `daml-json-types`.\r\n2. After the declaration of each enum, say `Color`, add a line `STATIC_IMPLEMENTS_SERIALIZABLE_CHECK<Color>(Color);`. This line kills two birds with one stone: It ensures that `Color` actually implements `Serializable<Color>` and it uses the import `daml-json-types`.",
        "createdAt" : "2019-12-13T20:26:59Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "f956eeb3-168d-4753-8e02-e25358e78156",
        "parentId" : "583cd242-2fb3-409a-9522-30058dc50518",
        "author" : {
          "login" : "robin-da",
          "name" : "Robin Krom",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/14074936?u=1b47fdbdfd82ea534219fc1b94d646873c56a7d7&v=4"
        },
        "body" : "good idea, I'll try it!",
        "createdAt" : "2019-12-14T16:04:27Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "robin-da",
          "name" : "Robin Krom",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/14074936?u=1b47fdbdfd82ea534219fc1b94d646873c56a7d7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3a68182d583d7fd2decf473c86963a606d73ecc7",
    "line" : null,
    "diffHunk" : "@@ -92,8 +92,14 @@ genModule mod\n             [\"// Generated from \" <> T.intercalate \"/\" (unModuleName curModName) <> \".daml\"\n             ,\"/* eslint-disable @typescript-eslint/camelcase */\"\n             ,\"/* eslint-disable @typescript-eslint/no-use-before-define */\"\n-            ,\"import * as daml from '@digitalasset/daml-json-types';\"\n+            ,\"/* eslint-disable @typescript-eslint/no-namespace */\"\n+            -- We use namespaces to add decoders to enumerations. eslint prefers modules, but\n+            -- these would have to live in \"d.ts\" files and are restricted in what they can contain.\n             ,\"import * as jtv from '@mojotech/json-type-validation';\"\n+            ] ++\n+            [\n+            \"import * as daml from '@digitalasset/daml-json-types';\"\n+            | moduleNameString curModName `notElem` [\"GHC.Types\", \"DA.Date\"]"
  },
  {
    "id" : "c5f4e1b3-2164-4ec9-bb32-87a6494b97a7",
    "prId" : 3852,
    "comments" : [
      {
        "id" : "791aff88-34d5-418a-af38-48383080353b",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "```suggestion\r\n                | VariantConName cons <- enumCons] ++\r\n```",
        "createdAt" : "2019-12-13T19:35:03Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3a68182d583d7fd2decf473c86963a606d73ecc7",
    "line" : null,
    "diffHunk" : "@@ -123,7 +129,19 @@ genDefDataType curModName tpls def = case unTypeConName (dataTypeCon def) of\n     [conName] -> case dataCons def of\n         DataSynonym{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(NICK)\n         DataVariant{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(MH): make variants type safe\n-        DataEnum{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(MH): make enum types type safe\n+        DataEnum enumCons ->\n+          let\n+            typeDesc =\n+                [ \"export enum \" <> conName <> \"{\"] ++\n+                [ \"  \" <> cons <> \" = \" <> \"\\'\" <> cons <> \"\\'\" <> \",\"\n+                | (VariantConName cons) <- enumCons] ++"
  },
  {
    "id" : "0c52aa84-b615-4f5d-867f-a6fe2cd22c90",
    "prId" : 3852,
    "comments" : [
      {
        "id" : "89e80844-0030-4a43-b1d9-a6e8b5e31ed2",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "```suggestion\r\n                [ \"  \" <> cons <> \" = '\" <> cons <> \"',\"\r\n```",
        "createdAt" : "2019-12-13T19:36:01Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "a7cd5e5f-dd65-446a-a8f2-3848d930bce3",
        "parentId" : "89e80844-0030-4a43-b1d9-a6e8b5e31ed2",
        "author" : {
          "login" : "robin-da",
          "name" : "Robin Krom",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/14074936?u=1b47fdbdfd82ea534219fc1b94d646873c56a7d7&v=4"
        },
        "body" : "sorry, wasn't hlinted yet.",
        "createdAt" : "2019-12-14T15:43:34Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "robin-da",
          "name" : "Robin Krom",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/14074936?u=1b47fdbdfd82ea534219fc1b94d646873c56a7d7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3a68182d583d7fd2decf473c86963a606d73ecc7",
    "line" : null,
    "diffHunk" : "@@ -123,7 +129,19 @@ genDefDataType curModName tpls def = case unTypeConName (dataTypeCon def) of\n     [conName] -> case dataCons def of\n         DataSynonym{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(NICK)\n         DataVariant{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(MH): make variants type safe\n-        DataEnum{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(MH): make enum types type safe\n+        DataEnum enumCons ->\n+          let\n+            typeDesc =\n+                [ \"export enum \" <> conName <> \"{\"] ++\n+                [ \"  \" <> cons <> \" = \" <> \"\\'\" <> cons <> \"\\'\" <> \",\""
  },
  {
    "id" : "3859005b-d9cb-40e3-aed4-b78ab5784e84",
    "prId" : 3852,
    "comments" : [
      {
        "id" : "e2e631a8-33c6-4c1a-bb43-a0a7176c50a2",
        "parentId" : null,
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "This line is tricky. On first reading, I thought it's wrong because I confused the two object languages. That is clearly not the case and it's alright. Generating code for language `X` from language `Y` in language `Z` is a tough best. 😃 ",
        "createdAt" : "2019-12-13T19:38:30Z",
        "updatedAt" : "2019-12-16T11:53:55Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "3a68182d583d7fd2decf473c86963a606d73ecc7",
    "line" : null,
    "diffHunk" : "@@ -123,7 +129,19 @@ genDefDataType curModName tpls def = case unTypeConName (dataTypeCon def) of\n     [conName] -> case dataCons def of\n         DataSynonym{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(NICK)\n         DataVariant{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(MH): make variants type safe\n-        DataEnum{} -> ((makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"]), Set.empty)  -- TODO(MH): make enum types type safe\n+        DataEnum enumCons ->\n+          let\n+            typeDesc =\n+                [ \"export enum \" <> conName <> \"{\"] ++\n+                [ \"  \" <> cons <> \" = \" <> \"\\'\" <> cons <> \"\\'\" <> \",\"\n+                | (VariantConName cons) <- enumCons] ++\n+                [ \"}\" ]\n+            serDesc =\n+                [\"  () => jtv.oneOf(\"] ++\n+                [\"    jtv.constant(\" <> conName <> \".\" <> cons <> \"),\" | VariantConName cons <- enumCons] ++"
  },
  {
    "id" : "74b81c9e-c78e-442b-8a41-ae91067103e6",
    "prId" : 3689,
    "comments" : [
      {
        "id" : "b32ad27b-d06f-404e-a224-c77eb20022e8",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "imhoo this would be easier to read as something like\r\n```\r\n++ [\"\"] ++\r\nintercalate [\"\"] $ concatMap (\\(def, ser) -> def ++ ser) defSers\r\n```\r\nIt took me a while to spot why we add a list with an empty string to each definition.",
        "createdAt" : "2019-12-01T11:19:20Z",
        "updatedAt" : "2019-12-01T11:26:04Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "105008ac1708b448f467614f7fb1a3da9910207d",
    "line" : 74,
    "diffHunk" : "@@ -59,61 +58,61 @@ daml2ts Options{..} pkgId pkg = do\n     T.writeFileUtf8 (outputDir </> \"packageId.ts\") $ T.unlines\n         [\"export default '\" <> unPackageId pkgId <> \"';\"]\n     forM_ (packageModules pkg) $ \\mod -> do\n-        let outputFile = outputDir </> joinPath (map T.unpack (unModuleName (moduleName mod))) <.> \"ts\"\n-        putStrLn $ \"Generating \" ++ outputFile\n-        createDirectoryIfMissing True (takeDirectory outputFile)\n-        T.writeFileUtf8 outputFile (genModule mod)\n+        whenJust (genModule mod) $ \\modTxt -> do\n+            let outputFile = outputDir </> joinPath (map T.unpack (unModuleName (moduleName mod))) <.> \"ts\"\n+            putStrLn $ \"Generating \" ++ outputFile\n+            createDirectoryIfMissing True (takeDirectory outputFile)\n+            T.writeFileUtf8 outputFile modTxt\n \n dup :: a -> (a, a)\n dup x = (x, x)\n \n-genModule :: Module -> T.Text\n-genModule mod =\n+genModule :: Module -> Maybe T.Text\n+genModule mod\n+  | null serDefs = Nothing\n+  | otherwise =\n     let curModName = moduleName mod\n         pkgRootPath\n           | lenModName == 1 = \".\"\n           | otherwise = T.intercalate \"/\" (replicate (lenModName - 1) \"..\")\n           where\n             lenModName = length (unModuleName curModName)\n         tpls = moduleTemplates mod\n+        (defSers, refs) = unzip (map (genDefDataType curModName tpls) serDefs)\n     in\n-    T.unlines $\n+    Just $ T.unlines $\n         [\"// Generated from \" <> T.intercalate \"/\" (unModuleName curModName) <> \".daml\"\n         ,\"/* eslint-disable @typescript-eslint/camelcase */\"\n-        ,\"/* eslint-disable @typescript-eslint/no-unused-vars */\"\n         ,\"/* eslint-disable @typescript-eslint/no-use-before-define */\"\n         ,\"import * as daml from '@digitalasset/daml-json-types';\"\n         ,\"import * as jtv from '@mojotech/json-type-validation';\"\n         ,\"import packageId from '\" <> pkgRootPath <> \"/packageId';\"\n         ] ++\n         [\"import * as \" <> modNameStr <> \" from '\" <> pkgRootPath <> \"/\" <> pkgRefStr <> T.intercalate \"/\" (unModuleName modName) <> \"';\"\n-        | modRef@(pkgRef, modName) <- Set.toList (Set.setOf moduleModuleRef mod)\n+        | modRef@(pkgRef, modName) <- Set.toList (Set.unions refs)\n         , let pkgRefStr = case pkgRef of\n                 PRSelf -> \"\"\n                 PRImport pkgId -> \"../\" <> unPackageId pkgId <> \"/\"\n-        , Just modNameStr <- [genModuleRef curModName modRef]\n+        , let modNameStr = genModuleRef modRef\n         ] ++\n         [ \"\"\n         ,\"const moduleName = '\" <> T.intercalate \".\" (unModuleName curModName) <> \"';\"\n         ,\"const templateId = (entityName: string): daml.TemplateId => ({packageId, moduleName, entityName});\"\n         ] ++\n-        concat\n-        [ [\"\"] ++ def' ++ ser\n-        | def <- NM.toList (moduleDataTypes mod)\n-        , getIsSerializable (dataSerializable def)\n-        , let (def', ser) = genDefDataType curModName tpls def\n-        ]\n+        concatMap (\\(def, ser) -> [\"\"] ++ def ++ ser) defSers"
  },
  {
    "id" : "9796abf2-6504-43b1-95f3-14fbf995bd68",
    "prId" : 3689,
    "comments" : [
      {
        "id" : "bd712483-0eba-4dd5-bcb4-4c5460b37027",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Manually writing the code for detecting the references seems a bit repetitive and brittle since it’s easy to forget to recurse somewhere. Is there a reason why we cannot throw some traversal at this that takes care of giving us all module references?",
        "createdAt" : "2019-12-01T11:24:05Z",
        "updatedAt" : "2019-12-01T11:26:04Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "105008ac1708b448f467614f7fb1a3da9910207d",
    "line" : 142,
    "diffHunk" : "@@ -168,48 +168,51 @@ genDefDataType curModName tpls def = case unTypeConName (dataTypeCon def) of\n             map (\"  \" <>) (onHead (\"decoder: \" <>) serDesc) ++\n             [\"});\"]\n \n-genType :: ModuleName -> Type -> (T.Text, T.Text)\n+genType :: ModuleName -> Type -> ((T.Text, T.Text), Set.Set ModuleRef)\n genType curModName = go\n   where\n     go = \\case\n-        TVar v -> dup (unTypeVarName v)\n-        TUnit -> (\"{}\", \"daml.Unit\")\n-        TBool -> (\"boolean\", \"daml.Bool\")\n-        TInt64 -> dup \"daml.Int\"\n-        TDecimal -> dup \"daml.Decimal\"\n-        TNumeric _ -> dup \"daml.Numeric\"  -- TODO(MH): Figure out what to do with the scale.\n-        TText -> (\"string\", \"daml.Text\")\n-        TTimestamp -> dup \"daml.Time\"\n-        TParty -> dup \"daml.Party\"\n-        TDate -> dup \"daml.Date\"\n+        TVar v -> (dup (unTypeVarName v), Set.empty)"
  },
  {
    "id" : "afe43d41-4b0e-47fe-b51e-31f1dae49b28",
    "prId" : 3441,
    "comments" : [
      {
        "id" : "8ef3bcf6-0db7-4936-a44f-be76180ff21b",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n    T.writeFileUtf8 (outputBaseDir </> \"packageId.ts\") $ T.unlines\r\n```",
        "createdAt" : "2019-11-19T08:13:28Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "eff993c856bef39dda178c0b0ca7b3cc76f89f26",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,248 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+module Main (main) where\n+\n+import qualified DA.Daml.LF.Proto3.Archive as Archive\n+import qualified DA.Daml.LF.Reader as DAR\n+import qualified DA.Pretty\n+import qualified Data.ByteString as B\n+import qualified Data.ByteString.Lazy as BSL\n+import qualified Data.NameMap as NM\n+import qualified Data.Set as Set\n+import qualified Data.Set.Lens as Set\n+import qualified Data.Text as T\n+import qualified Data.Text.IO as T\n+import qualified \"zip-archive\" Codec.Archive.Zip as Zip\n+\n+import Control.Monad\n+import DA.Daml.LF.Ast\n+import DA.Daml.LF.Ast.Optics\n+import Data.List.Extra\n+import Options.Applicative\n+import System.Directory\n+import System.FilePath\n+\n+data Options = Options\n+    { optInputDar :: FilePath\n+    , optOutputDir :: FilePath\n+    }\n+\n+optionsParser :: Parser Options\n+optionsParser = Options\n+    <$> argument str\n+        (  metavar \"DAR-FILE\"\n+        <> help \"DAR file to generate TypeScript bindings for\"\n+        )\n+    <*> strOption\n+        (  short 'o'\n+        <> metavar \"DIR\"\n+        <> help \"Output directory for the generated TypeScript files\"\n+        )\n+\n+optionsParserInfo :: ParserInfo Options\n+optionsParserInfo = info (optionsParser <**> helper)\n+    (  fullDesc\n+    <> progDesc \"Generate TypeScript bindings from a DAR\"\n+    )\n+\n+main :: IO ()\n+main = do\n+    opts@Options{..} <- execParser optionsParserInfo\n+    dar <- B.readFile optInputDar\n+    dalfs <- either fail pure $ DAR.readDalfs $ Zip.toArchive $ BSL.fromStrict dar\n+    forM_ (DAR.mainDalf dalfs : DAR.dalfs dalfs) $ \\dalf -> do\n+        (pkgId, pkg) <- either (fail . show)  pure $ Archive.decodeArchive Archive.DecodeAsMain (BSL.toStrict dalf)\n+        daml2ts opts pkgId pkg\n+\n+daml2ts :: Options -> PackageId -> Package -> IO ()\n+daml2ts Options{..} pkgId pkg = do\n+    let outputBaseDir = optOutputDir </> T.unpack (unPackageId pkgId)\n+    createDirectoryIfMissing True outputBaseDir\n+    T.writeFile (outputBaseDir </> \"packageId.ts\") $ T.unlines"
  },
  {
    "id" : "af558bdc-3ee8-4ab9-972a-9127e8336261",
    "prId" : 3441,
    "comments" : [
      {
        "id" : "3abf75f5-c923-4117-95c0-afa557e3de0a",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n        T.writeFileUtf8 outputFile (genModule mod)\r\n```",
        "createdAt" : "2019-11-19T08:13:40Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "eff993c856bef39dda178c0b0ca7b3cc76f89f26",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,248 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+module Main (main) where\n+\n+import qualified DA.Daml.LF.Proto3.Archive as Archive\n+import qualified DA.Daml.LF.Reader as DAR\n+import qualified DA.Pretty\n+import qualified Data.ByteString as B\n+import qualified Data.ByteString.Lazy as BSL\n+import qualified Data.NameMap as NM\n+import qualified Data.Set as Set\n+import qualified Data.Set.Lens as Set\n+import qualified Data.Text as T\n+import qualified Data.Text.IO as T\n+import qualified \"zip-archive\" Codec.Archive.Zip as Zip\n+\n+import Control.Monad\n+import DA.Daml.LF.Ast\n+import DA.Daml.LF.Ast.Optics\n+import Data.List.Extra\n+import Options.Applicative\n+import System.Directory\n+import System.FilePath\n+\n+data Options = Options\n+    { optInputDar :: FilePath\n+    , optOutputDir :: FilePath\n+    }\n+\n+optionsParser :: Parser Options\n+optionsParser = Options\n+    <$> argument str\n+        (  metavar \"DAR-FILE\"\n+        <> help \"DAR file to generate TypeScript bindings for\"\n+        )\n+    <*> strOption\n+        (  short 'o'\n+        <> metavar \"DIR\"\n+        <> help \"Output directory for the generated TypeScript files\"\n+        )\n+\n+optionsParserInfo :: ParserInfo Options\n+optionsParserInfo = info (optionsParser <**> helper)\n+    (  fullDesc\n+    <> progDesc \"Generate TypeScript bindings from a DAR\"\n+    )\n+\n+main :: IO ()\n+main = do\n+    opts@Options{..} <- execParser optionsParserInfo\n+    dar <- B.readFile optInputDar\n+    dalfs <- either fail pure $ DAR.readDalfs $ Zip.toArchive $ BSL.fromStrict dar\n+    forM_ (DAR.mainDalf dalfs : DAR.dalfs dalfs) $ \\dalf -> do\n+        (pkgId, pkg) <- either (fail . show)  pure $ Archive.decodeArchive Archive.DecodeAsMain (BSL.toStrict dalf)\n+        daml2ts opts pkgId pkg\n+\n+daml2ts :: Options -> PackageId -> Package -> IO ()\n+daml2ts Options{..} pkgId pkg = do\n+    let outputBaseDir = optOutputDir </> T.unpack (unPackageId pkgId)\n+    createDirectoryIfMissing True outputBaseDir\n+    T.writeFile (outputBaseDir </> \"packageId.ts\") $ T.unlines\n+        [\"export default '\" <> unPackageId pkgId <> \"';\"]\n+    forM_ (packageModules pkg) $ \\mod -> do\n+        Just (modPath, modName) <- pure $ unsnoc (map T.unpack (unModuleName (moduleName mod)))\n+        let outputDir = outputBaseDir </> joinPath (modPath)\n+        let outputFile = outputDir </> modName <.> \"ts\"\n+        putStrLn $ \"Generating \" ++ outputFile\n+        createDirectoryIfMissing True outputDir\n+        T.writeFile outputFile (genModule mod)"
  },
  {
    "id" : "1c8081cf-01a9-4477-8221-92e29001600e",
    "prId" : 3441,
    "comments" : [
      {
        "id" : "194f2f42-e7c9-424e-9a33-23c5b3a323d8",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "I don’t understand the logic here. It looks like given the module name `[\"X\",\"Y\",\"Z\"]` you first split it into `[X\",\"Y\"]` and \"Z\" only to then turn it into `\"X/Y\"` and `\"Z.ts\"` and then you join them back to `\"X/Y/Z.ts\"`. Why don’t we just do something like `joinPath [\"X\", \"Y\", \"Z\"] <.> \"ts\"`?",
        "createdAt" : "2019-11-19T08:18:44Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "5f77f4e5-c28a-4732-9f2d-68dee4f0ca6d",
        "parentId" : "194f2f42-e7c9-424e-9a33-23c5b3a323d8",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "I need the \"X/Y\" part to call `createDirectoryIfMissing` a few lines below.",
        "createdAt" : "2019-11-19T08:50:33Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "14c85bbf-01e8-448f-b612-faeb5ebb684d",
        "parentId" : "194f2f42-e7c9-424e-9a33-23c5b3a323d8",
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "`createDirectoryIfMissing True (takeDirectory file)` is imho easier to understand.",
        "createdAt" : "2019-11-19T08:56:47Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "4b866a0e-d313-43d3-82b0-4612bd2627c2",
        "parentId" : "194f2f42-e7c9-424e-9a33-23c5b3a323d8",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "You're absolutely right. My interacting-with-the-real-world-Haskell is apparently a bit rusty. :(",
        "createdAt" : "2019-11-19T09:32:24Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "eff993c856bef39dda178c0b0ca7b3cc76f89f26",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,248 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+module Main (main) where\n+\n+import qualified DA.Daml.LF.Proto3.Archive as Archive\n+import qualified DA.Daml.LF.Reader as DAR\n+import qualified DA.Pretty\n+import qualified Data.ByteString as B\n+import qualified Data.ByteString.Lazy as BSL\n+import qualified Data.NameMap as NM\n+import qualified Data.Set as Set\n+import qualified Data.Set.Lens as Set\n+import qualified Data.Text as T\n+import qualified Data.Text.IO as T\n+import qualified \"zip-archive\" Codec.Archive.Zip as Zip\n+\n+import Control.Monad\n+import DA.Daml.LF.Ast\n+import DA.Daml.LF.Ast.Optics\n+import Data.List.Extra\n+import Options.Applicative\n+import System.Directory\n+import System.FilePath\n+\n+data Options = Options\n+    { optInputDar :: FilePath\n+    , optOutputDir :: FilePath\n+    }\n+\n+optionsParser :: Parser Options\n+optionsParser = Options\n+    <$> argument str\n+        (  metavar \"DAR-FILE\"\n+        <> help \"DAR file to generate TypeScript bindings for\"\n+        )\n+    <*> strOption\n+        (  short 'o'\n+        <> metavar \"DIR\"\n+        <> help \"Output directory for the generated TypeScript files\"\n+        )\n+\n+optionsParserInfo :: ParserInfo Options\n+optionsParserInfo = info (optionsParser <**> helper)\n+    (  fullDesc\n+    <> progDesc \"Generate TypeScript bindings from a DAR\"\n+    )\n+\n+main :: IO ()\n+main = do\n+    opts@Options{..} <- execParser optionsParserInfo\n+    dar <- B.readFile optInputDar\n+    dalfs <- either fail pure $ DAR.readDalfs $ Zip.toArchive $ BSL.fromStrict dar\n+    forM_ (DAR.mainDalf dalfs : DAR.dalfs dalfs) $ \\dalf -> do\n+        (pkgId, pkg) <- either (fail . show)  pure $ Archive.decodeArchive Archive.DecodeAsMain (BSL.toStrict dalf)\n+        daml2ts opts pkgId pkg\n+\n+daml2ts :: Options -> PackageId -> Package -> IO ()\n+daml2ts Options{..} pkgId pkg = do\n+    let outputBaseDir = optOutputDir </> T.unpack (unPackageId pkgId)\n+    createDirectoryIfMissing True outputBaseDir\n+    T.writeFile (outputBaseDir </> \"packageId.ts\") $ T.unlines\n+        [\"export default '\" <> unPackageId pkgId <> \"';\"]\n+    forM_ (packageModules pkg) $ \\mod -> do\n+        Just (modPath, modName) <- pure $ unsnoc (map T.unpack (unModuleName (moduleName mod)))"
  },
  {
    "id" : "e2e05745-fc47-464f-a4ae-0bf58dc5724f",
    "prId" : 3441,
    "comments" : [
      {
        "id" : "751453bc-f837-40b0-8ed1-39b8a03cc47b",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Those relative imports make me sad :disappointed: ",
        "createdAt" : "2019-11-19T08:22:50Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "fd12b443-154f-4867-9326-0441c05063e5",
        "parentId" : "751453bc-f837-40b0-8ed1-39b8a03cc47b",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "That's apparently how JavaScript imports work. :|",
        "createdAt" : "2019-11-19T08:51:16Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "eff993c856bef39dda178c0b0ca7b3cc76f89f26",
    "line" : 87,
    "diffHunk" : "@@ -0,0 +1,248 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+module Main (main) where\n+\n+import qualified DA.Daml.LF.Proto3.Archive as Archive\n+import qualified DA.Daml.LF.Reader as DAR\n+import qualified DA.Pretty\n+import qualified Data.ByteString as B\n+import qualified Data.ByteString.Lazy as BSL\n+import qualified Data.NameMap as NM\n+import qualified Data.Set as Set\n+import qualified Data.Set.Lens as Set\n+import qualified Data.Text as T\n+import qualified Data.Text.IO as T\n+import qualified \"zip-archive\" Codec.Archive.Zip as Zip\n+\n+import Control.Monad\n+import DA.Daml.LF.Ast\n+import DA.Daml.LF.Ast.Optics\n+import Data.List.Extra\n+import Options.Applicative\n+import System.Directory\n+import System.FilePath\n+\n+data Options = Options\n+    { optInputDar :: FilePath\n+    , optOutputDir :: FilePath\n+    }\n+\n+optionsParser :: Parser Options\n+optionsParser = Options\n+    <$> argument str\n+        (  metavar \"DAR-FILE\"\n+        <> help \"DAR file to generate TypeScript bindings for\"\n+        )\n+    <*> strOption\n+        (  short 'o'\n+        <> metavar \"DIR\"\n+        <> help \"Output directory for the generated TypeScript files\"\n+        )\n+\n+optionsParserInfo :: ParserInfo Options\n+optionsParserInfo = info (optionsParser <**> helper)\n+    (  fullDesc\n+    <> progDesc \"Generate TypeScript bindings from a DAR\"\n+    )\n+\n+main :: IO ()\n+main = do\n+    opts@Options{..} <- execParser optionsParserInfo\n+    dar <- B.readFile optInputDar\n+    dalfs <- either fail pure $ DAR.readDalfs $ Zip.toArchive $ BSL.fromStrict dar\n+    forM_ (DAR.mainDalf dalfs : DAR.dalfs dalfs) $ \\dalf -> do\n+        (pkgId, pkg) <- either (fail . show)  pure $ Archive.decodeArchive Archive.DecodeAsMain (BSL.toStrict dalf)\n+        daml2ts opts pkgId pkg\n+\n+daml2ts :: Options -> PackageId -> Package -> IO ()\n+daml2ts Options{..} pkgId pkg = do\n+    let outputBaseDir = optOutputDir </> T.unpack (unPackageId pkgId)\n+    createDirectoryIfMissing True outputBaseDir\n+    T.writeFile (outputBaseDir </> \"packageId.ts\") $ T.unlines\n+        [\"export default '\" <> unPackageId pkgId <> \"';\"]\n+    forM_ (packageModules pkg) $ \\mod -> do\n+        Just (modPath, modName) <- pure $ unsnoc (map T.unpack (unModuleName (moduleName mod)))\n+        let outputDir = outputBaseDir </> joinPath (modPath)\n+        let outputFile = outputDir </> modName <.> \"ts\"\n+        putStrLn $ \"Generating \" ++ outputFile\n+        createDirectoryIfMissing True outputDir\n+        T.writeFile outputFile (genModule mod)\n+\n+dup :: a -> (a, a)\n+dup x = (x, x)\n+\n+genModule :: Module -> T.Text\n+genModule mod =\n+    let curModName = moduleName mod\n+        pkgRootPath\n+          | lenModName == 1 = \".\"\n+          | otherwise = T.intercalate \"/\" (replicate (lenModName - 1) \"..\")\n+          where\n+            lenModName = length (unModuleName curModName)\n+        tpls = moduleTemplates mod\n+    in\n+    T.unlines $\n+        [\"// Generated from \" <> T.intercalate \"/\" (unModuleName curModName) <> \".daml\"\n+        ,\"/* eslint-disable @typescript-eslint/camelcase */\"\n+        ,\"/* eslint-disable @typescript-eslint/no-unused-vars */\"\n+        ,\"/* eslint-disable @typescript-eslint/no-use-before-define */\"\n+        ,\"import * as daml from '@digitalasset/daml-json-types';\"\n+        ,\"import * as jtv from '@mojotech/json-type-validation';\"\n+        ,\"import packageId from '\" <> pkgRootPath <> \"/packageId';\""
  },
  {
    "id" : "82ae7e21-962d-4aff-abe0-cc0197f44e8e",
    "prId" : 3441,
    "comments" : [
      {
        "id" : "da7a9c73-fa7f-4ad9-95c1-590641663566",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "Why do we need to treat nested options specially?",
        "createdAt" : "2019-11-19T08:25:19Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "322b722f-4c9a-4603-924a-44179502c004",
        "parentId" : "da7a9c73-fa7f-4ad9-95c1-590641663566",
        "author" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "body" : "They have a different encoding, see https://docs.daml.com/json-api/lf-value-specification.html#optional. I just realized I'm also off for record fields of type `Optional _`. It's tracked on #3518 now as well.",
        "createdAt" : "2019-11-19T08:57:23Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "hurryabit",
          "name" : "Martin Huschenbett",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/11665611?u=7dbd00d5e7ea53919ed31dc4200f602ebca91c8f&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "eff993c856bef39dda178c0b0ca7b3cc76f89f26",
    "line" : 189,
    "diffHunk" : "@@ -0,0 +1,248 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+module Main (main) where\n+\n+import qualified DA.Daml.LF.Proto3.Archive as Archive\n+import qualified DA.Daml.LF.Reader as DAR\n+import qualified DA.Pretty\n+import qualified Data.ByteString as B\n+import qualified Data.ByteString.Lazy as BSL\n+import qualified Data.NameMap as NM\n+import qualified Data.Set as Set\n+import qualified Data.Set.Lens as Set\n+import qualified Data.Text as T\n+import qualified Data.Text.IO as T\n+import qualified \"zip-archive\" Codec.Archive.Zip as Zip\n+\n+import Control.Monad\n+import DA.Daml.LF.Ast\n+import DA.Daml.LF.Ast.Optics\n+import Data.List.Extra\n+import Options.Applicative\n+import System.Directory\n+import System.FilePath\n+\n+data Options = Options\n+    { optInputDar :: FilePath\n+    , optOutputDir :: FilePath\n+    }\n+\n+optionsParser :: Parser Options\n+optionsParser = Options\n+    <$> argument str\n+        (  metavar \"DAR-FILE\"\n+        <> help \"DAR file to generate TypeScript bindings for\"\n+        )\n+    <*> strOption\n+        (  short 'o'\n+        <> metavar \"DIR\"\n+        <> help \"Output directory for the generated TypeScript files\"\n+        )\n+\n+optionsParserInfo :: ParserInfo Options\n+optionsParserInfo = info (optionsParser <**> helper)\n+    (  fullDesc\n+    <> progDesc \"Generate TypeScript bindings from a DAR\"\n+    )\n+\n+main :: IO ()\n+main = do\n+    opts@Options{..} <- execParser optionsParserInfo\n+    dar <- B.readFile optInputDar\n+    dalfs <- either fail pure $ DAR.readDalfs $ Zip.toArchive $ BSL.fromStrict dar\n+    forM_ (DAR.mainDalf dalfs : DAR.dalfs dalfs) $ \\dalf -> do\n+        (pkgId, pkg) <- either (fail . show)  pure $ Archive.decodeArchive Archive.DecodeAsMain (BSL.toStrict dalf)\n+        daml2ts opts pkgId pkg\n+\n+daml2ts :: Options -> PackageId -> Package -> IO ()\n+daml2ts Options{..} pkgId pkg = do\n+    let outputBaseDir = optOutputDir </> T.unpack (unPackageId pkgId)\n+    createDirectoryIfMissing True outputBaseDir\n+    T.writeFile (outputBaseDir </> \"packageId.ts\") $ T.unlines\n+        [\"export default '\" <> unPackageId pkgId <> \"';\"]\n+    forM_ (packageModules pkg) $ \\mod -> do\n+        Just (modPath, modName) <- pure $ unsnoc (map T.unpack (unModuleName (moduleName mod)))\n+        let outputDir = outputBaseDir </> joinPath (modPath)\n+        let outputFile = outputDir </> modName <.> \"ts\"\n+        putStrLn $ \"Generating \" ++ outputFile\n+        createDirectoryIfMissing True outputDir\n+        T.writeFile outputFile (genModule mod)\n+\n+dup :: a -> (a, a)\n+dup x = (x, x)\n+\n+genModule :: Module -> T.Text\n+genModule mod =\n+    let curModName = moduleName mod\n+        pkgRootPath\n+          | lenModName == 1 = \".\"\n+          | otherwise = T.intercalate \"/\" (replicate (lenModName - 1) \"..\")\n+          where\n+            lenModName = length (unModuleName curModName)\n+        tpls = moduleTemplates mod\n+    in\n+    T.unlines $\n+        [\"// Generated from \" <> T.intercalate \"/\" (unModuleName curModName) <> \".daml\"\n+        ,\"/* eslint-disable @typescript-eslint/camelcase */\"\n+        ,\"/* eslint-disable @typescript-eslint/no-unused-vars */\"\n+        ,\"/* eslint-disable @typescript-eslint/no-use-before-define */\"\n+        ,\"import * as daml from '@digitalasset/daml-json-types';\"\n+        ,\"import * as jtv from '@mojotech/json-type-validation';\"\n+        ,\"import packageId from '\" <> pkgRootPath <> \"/packageId';\"\n+        ] ++\n+        [\"import * as \" <> modNameStr <> \" from '\" <> pkgRootPath <> \"/\" <> pkgRefStr <> T.intercalate \"/\" (unModuleName modName) <> \"';\"\n+        | modRef@(pkgRef, modName) <- Set.toList (Set.setOf moduleModuleRef mod)\n+        , Just modNameStr <- [genModuleRef curModName modRef]\n+        , let pkgRefStr = case pkgRef of\n+                PRSelf -> \"\"\n+                PRImport pkgId -> \"../\" <> unPackageId pkgId <> \"/\"\n+        ] ++\n+        [ \"\"\n+        ,\"const moduleName = '\" <> T.intercalate \".\" (unModuleName curModName) <> \"';\"\n+        ,\"const templateId = (entityName: string): daml.TemplateId => ({packageId, moduleName, entityName});\"\n+        ] ++\n+        concat\n+        [ [\"\"] ++ def' ++ ser\n+        | def <- NM.toList (moduleDataTypes mod)\n+        , getIsSerializable (dataSerializable def)\n+        , let (def', ser) = genDefDataType curModName tpls def\n+        ]\n+\n+genDefDataType :: ModuleName -> NM.NameMap Template -> DefDataType -> ([T.Text], [T.Text])\n+genDefDataType curModName tpls def = case unTypeConName (dataTypeCon def) of\n+    [] -> error \"IMPOSSIBLE: empty type constructor name\"\n+    _:_:_ -> error \"TODO(MH): multi-part type constructor names\"\n+    [conName] -> case dataCons def of\n+        DataVariant{} -> (makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"])  -- TODO(MH): make variants type safe\n+        DataEnum{} -> (makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"])  -- TODO(MH): make enum types type safe\n+        DataRecord fields ->\n+            let (fieldNames, fieldTypesLf) = unzip [(unFieldName x, t) | (x, t) <- fields]\n+                (fieldTypesTs, fieldSers) = unzip (map (genType curModName) fieldTypesLf)\n+                typeDesc =\n+                    [\"{\"] ++\n+                    [\"  \" <> x <> \": \" <> t <> \";\" | (x, t) <- zip fieldNames fieldTypesTs] ++\n+                    [\"};\"]\n+                serDesc =\n+                    [\"() => jtv.object({\"] ++\n+                    [\"  \" <> x <> \": \" <> ser <> \".decoder(),\" | (x, ser) <- zip fieldNames fieldSers] ++\n+                    [\"}),\"]\n+            in\n+            case NM.lookup (dataTypeCon def) tpls of\n+                Nothing -> (makeType typeDesc, makeSer serDesc)\n+                Just tpl ->\n+                    let chcs =\n+                            [(unChoiceName (chcName chc), t)\n+                            | chc <- NM.toList (tplChoices tpl)\n+                            , let (t, _) = genType curModName (snd (chcArgBinder chc))\n+                            ]\n+                        dict =\n+                            [\"export const \" <> conName <> \": daml.Template<\" <> conName <> \"> & {\"] ++\n+                            [\"  \" <> x <> \": daml.Choice<\" <> conName <> \", \" <> t <> \">;\" | (x, t) <- chcs] ++\n+                            [\"} = {\"\n+                            ] ++\n+                            [\"  templateId: templateId('\" <> conName <> \"'),\"\n+                            ] ++\n+                            map (\"  \" <>) (onHead (\"decoder: \" <>) serDesc) ++\n+                            concat\n+                            [ [\"  \" <> x <> \": {\"\n+                              ,\"    template: undefined as unknown as daml.Template<\" <> conName <> \">,\"\n+                              ,\"    choiceName: '\" <> x <> \"',\"\n+                              ,\"    decoder: \" <> t <> \".decoder,\"\n+                              ,\"  },\"\n+                              ]\n+                            | (x, t) <- chcs\n+                            ] ++\n+                            [\"};\"]\n+                        knots =\n+                            [conName <> \".\" <> x <> \".template = \" <> conName <> \";\" | (x, _) <- chcs]\n+                    in\n+                    (makeType typeDesc, dict ++ knots)\n+      where\n+        paramNames = map (unTypeVarName . fst) (dataParams def)\n+        typeParams\n+          | null paramNames = \"\"\n+          | otherwise = \"<\" <> T.intercalate \", \" paramNames <> \">\"\n+        serParam paramName = paramName <> \": daml.Serializable<\" <> paramName <> \">\"\n+        serHeader\n+          | null paramNames = \": daml.Serializable<\" <> conName <> \"> =\"\n+          | otherwise = \" = \" <> typeParams <> \"(\" <> T.intercalate \", \" (map serParam paramNames) <> \"): daml.Serializable<\" <> conName <> typeParams <> \"> =>\"\n+        makeType = onHead (\\x -> \"export type \" <> conName <> typeParams <> \" = \" <> x)\n+        makeSer serDesc =\n+            [\"export const \" <> conName <> serHeader <> \" ({\"] ++\n+            map (\"  \" <>) (onHead (\"decoder: \" <>) serDesc) ++\n+            [\"});\"]\n+\n+genType :: ModuleName -> Type -> (T.Text, T.Text)\n+genType curModName = go\n+  where\n+    go = \\case\n+        TVar v -> dup (unTypeVarName v)\n+        TUnit -> (\"{}\", \"daml.Unit\")\n+        TBool -> (\"boolean\", \"daml.Bool\")\n+        TInt64 -> dup \"daml.Int\"\n+        TDecimal -> dup \"daml.Decimal\"\n+        TNumeric _ -> dup \"daml.Numeric\"  -- TODO(MH): Figure out what to do with the scale.\n+        TText -> (\"string\", \"daml.Text\")\n+        TTimestamp -> dup \"daml.Time\"\n+        TParty -> dup \"daml.Party\"\n+        TDate -> dup \"daml.Date\"\n+        TList t ->\n+            let (t', ser) = go t\n+            in\n+            (t' <> \"[]\", \"daml.List(\" <> ser <> \")\")\n+        TOptional (TOptional _) -> error \"TODO(MH): nested optionals\""
  },
  {
    "id" : "dd055351-4bad-4f0d-a6c6-a7250bbcb363",
    "prId" : 3441,
    "comments" : [
      {
        "id" : "c44c45cc-50c7-45bc-9692-d70332319afc",
        "parentId" : null,
        "author" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "body" : "```suggestion\r\n        TTuple{} -> error \"IMPOSSIBLE: structural record not serializable\"\r\n```",
        "createdAt" : "2019-11-19T08:25:57Z",
        "updatedAt" : "2019-11-19T15:10:10Z",
        "lastEditedBy" : {
          "login" : "cocreature",
          "name" : "Moritz Kiefer",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/1313584?u=7864421488a876940b33e865c4b0091925617ca7&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "eff993c856bef39dda178c0b0ca7b3cc76f89f26",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,248 @@\n+-- Copyright (c) 2019 The DAML Authors. All rights reserved.\n+-- SPDX-License-Identifier: Apache-2.0\n+module Main (main) where\n+\n+import qualified DA.Daml.LF.Proto3.Archive as Archive\n+import qualified DA.Daml.LF.Reader as DAR\n+import qualified DA.Pretty\n+import qualified Data.ByteString as B\n+import qualified Data.ByteString.Lazy as BSL\n+import qualified Data.NameMap as NM\n+import qualified Data.Set as Set\n+import qualified Data.Set.Lens as Set\n+import qualified Data.Text as T\n+import qualified Data.Text.IO as T\n+import qualified \"zip-archive\" Codec.Archive.Zip as Zip\n+\n+import Control.Monad\n+import DA.Daml.LF.Ast\n+import DA.Daml.LF.Ast.Optics\n+import Data.List.Extra\n+import Options.Applicative\n+import System.Directory\n+import System.FilePath\n+\n+data Options = Options\n+    { optInputDar :: FilePath\n+    , optOutputDir :: FilePath\n+    }\n+\n+optionsParser :: Parser Options\n+optionsParser = Options\n+    <$> argument str\n+        (  metavar \"DAR-FILE\"\n+        <> help \"DAR file to generate TypeScript bindings for\"\n+        )\n+    <*> strOption\n+        (  short 'o'\n+        <> metavar \"DIR\"\n+        <> help \"Output directory for the generated TypeScript files\"\n+        )\n+\n+optionsParserInfo :: ParserInfo Options\n+optionsParserInfo = info (optionsParser <**> helper)\n+    (  fullDesc\n+    <> progDesc \"Generate TypeScript bindings from a DAR\"\n+    )\n+\n+main :: IO ()\n+main = do\n+    opts@Options{..} <- execParser optionsParserInfo\n+    dar <- B.readFile optInputDar\n+    dalfs <- either fail pure $ DAR.readDalfs $ Zip.toArchive $ BSL.fromStrict dar\n+    forM_ (DAR.mainDalf dalfs : DAR.dalfs dalfs) $ \\dalf -> do\n+        (pkgId, pkg) <- either (fail . show)  pure $ Archive.decodeArchive Archive.DecodeAsMain (BSL.toStrict dalf)\n+        daml2ts opts pkgId pkg\n+\n+daml2ts :: Options -> PackageId -> Package -> IO ()\n+daml2ts Options{..} pkgId pkg = do\n+    let outputBaseDir = optOutputDir </> T.unpack (unPackageId pkgId)\n+    createDirectoryIfMissing True outputBaseDir\n+    T.writeFile (outputBaseDir </> \"packageId.ts\") $ T.unlines\n+        [\"export default '\" <> unPackageId pkgId <> \"';\"]\n+    forM_ (packageModules pkg) $ \\mod -> do\n+        Just (modPath, modName) <- pure $ unsnoc (map T.unpack (unModuleName (moduleName mod)))\n+        let outputDir = outputBaseDir </> joinPath (modPath)\n+        let outputFile = outputDir </> modName <.> \"ts\"\n+        putStrLn $ \"Generating \" ++ outputFile\n+        createDirectoryIfMissing True outputDir\n+        T.writeFile outputFile (genModule mod)\n+\n+dup :: a -> (a, a)\n+dup x = (x, x)\n+\n+genModule :: Module -> T.Text\n+genModule mod =\n+    let curModName = moduleName mod\n+        pkgRootPath\n+          | lenModName == 1 = \".\"\n+          | otherwise = T.intercalate \"/\" (replicate (lenModName - 1) \"..\")\n+          where\n+            lenModName = length (unModuleName curModName)\n+        tpls = moduleTemplates mod\n+    in\n+    T.unlines $\n+        [\"// Generated from \" <> T.intercalate \"/\" (unModuleName curModName) <> \".daml\"\n+        ,\"/* eslint-disable @typescript-eslint/camelcase */\"\n+        ,\"/* eslint-disable @typescript-eslint/no-unused-vars */\"\n+        ,\"/* eslint-disable @typescript-eslint/no-use-before-define */\"\n+        ,\"import * as daml from '@digitalasset/daml-json-types';\"\n+        ,\"import * as jtv from '@mojotech/json-type-validation';\"\n+        ,\"import packageId from '\" <> pkgRootPath <> \"/packageId';\"\n+        ] ++\n+        [\"import * as \" <> modNameStr <> \" from '\" <> pkgRootPath <> \"/\" <> pkgRefStr <> T.intercalate \"/\" (unModuleName modName) <> \"';\"\n+        | modRef@(pkgRef, modName) <- Set.toList (Set.setOf moduleModuleRef mod)\n+        , Just modNameStr <- [genModuleRef curModName modRef]\n+        , let pkgRefStr = case pkgRef of\n+                PRSelf -> \"\"\n+                PRImport pkgId -> \"../\" <> unPackageId pkgId <> \"/\"\n+        ] ++\n+        [ \"\"\n+        ,\"const moduleName = '\" <> T.intercalate \".\" (unModuleName curModName) <> \"';\"\n+        ,\"const templateId = (entityName: string): daml.TemplateId => ({packageId, moduleName, entityName});\"\n+        ] ++\n+        concat\n+        [ [\"\"] ++ def' ++ ser\n+        | def <- NM.toList (moduleDataTypes mod)\n+        , getIsSerializable (dataSerializable def)\n+        , let (def', ser) = genDefDataType curModName tpls def\n+        ]\n+\n+genDefDataType :: ModuleName -> NM.NameMap Template -> DefDataType -> ([T.Text], [T.Text])\n+genDefDataType curModName tpls def = case unTypeConName (dataTypeCon def) of\n+    [] -> error \"IMPOSSIBLE: empty type constructor name\"\n+    _:_:_ -> error \"TODO(MH): multi-part type constructor names\"\n+    [conName] -> case dataCons def of\n+        DataVariant{} -> (makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"])  -- TODO(MH): make variants type safe\n+        DataEnum{} -> (makeType [\"unknown;\"], makeSer [\"jtv.unknownJson,\"])  -- TODO(MH): make enum types type safe\n+        DataRecord fields ->\n+            let (fieldNames, fieldTypesLf) = unzip [(unFieldName x, t) | (x, t) <- fields]\n+                (fieldTypesTs, fieldSers) = unzip (map (genType curModName) fieldTypesLf)\n+                typeDesc =\n+                    [\"{\"] ++\n+                    [\"  \" <> x <> \": \" <> t <> \";\" | (x, t) <- zip fieldNames fieldTypesTs] ++\n+                    [\"};\"]\n+                serDesc =\n+                    [\"() => jtv.object({\"] ++\n+                    [\"  \" <> x <> \": \" <> ser <> \".decoder(),\" | (x, ser) <- zip fieldNames fieldSers] ++\n+                    [\"}),\"]\n+            in\n+            case NM.lookup (dataTypeCon def) tpls of\n+                Nothing -> (makeType typeDesc, makeSer serDesc)\n+                Just tpl ->\n+                    let chcs =\n+                            [(unChoiceName (chcName chc), t)\n+                            | chc <- NM.toList (tplChoices tpl)\n+                            , let (t, _) = genType curModName (snd (chcArgBinder chc))\n+                            ]\n+                        dict =\n+                            [\"export const \" <> conName <> \": daml.Template<\" <> conName <> \"> & {\"] ++\n+                            [\"  \" <> x <> \": daml.Choice<\" <> conName <> \", \" <> t <> \">;\" | (x, t) <- chcs] ++\n+                            [\"} = {\"\n+                            ] ++\n+                            [\"  templateId: templateId('\" <> conName <> \"'),\"\n+                            ] ++\n+                            map (\"  \" <>) (onHead (\"decoder: \" <>) serDesc) ++\n+                            concat\n+                            [ [\"  \" <> x <> \": {\"\n+                              ,\"    template: undefined as unknown as daml.Template<\" <> conName <> \">,\"\n+                              ,\"    choiceName: '\" <> x <> \"',\"\n+                              ,\"    decoder: \" <> t <> \".decoder,\"\n+                              ,\"  },\"\n+                              ]\n+                            | (x, t) <- chcs\n+                            ] ++\n+                            [\"};\"]\n+                        knots =\n+                            [conName <> \".\" <> x <> \".template = \" <> conName <> \";\" | (x, _) <- chcs]\n+                    in\n+                    (makeType typeDesc, dict ++ knots)\n+      where\n+        paramNames = map (unTypeVarName . fst) (dataParams def)\n+        typeParams\n+          | null paramNames = \"\"\n+          | otherwise = \"<\" <> T.intercalate \", \" paramNames <> \">\"\n+        serParam paramName = paramName <> \": daml.Serializable<\" <> paramName <> \">\"\n+        serHeader\n+          | null paramNames = \": daml.Serializable<\" <> conName <> \"> =\"\n+          | otherwise = \" = \" <> typeParams <> \"(\" <> T.intercalate \", \" (map serParam paramNames) <> \"): daml.Serializable<\" <> conName <> typeParams <> \"> =>\"\n+        makeType = onHead (\\x -> \"export type \" <> conName <> typeParams <> \" = \" <> x)\n+        makeSer serDesc =\n+            [\"export const \" <> conName <> serHeader <> \" ({\"] ++\n+            map (\"  \" <>) (onHead (\"decoder: \" <>) serDesc) ++\n+            [\"});\"]\n+\n+genType :: ModuleName -> Type -> (T.Text, T.Text)\n+genType curModName = go\n+  where\n+    go = \\case\n+        TVar v -> dup (unTypeVarName v)\n+        TUnit -> (\"{}\", \"daml.Unit\")\n+        TBool -> (\"boolean\", \"daml.Bool\")\n+        TInt64 -> dup \"daml.Int\"\n+        TDecimal -> dup \"daml.Decimal\"\n+        TNumeric _ -> dup \"daml.Numeric\"  -- TODO(MH): Figure out what to do with the scale.\n+        TText -> (\"string\", \"daml.Text\")\n+        TTimestamp -> dup \"daml.Time\"\n+        TParty -> dup \"daml.Party\"\n+        TDate -> dup \"daml.Date\"\n+        TList t ->\n+            let (t', ser) = go t\n+            in\n+            (t' <> \"[]\", \"daml.List(\" <> ser <> \")\")\n+        TOptional (TOptional _) -> error \"TODO(MH): nested optionals\"\n+        TOptional t ->\n+            let (t', ser) = go t\n+            in\n+            (\"(\" <> t' <> \" | null)\", \"daml.Optional(\" <> ser <> \")\")\n+        TMap t  ->\n+            let (t', ser) = go t\n+            in\n+            (\"{ [key: string]: \" <> t' <> \" }\", \"daml.TextMap(\" <> ser <> \")\")\n+        TUpdate _ -> error \"IMPOSSIBLE: Update not serializable\"\n+        TScenario _ -> error \"IMPOSSIBLE: Scenario not serializable\"\n+        TContractId t ->\n+            let (t', ser) = go t\n+            in\n+            (\"daml.ContractId<\" <> t' <> \">\", \"daml.ContractId(\" <> ser <> \")\")\n+        TConApp con ts ->\n+            let (con', ser) = genTypeCon curModName con\n+                (ts', sers) = unzip (map go ts)\n+            in\n+            if null ts\n+                then (con', ser)\n+                else\n+                    ( con' <> \"<\" <> T.intercalate \", \" ts' <> \">\"\n+                    , ser <> \"(\" <> T.intercalate \", \" sers <> \")\"\n+                    )\n+        TCon _ -> error \"IMPOSSIBLE: lonely type constructor\"\n+        t@TApp{} -> error $ \"IMPOSSIBLE: type application not serializable - \" <> DA.Pretty.renderPretty t\n+        TBuiltin t -> error $ \"IMPOSSIBLE: partially applied primitive type not serializable - \" <> DA.Pretty.renderPretty t\n+        TForall{} -> error \"IMPOSSIBLE: universally quantified type not serializable\"\n+        TTuple{} -> error \"IMPOSSIBLE: structur record not serializable\""
  }
]