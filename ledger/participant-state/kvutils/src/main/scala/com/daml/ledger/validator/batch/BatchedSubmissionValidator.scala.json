[
  {
    "id" : "f1e33761-f762-4b32-a2bb-65bbfdae8170",
    "prId" : 7515,
    "comments" : [
      {
        "id" : "43082a29-9b3a-4ff5-905e-d920159bcd09",
        "parentId" : null,
        "author" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "body" : "Is this unit-tested anywhere? Perhaps not so important as we are going to have proper (i.e. non-reordering) integrity checks with this one.",
        "createdAt" : "2020-09-29T14:17:10Z",
        "updatedAt" : "2020-09-29T14:19:19Z",
        "lastEditedBy" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "ac8b2b9e-1c30-40b2-b4db-ce7251ee63b2",
        "parentId" : "43082a29-9b3a-4ff5-905e-d920159bcd09",
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Yes; the spec file had a test for serial commits which I merged into the other tests.",
        "createdAt" : "2020-09-29T14:21:41Z",
        "updatedAt" : "2020-09-29T14:21:41Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "9861bfec-dad8-4672-a7e7-2e3be7ad7c56",
        "parentId" : "43082a29-9b3a-4ff5-905e-d920159bcd09",
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "(And it's also tested by the integrity check tests.)",
        "createdAt" : "2020-09-29T14:24:37Z",
        "updatedAt" : "2020-09-29T14:24:37Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "2a03714d44102a50f8583de03c250ad3d4108d69",
    "line" : 7,
    "diffHunk" : "@@ -303,8 +303,8 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n             )\n         }\n       }\n-      // Commit the results.\n-      .mapAsync[Outputs6](params.commitParallelism) {\n+      // Commit the results. This must be done serially to ensure a deterministic set of writes.\n+      .mapAsync[Outputs6](1) {"
  },
  {
    "id" : "c013d6f3-822a-4df8-96f4-5ab31b6d3cc8",
    "prId" : 7215,
    "comments" : [
      {
        "id" : "5315571e-460d-4941-b46e-91e586da5bd8",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`submissionAggregator`",
        "createdAt" : "2020-08-31T13:34:42Z",
        "updatedAt" : "2020-08-31T13:34:43Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "0020dd8e089d897ae22c94ce2643c7d7f6073b04",
    "line" : 66,
    "diffHunk" : "@@ -126,23 +114,24 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n       commitStrategy: CommitStrategy[CommitResult]\n   )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n     withCorrelationIdLogged(correlationId) { implicit loggingContext =>\n-      ledgerDataExporter.addSubmission(\n-        submissionEnvelope,\n+      val exporterAggregator = ledgerDataExporter.addSubmission("
  },
  {
    "id" : "df24f70c-399d-4696-a4d8-b26210095159",
    "prId" : 7215,
    "comments" : [
      {
        "id" : "93f1f845-4d4f-4491-bce4-b9b9abcb1903",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`writeSetBuilder`",
        "createdAt" : "2020-08-31T13:34:59Z",
        "updatedAt" : "2020-08-31T13:34:59Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "0020dd8e089d897ae22c94ce2643c7d7f6073b04",
    "line" : 111,
    "diffHunk" : "@@ -231,7 +221,9 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n   private case class ValidatedSubmission(\n       correlatedSubmission: CorrelatedSubmission,\n       inputState: DamlInputState,\n-      logEntryAndState: LogEntryAndState)\n+      logEntryAndState: LogEntryAndState,\n+      exporterWriteSet: SubmissionAggregator.WriteSetBuilder,"
  },
  {
    "id" : "3133ee3e-7be1-4cae-83c1-1445fa7cb0b4",
    "prId" : 7215,
    "comments" : [
      {
        "id" : "51ad2bc3-11d9-4206-9df6-a5328a188886",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`submissionAggregator`",
        "createdAt" : "2020-08-31T13:35:09Z",
        "updatedAt" : "2020-08-31T13:35:09Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "0020dd8e089d897ae22c94ce2643c7d7f6073b04",
    "line" : 126,
    "diffHunk" : "@@ -253,13 +245,15 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n     */\n   private def processBatch(\n       participantId: ParticipantId,\n-      batchCorrelationId: CorrelationId,\n       recordTime: Timestamp,\n       indexedSubmissions: Source[Inputs, NotUsed],\n       damlLedgerStateReader: DamlLedgerStateReader,\n-      commitStrategy: CommitStrategy[CommitResult])(\n+      commitStrategy: CommitStrategy[CommitResult],\n+      exporterAggregator: SubmissionAggregator,"
  },
  {
    "id" : "a34bbe78-6833-46b5-b59f-a3676a7e76d2",
    "prId" : 7215,
    "comments" : [
      {
        "id" : "4aa48e03-27ff-496e-bbe2-fa32bf2acbf9",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`writeSetBuilder`",
        "createdAt" : "2020-08-31T13:35:23Z",
        "updatedAt" : "2020-08-31T13:35:23Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "0020dd8e089d897ae22c94ce2643c7d7f6073b04",
    "line" : 207,
    "diffHunk" : "@@ -332,8 +344,9 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n       participantId: ParticipantId,\n       recordTime: Timestamp,\n       correlatedSubmission: CorrelatedSubmission,\n-      inputState: DamlInputState)(\n-      implicit executionContext: ExecutionContext): Future[ValidatedSubmission] =\n+      inputState: DamlInputState,\n+      exporterWriteSet: SubmissionAggregator.WriteSetBuilder,"
  },
  {
    "id" : "aff19ff0-eb9f-4e9e-bbe0-20d86a638901",
    "prId" : 7215,
    "comments" : [
      {
        "id" : "b2e111f3-dd1f-4291-a656-b8ffd2118f92",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`writeSetBuilder`",
        "createdAt" : "2020-08-31T13:35:32Z",
        "updatedAt" : "2020-08-31T13:35:32Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "0020dd8e089d897ae22c94ce2643c7d7f6073b04",
    "line" : 228,
    "diffHunk" : "@@ -356,8 +369,9 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n       correlatedSubmission: CorrelatedSubmission,\n       inputState: DamlInputState,\n       logEntryAndState: LogEntryAndState,\n-      invalidatedKeys: mutable.Set[DamlStateKey])\n-    : scala.collection.immutable.Iterable[ValidatedSubmission] = {\n+      invalidatedKeys: mutable.Set[DamlStateKey],\n+      exporterWriteSet: SubmissionAggregator.WriteSetBuilder,"
  },
  {
    "id" : "4172aebe-0e20-4c46-98aa-364896a7bd9c",
    "prId" : 7215,
    "comments" : [
      {
        "id" : "87a3bf1a-69be-4003-a92a-a0135903ad9e",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`writeSetBuilder`",
        "createdAt" : "2020-08-31T13:35:41Z",
        "updatedAt" : "2020-08-31T13:35:41Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "0020dd8e089d897ae22c94ce2643c7d7f6073b04",
    "line" : 254,
    "diffHunk" : "@@ -389,23 +408,27 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n       correlatedSubmission: CorrelatedSubmission,\n       inputState: DamlInputState,\n       logEntryAndState: LogEntryAndState,\n-      commitStrategy: CommitStrategy[CommitResult])(\n-      implicit executionContext: ExecutionContext): Future[Unit] = {\n+      commitStrategy: CommitStrategy[CommitResult],\n+      exporterWriteSet: SubmissionAggregator.WriteSetBuilder,"
  },
  {
    "id" : "5b4d788b-1956-410b-98e4-cabb5e150018",
    "prId" : 6992,
    "comments" : [
      {
        "id" : "6a976847-d87e-4975-ac70-9cbac2751a89",
        "parentId" : null,
        "author" : {
          "login" : "S11001001",
          "name" : "Stephen Compall",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/219186?u=7b27ed58a578fe7d4983d1bab28c2f5608ed8739&v=4"
        },
        "body" : "With the additional implication that this `withSubmissionLoggingContext` call also does nothing, and can be removed.",
        "createdAt" : "2020-08-04T19:23:32Z",
        "updatedAt" : "2020-08-06T15:33:42Z",
        "lastEditedBy" : {
          "login" : "S11001001",
          "name" : "Stephen Compall",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/219186?u=7b27ed58a578fe7d4983d1bab28c2f5608ed8739&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "255abaac-fb24-4bca-b428-c812fba7d86f",
        "parentId" : "6a976847-d87e-4975-ac70-9cbac2751a89",
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Yup. This worries me, because it means we're not logging.\r\n\r\n@miklos-da, is this supposed to be logging somewhere?",
        "createdAt" : "2020-08-05T08:00:46Z",
        "updatedAt" : "2020-08-06T15:33:42Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "d055147f-c9ed-4b58-999f-dd8c75369a92",
        "parentId" : "6a976847-d87e-4975-ac70-9cbac2751a89",
        "author" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "body" : "Currently this uses a non-contextual logger but I believe this is preparation for contextual logging where the context is the correlation ID; if this is not the case (or if the usage of contextual logging is not coming shortly) then I'd remove it for now. @miklos-da can probably elaborate.",
        "createdAt" : "2020-08-05T09:20:43Z",
        "updatedAt" : "2020-08-06T15:33:42Z",
        "lastEditedBy" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "8ce0f600-7391-4aef-be3a-34cf4627d55a",
        "parentId" : "6a976847-d87e-4975-ac70-9cbac2751a89",
        "author" : {
          "login" : "S11001001",
          "name" : "Stephen Compall",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/219186?u=7b27ed58a578fe7d4983d1bab28c2f5608ed8739&v=4"
        },
        "body" : "Also considered in sandbox: https://github.com/digital-asset/daml/pull/7035/files#r465983041",
        "createdAt" : "2020-08-05T20:25:35Z",
        "updatedAt" : "2020-08-06T15:33:42Z",
        "lastEditedBy" : {
          "login" : "S11001001",
          "name" : "Stephen Compall",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/219186?u=7b27ed58a578fe7d4983d1bab28c2f5608ed8739&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "a472d0ca-9e95-4dbc-8609-532ba73838af",
        "parentId" : "6a976847-d87e-4975-ac70-9cbac2751a89",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "We just used this bit to add a correlation ID to all log events transparently, i.e., not requiring a previous context. Threading a logging context through the stack is to be done later.",
        "createdAt" : "2020-08-06T15:16:45Z",
        "updatedAt" : "2020-08-06T15:33:42Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "4666d04ce7a5dc19ce3b8a8b1a8e625aa07570e0",
    "line" : 55,
    "diffHunk" : "@@ -395,7 +392,7 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n       commitStrategy: CommitStrategy[CommitResult])(\n       implicit executionContext: ExecutionContext): Future[Unit] = {\n     val (logEntry, outputState) = logEntryAndState\n-    withSubmissionLoggingContext(correlatedSubmission) { implicit loggingContext =>\n+    withSubmissionLoggingContext(correlatedSubmission) { _ =>"
  },
  {
    "id" : "1fc78557-5c23-49fc-bb1a-d84258d835a6",
    "prId" : 6711,
    "comments" : [
      {
        "id" : "91379961-7cda-43e2-914c-674840850b61",
        "parentId" : null,
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "This parameter wasn't required.",
        "createdAt" : "2020-07-13T16:06:51Z",
        "updatedAt" : "2020-07-15T08:11:38Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "e6145fdda1728eb9dd00d6dc94b3e0058872bbb2",
    "line" : 4,
    "diffHunk" : "@@ -36,13 +36,11 @@ object BatchedSubmissionValidator {\n       committer: KeyValueCommitting,\n       conflictDetection: ConflictDetection,\n       metrics: Metrics,\n-      engine: Engine,"
  },
  {
    "id" : "badfcbd1-1e3a-4fc8-93d6-7a10fc54e268",
    "prId" : 6145,
    "comments" : [
      {
        "id" : "66406028-43a9-46a4-8896-5a9eec86a2c3",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Can you move this to the top, please? It's odd to see `val`s referred to before they're used.",
        "createdAt" : "2020-05-28T17:24:26Z",
        "updatedAt" : "2020-05-29T09:35:24Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "3a87b673-0b72-4d96-aba5-de9950ce27f1",
        "parentId" : "66406028-43a9-46a4-8896-5a9eec86a2c3",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Moved there.",
        "createdAt" : "2020-05-29T09:36:37Z",
        "updatedAt" : "2020-05-29T09:36:38Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "0447e8536ddc4746873fdfac379b8c59fcf24fc7",
    "line" : null,
    "diffHunk" : "@@ -402,41 +401,5 @@ class BatchedSubmissionValidator[CommitResult] private[validator] (\n     }\n   }\n \n-  private[batch] object Metrics {\n-    private val Prefix = MetricName.DAML :+ \"pkvutils\" :+ \"batch_validator\"\n-\n-    val validateAndCommit: Timer =\n-      metrics.registry.timer(Prefix :+ \"validate_and_commit\")\n-\n-    val openEnvelope: Timer =\n-      metrics.registry.timer(Prefix :+ \"open_envelope\")\n-\n-    val batchSizes: Histogram =\n-      metrics.registry.histogram(Prefix :+ \"batch_sizes\")\n-\n-    val receivedBatchSubmissionBytes: Histogram =\n-      metrics.registry.histogram(Prefix :+ \"received_batch_submission_bytes\")\n-\n-    val receivedSubmissionBytes: Histogram =\n-      metrics.registry.histogram(Prefix :+ \"received_submission_bytes\")\n-\n-    // Metrics for each stage. We both time and maintain a counter for each running stage.\n-    // With the counter we can track how many submissions we're processing in parallel.\n-    // We don't have metrics for stages 4 and 5 since they're trivial (collect and sort).\n-\n-    val decode: Timer = metrics.registry.timer(Prefix :+ \"decode\")\n-    val decodeRunning: Counter = metrics.registry.counter(Prefix :+ \"decode_running\")\n-\n-    val fetchInputs: Timer = metrics.registry.timer(Prefix :+ \"fetch_inputs\")\n-    val fetchInputsRunning: Counter = metrics.registry.counter(Prefix :+ \"fetch_inputs_running\")\n-\n-    val validate: Timer = metrics.registry.timer(Prefix :+ \"validate\")\n-    val validateRunning: Counter = metrics.registry.counter(Prefix :+ \"validate_running\")\n-\n-    val detectConflicts: Timer =\n-      metrics.registry.timer(Prefix :+ \"detect_conflicts\")\n-\n-    val commit: Timer = metrics.registry.timer(Prefix :+ \"commit\")\n-    val commitRunning: Counter = metrics.registry.counter(Prefix :+ \"commit_running\")\n-  }\n+  private[this] val metrics = damlMetrics.daml.kvutils.submission.validator"
  },
  {
    "id" : "69813976-5063-4342-aa7f-b0208040f2b6",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "643e1517-05c6-4463-ac6b-b0d3a9e1af4a",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "This gets a `CommitResult`, but that is then discarded. If we were to propagate this outwards, we can use this in the `InMemoryLedgerStateOperations` instead of getting the `log.size` again.",
        "createdAt" : "2020-05-20T07:22:20Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "eb522c52-72ee-428f-ad65-192d94d37c07",
        "parentId" : "643e1517-05c6-4463-ac6b-b0d3a9e1af4a",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Yes, that's intentional because this way we don't have to deal with multiple `CommitResult`s. I'm happy to add this in a separate PR, though, e.g., by taking the max of the `CommitResult`s and returning that instead of `Unit`. Does that work for you?",
        "createdAt" : "2020-05-20T08:54:50Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "8dbe1e53-30a4-4a2d-a52b-a7a2622f9114",
        "parentId" : "643e1517-05c6-4463-ac6b-b0d3a9e1af4a",
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Sounds good. I expect writing an API for some kind of reduce function will be quite a considerable change.",
        "createdAt" : "2020-05-20T10:56:47Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "a2f4d94d-3ed7-4ab6-8c20-08f6833a934c",
        "parentId" : "643e1517-05c6-4463-ac6b-b0d3a9e1af4a",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Agreed. To avoid that I'd first go with adding some default reduce function (e.g., max as the log offsets should be monotonically increasing anyway) and in case something else is needed one can handle that as part of the `CommitStrategy` and/or `LedgerWriter` implementation. For production ledgers the signaling mechanism is not necessarily tied to the validation logic as in case of the in-memory or SQL ledgers (e.g., the participant will be notified of new blocks after they have been committed which drives the dispatcher instead of the validation logic in a post-commit step).",
        "createdAt" : "2020-05-20T11:11:16Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "5c0e55dd-6126-4357-a614-e016f3d0e5a7",
        "parentId" : "643e1517-05c6-4463-ac6b-b0d3a9e1af4a",
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "You may not be able to do that; you don't know anything about `CommitStrategy`. But it doesn't matter for now.",
        "createdAt" : "2020-05-20T13:05:02Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "fb999705-8e85-4580-be9d-b01474f6dfc9",
        "parentId" : "643e1517-05c6-4463-ac6b-b0d3a9e1af4a",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Yeah, that's right, however, I was describing from the consumer's side, i.e., as you can pass in a separate `CommitStrategy` instance for each `validateAndCommit` call you can simply collect the log results and do something with them once the validation is finished.",
        "createdAt" : "2020-05-20T13:15:24Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : 400,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)\n+    DamlLogEntryId.newBuilder\n+      .setEntryId(prefixedHash)\n+      .build\n+  }\n+\n+  private def withCorrelationIdLogged[T](correlationId: CorrelationId)(\n+      f: LoggingContext => T): T = {\n+    newLoggingContext(\"correlationId\" -> correlationId) { logCtx =>\n+      f(logCtx)\n+    }\n+  }\n+\n+  private def withSubmissionLoggingContext[T](correlatedSubmission: CorrelatedSubmission)(\n+      f: LoggingContext => T): T =\n+    withCorrelationIdLogged(correlatedSubmission.correlationId)(f)\n+}\n+\n+/** Batch validator validates and commits DAML submission batches to a DAML ledger. */\n+class BatchedSubmissionValidator[CommitResult] private[validator] (\n+    params: BatchedSubmissionValidatorParameters,\n+    committer: KeyValueCommitting,\n+    engine: Engine,\n+    conflictDetection: ConflictDetection,\n+    metrics: Metrics) {\n+\n+  import BatchedSubmissionValidator._\n+\n+  private val logger = ContextualizedLogger.get(getClass)\n+\n+  /** Validate and commit a submission to the ledger.\n+    *\n+    * On errors the future is completed with [[com.daml.ledger.validator.ValidationFailed]]\n+    * and all unprocessed submissions are discarded. Note that some submissions may have already\n+    * been committed. It is up to the caller to discard, or not to, a partially successful batch.\n+    */\n+  def validateAndCommit(\n+      submissionEnvelope: ByteString,\n+      correlationId: CorrelationId,\n+      recordTimeInstant: Instant,\n+      participantId: ParticipantId,\n+      ledgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult]\n+  )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n+    withCorrelationIdLogged(correlationId) { implicit logCtx =>\n+      val recordTime = Time.Timestamp.assertFromInstant(recordTimeInstant)\n+      Timed.future(\n+        Metrics.validateAndCommit, {\n+          val result = Metrics.openEnvelope.time(() => Envelope.open(submissionEnvelope)) match {\n+            case Right(Envelope.SubmissionMessage(submission)) =>\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                singleSubmissionSource(submissionEnvelope, submission, correlationId),\n+                ledgerStateReader,\n+                commitStrategy\n+              )\n+\n+            case Right(Envelope.SubmissionBatchMessage(batch)) =>\n+              logger.trace(s\"Validating a batch of ${batch.getSubmissionsCount} submissions\")\n+              Metrics.batchSizes.update(batch.getSubmissionsCount)\n+              Metrics.receivedBatchSubmissionBytes.update(batch.getSerializedSize)\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                batchSubmissionSource(batch, correlationId),\n+                ledgerStateReader,\n+                commitStrategy)\n+\n+            case Right(other) =>\n+              Future.failed(\n+                ValidationFailed.ValidationError(\n+                  s\"Unexpected message in envelope: ${other.getClass.getSimpleName}\"))\n+\n+            case Left(error) =>\n+              Future.failed(ValidationFailed.ValidationError(s\"Cannot open envelope: $error\"))\n+          }\n+\n+          result\n+            .andThen {\n+              case Failure(exception) =>\n+                logger.error(s\"Validation failure: $exception\")\n+              case Success(_) =>\n+                ()\n+            }\n+        }\n+      )\n+    }\n+\n+  private def singleSubmissionSource(\n+      envelope: ByteString,\n+      submission: DamlSubmission,\n+      correlationId: CorrelationId): Source[Stage1, NotUsed] = {\n+    val logEntryId = bytesToLogEntryId(envelope)\n+    Source.single(Indexed(CorrelatedSubmission(correlationId, logEntryId, submission), 0L))\n+  }\n+\n+  private def batchSubmissionSource(batch: DamlSubmissionBatch, correlationId: CorrelationId)(\n+      implicit executionContext: ExecutionContext): Source[Stage1, NotUsed] =\n+    Source(\n+      Indexed\n+        .fromSeq(batch.getSubmissionsList.asScala\n+          .map(cs => cs.getCorrelationId -> cs.getSubmission))\n+        .to)\n+      .mapAsyncUnordered(params.cpuParallelism) {\n+        _.mapFuture {\n+          case (correlationId, submissionEnvelope) =>\n+            // Decompress and decode the submissions in parallel.\n+            Timed.timedAndTrackedFuture(\n+              Metrics.decode,\n+              Metrics.decodeRunning,\n+              Future {\n+                val submission = Envelope\n+                  .openSubmission(submissionEnvelope)\n+                  .fold(error => throw validator.ValidationFailed.ValidationError(error), identity)\n+                Metrics.receivedSubmissionBytes.update(submission.getSerializedSize)\n+                CorrelatedSubmission(\n+                  correlationId,\n+                  bytesToLogEntryId(submissionEnvelope),\n+                  submission)\n+              }\n+            )\n+        }\n+      }\n+\n+  private type DamlInputState = Map[DamlStateKey, Option[DamlStateValue]]\n+\n+  //\n+  // The following type aliases describe how the batch processing pipeline transforms the data:\n+  //\n+\n+  // The batch pipeline starts with a stream of correlated submissions that carry their original index\n+  // in the batch.\n+  private type Stage1 = Indexed[CorrelatedSubmission]\n+\n+  // The second stage resolves the inputs to each submission.\n+  private type FetchedInput = (CorrelatedSubmission, DamlInputState)\n+  private type Stage2 = Indexed[FetchedInput]\n+\n+  // Third stage validates the submission, adding in the validation results.\n+  private type ValidatedSubmission = (CorrelatedSubmission, DamlInputState, LogEntryAndState)\n+  private type Stage3 = Indexed[ValidatedSubmission]\n+\n+  // Fourth stage collects the results.\n+  private type Stage4 = List[Stage3]\n+\n+  // The fifth stage sorts the results and drops the index.\n+  private type Stage5 = ValidatedSubmission\n+\n+  // Sixth stage performs conflict detection and potentially drops conflicting results.\n+  private type Stage6 = Stage5\n+\n+  // The last stage commits the results.\n+  private type Stage7 = Unit\n+\n+  /** Validate and commit a batch of indexed DAML submissions.\n+    * See the type definitions above to understand the different stages in the\n+    * processing pipeline.\n+    */\n+  private def processBatch(\n+      participantId: ParticipantId,\n+      batchCorrelationId: CorrelationId,\n+      recordTime: Timestamp,\n+      indexedSubmissions: Source[Stage1, NotUsed],\n+      damlLedgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult])(\n+      implicit materializer: Materializer,\n+      executionContext: ExecutionContext,\n+      logCtx: LoggingContext): Future[Unit] =\n+    indexedSubmissions\n+    /** Stage1 => Stage2: Fetch the submission inputs in parallel. */\n+      .mapAsyncUnordered[Stage2](params.readParallelism) {\n+        _.mapFuture(fetchSubmissionInputs(_, damlLedgerStateReader))\n+      }\n+      /** Stage2 => Stage3: Validate the submissions in parallel. */\n+      .mapAsyncUnordered[Stage3](params.cpuParallelism) {\n+        _.mapFuture {\n+          case (correlatedSubmission, inputState) =>\n+            validateSubmission(participantId, recordTime, correlatedSubmission, inputState)\n+        }\n+      }\n+      /** Stage3 => Stage4: Collect the results */\n+      .fold(List.empty[Stage3]) {\n+        case (results: Stage4, result: Stage3) =>\n+          result :: results\n+      }\n+      /** Stage4 => Stage5: Sort the results and drop the index. */\n+      .mapConcat { results: Stage4 =>\n+        results.sortBy(_.index).map(_.value)\n+      }\n+      /** Stage5 => Stage6: Conflict detect and either recover or drop the result.  */\n+      .statefulMapConcat[Stage5] { () =>\n+        val invalidatedKeys = mutable.Set.empty[DamlStateKey]\n+\n+        {\n+          case (correlatedSubmission, inputState, logEntryAndOutputState) =>\n+            detectConflictsAndRecover(\n+              correlatedSubmission,\n+              inputState,\n+              logEntryAndOutputState,\n+              invalidatedKeys)\n+        }\n+      }\n+      /** Stage6 => Stage7: Commit the results. */\n+      .mapAsync[Stage7](params.commitParallelism) {\n+        case (correlatedSubmission, inputState, logEntryAndOutputState) =>\n+          commitResult(\n+            participantId,\n+            correlatedSubmission,\n+            inputState,\n+            logEntryAndOutputState,\n+            commitStrategy)\n+      }\n+      .runWith(Sink.ignore)\n+      .map(_ => ())\n+\n+  private def fetchSubmissionInputs(\n+      correlatedSubmission: CorrelatedSubmission,\n+      ledgerStateReader: DamlLedgerStateReader)(\n+      implicit executionContext: ExecutionContext): Future[FetchedInput] = {\n+    val inputKeys = correlatedSubmission.submission.getInputDamlStateList.asScala\n+    withSubmissionLoggingContext(correlatedSubmission) { implicit logCtx =>\n+      Timed.timedAndTrackedFuture(\n+        Metrics.fetchInputs,\n+        Metrics.fetchInputsRunning,\n+        ledgerStateReader\n+          .readState(inputKeys)\n+          .map { values =>\n+            (correlatedSubmission, inputKeys.zip(values).toMap)\n+          }\n+      )\n+    }\n+  }\n+\n+  private def validateSubmission(\n+      participantId: ParticipantId,\n+      recordTime: Timestamp,\n+      correlatedSubmission: CorrelatedSubmission,\n+      inputState: DamlInputState)(\n+      implicit executionContext: ExecutionContext): Future[ValidatedSubmission] =\n+    withSubmissionLoggingContext(correlatedSubmission) { implicit logCtx =>\n+      Timed.timedAndTrackedFuture(\n+        Metrics.validate,\n+        Metrics.validateRunning,\n+        Future {\n+          val logEntryAndState = committer.processSubmission(\n+            correlatedSubmission.logEntryId,\n+            recordTime,\n+            LedgerReader.DefaultConfiguration,\n+            correlatedSubmission.submission,\n+            participantId,\n+            inputState\n+          )\n+          (correlatedSubmission, inputState, logEntryAndState)\n+        }\n+      )\n+    }\n+\n+  private def detectConflictsAndRecover(\n+      correlatedSubmission: CorrelatedSubmission,\n+      inputState: DamlInputState,\n+      logEntryAndState: LogEntryAndState,\n+      invalidatedKeys: mutable.Set[DamlStateKey])\n+    : scala.collection.immutable.Iterable[ValidatedSubmission] = {\n+    val (logEntry, outputState) = logEntryAndState\n+    withSubmissionLoggingContext(correlatedSubmission) { implicit logCtx =>\n+      Timed.value(\n+        Metrics.detectConflicts, {\n+          conflictDetection\n+            .detectConflictsAndRecover(\n+              invalidatedKeys,\n+              inputState,\n+              logEntry,\n+              outputState\n+            )\n+            .map {\n+              case (newInvalidatedKeys, (newLogEntry, newState)) =>\n+                invalidatedKeys ++= newInvalidatedKeys\n+                (correlatedSubmission, inputState, (newLogEntry, newState)) :: Nil\n+            }\n+            .getOrElse {\n+              logger.info(\n+                s\"Submission ${correlatedSubmission.correlationId} dropped as it conflicted and recovery was not possible\")\n+              Nil\n+            }\n+        }\n+      )\n+    }\n+  }\n+\n+  private def commitResult(\n+      participantId: ParticipantId,\n+      correlatedSubmission: CorrelatedSubmission,\n+      inputState: DamlInputState,\n+      logEntryAndState: LogEntryAndState,\n+      commitStrategy: CommitStrategy[CommitResult])(\n+      implicit executionContext: ExecutionContext): Future[Unit] = {\n+    val (logEntry, outputState) = logEntryAndState\n+    withSubmissionLoggingContext(correlatedSubmission) { implicit logCtx =>\n+      Timed.timedAndTrackedFuture(\n+        Metrics.commit,\n+        Metrics.commitRunning,\n+        commitStrategy\n+          .commit(\n+            participantId,\n+            correlatedSubmission.correlationId,\n+            correlatedSubmission.logEntryId,\n+            logEntry,\n+            inputState,\n+            outputState)\n+          .map(_ => ())"
  },
  {
    "id" : "d004727d-ce11-4753-a72d-a109f266eaab",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "556aa5e3-a1d0-4db5-928f-f617c3585094",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "I find the naming here confusing. I would have expected a \"stage\" to be a function that goes from `A` to `B`. I think these might be better named as \"results\" or \"outputs\" (with the first one being the \"input\").",
        "createdAt" : "2020-05-20T07:28:55Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "a661ac3e-6824-4937-87de-f57b5565a68d",
        "parentId" : "556aa5e3-a1d0-4db5-928f-f617c3585094",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Renamed the types to be `Inputs` and `Outputs1`, `Outputs2`, etc. Can you check if this is less confusing, please?",
        "createdAt" : "2020-05-20T09:59:09Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "b734cb71-8e00-482b-b235-3619eab56897",
        "parentId" : "556aa5e3-a1d0-4db5-928f-f617c3585094",
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Sounds good to me.",
        "createdAt" : "2020-05-20T10:57:40Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)\n+    DamlLogEntryId.newBuilder\n+      .setEntryId(prefixedHash)\n+      .build\n+  }\n+\n+  private def withCorrelationIdLogged[T](correlationId: CorrelationId)(\n+      f: LoggingContext => T): T = {\n+    newLoggingContext(\"correlationId\" -> correlationId) { logCtx =>\n+      f(logCtx)\n+    }\n+  }\n+\n+  private def withSubmissionLoggingContext[T](correlatedSubmission: CorrelatedSubmission)(\n+      f: LoggingContext => T): T =\n+    withCorrelationIdLogged(correlatedSubmission.correlationId)(f)\n+}\n+\n+/** Batch validator validates and commits DAML submission batches to a DAML ledger. */\n+class BatchedSubmissionValidator[CommitResult] private[validator] (\n+    params: BatchedSubmissionValidatorParameters,\n+    committer: KeyValueCommitting,\n+    engine: Engine,\n+    conflictDetection: ConflictDetection,\n+    metrics: Metrics) {\n+\n+  import BatchedSubmissionValidator._\n+\n+  private val logger = ContextualizedLogger.get(getClass)\n+\n+  /** Validate and commit a submission to the ledger.\n+    *\n+    * On errors the future is completed with [[com.daml.ledger.validator.ValidationFailed]]\n+    * and all unprocessed submissions are discarded. Note that some submissions may have already\n+    * been committed. It is up to the caller to discard, or not to, a partially successful batch.\n+    */\n+  def validateAndCommit(\n+      submissionEnvelope: ByteString,\n+      correlationId: CorrelationId,\n+      recordTimeInstant: Instant,\n+      participantId: ParticipantId,\n+      ledgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult]\n+  )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n+    withCorrelationIdLogged(correlationId) { implicit logCtx =>\n+      val recordTime = Time.Timestamp.assertFromInstant(recordTimeInstant)\n+      Timed.future(\n+        Metrics.validateAndCommit, {\n+          val result = Metrics.openEnvelope.time(() => Envelope.open(submissionEnvelope)) match {\n+            case Right(Envelope.SubmissionMessage(submission)) =>\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                singleSubmissionSource(submissionEnvelope, submission, correlationId),\n+                ledgerStateReader,\n+                commitStrategy\n+              )\n+\n+            case Right(Envelope.SubmissionBatchMessage(batch)) =>\n+              logger.trace(s\"Validating a batch of ${batch.getSubmissionsCount} submissions\")\n+              Metrics.batchSizes.update(batch.getSubmissionsCount)\n+              Metrics.receivedBatchSubmissionBytes.update(batch.getSerializedSize)\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                batchSubmissionSource(batch, correlationId),\n+                ledgerStateReader,\n+                commitStrategy)\n+\n+            case Right(other) =>\n+              Future.failed(\n+                ValidationFailed.ValidationError(\n+                  s\"Unexpected message in envelope: ${other.getClass.getSimpleName}\"))\n+\n+            case Left(error) =>\n+              Future.failed(ValidationFailed.ValidationError(s\"Cannot open envelope: $error\"))\n+          }\n+\n+          result\n+            .andThen {\n+              case Failure(exception) =>\n+                logger.error(s\"Validation failure: $exception\")\n+              case Success(_) =>\n+                ()\n+            }\n+        }\n+      )\n+    }\n+\n+  private def singleSubmissionSource(\n+      envelope: ByteString,\n+      submission: DamlSubmission,\n+      correlationId: CorrelationId): Source[Stage1, NotUsed] = {\n+    val logEntryId = bytesToLogEntryId(envelope)\n+    Source.single(Indexed(CorrelatedSubmission(correlationId, logEntryId, submission), 0L))\n+  }\n+\n+  private def batchSubmissionSource(batch: DamlSubmissionBatch, correlationId: CorrelationId)(\n+      implicit executionContext: ExecutionContext): Source[Stage1, NotUsed] =\n+    Source(\n+      Indexed\n+        .fromSeq(batch.getSubmissionsList.asScala\n+          .map(cs => cs.getCorrelationId -> cs.getSubmission))\n+        .to)\n+      .mapAsyncUnordered(params.cpuParallelism) {\n+        _.mapFuture {\n+          case (correlationId, submissionEnvelope) =>\n+            // Decompress and decode the submissions in parallel.\n+            Timed.timedAndTrackedFuture(\n+              Metrics.decode,\n+              Metrics.decodeRunning,\n+              Future {\n+                val submission = Envelope\n+                  .openSubmission(submissionEnvelope)\n+                  .fold(error => throw validator.ValidationFailed.ValidationError(error), identity)\n+                Metrics.receivedSubmissionBytes.update(submission.getSerializedSize)\n+                CorrelatedSubmission(\n+                  correlationId,\n+                  bytesToLogEntryId(submissionEnvelope),\n+                  submission)\n+              }\n+            )\n+        }\n+      }\n+\n+  private type DamlInputState = Map[DamlStateKey, Option[DamlStateValue]]\n+\n+  //\n+  // The following type aliases describe how the batch processing pipeline transforms the data:\n+  //\n+\n+  // The batch pipeline starts with a stream of correlated submissions that carry their original index\n+  // in the batch.\n+  private type Stage1 = Indexed[CorrelatedSubmission]"
  },
  {
    "id" : "e378e894-8eaf-4da7-885c-6bce85123d8c",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "18b695e1-c6a6-40f2-b264-2d9c34818651",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "body" : "Pertaining to the above, I'd call this \"Stage 1\", which goes from \"Input\" to \"Output 1\" (or something like that).",
        "createdAt" : "2020-05-20T07:29:38Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar-DA",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars2.githubusercontent.com/u/60356447?u=f6cdfccc6ea4254bd7c212099bbac2c27a00a28c&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "ebe409d6-2ae9-4e56-b0f5-602dde795f9a",
        "parentId" : "18b695e1-c6a6-40f2-b264-2d9c34818651",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Removed the stage references from here -- now the comments are easier to read.",
        "createdAt" : "2020-05-20T09:59:46Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)\n+    DamlLogEntryId.newBuilder\n+      .setEntryId(prefixedHash)\n+      .build\n+  }\n+\n+  private def withCorrelationIdLogged[T](correlationId: CorrelationId)(\n+      f: LoggingContext => T): T = {\n+    newLoggingContext(\"correlationId\" -> correlationId) { logCtx =>\n+      f(logCtx)\n+    }\n+  }\n+\n+  private def withSubmissionLoggingContext[T](correlatedSubmission: CorrelatedSubmission)(\n+      f: LoggingContext => T): T =\n+    withCorrelationIdLogged(correlatedSubmission.correlationId)(f)\n+}\n+\n+/** Batch validator validates and commits DAML submission batches to a DAML ledger. */\n+class BatchedSubmissionValidator[CommitResult] private[validator] (\n+    params: BatchedSubmissionValidatorParameters,\n+    committer: KeyValueCommitting,\n+    engine: Engine,\n+    conflictDetection: ConflictDetection,\n+    metrics: Metrics) {\n+\n+  import BatchedSubmissionValidator._\n+\n+  private val logger = ContextualizedLogger.get(getClass)\n+\n+  /** Validate and commit a submission to the ledger.\n+    *\n+    * On errors the future is completed with [[com.daml.ledger.validator.ValidationFailed]]\n+    * and all unprocessed submissions are discarded. Note that some submissions may have already\n+    * been committed. It is up to the caller to discard, or not to, a partially successful batch.\n+    */\n+  def validateAndCommit(\n+      submissionEnvelope: ByteString,\n+      correlationId: CorrelationId,\n+      recordTimeInstant: Instant,\n+      participantId: ParticipantId,\n+      ledgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult]\n+  )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n+    withCorrelationIdLogged(correlationId) { implicit logCtx =>\n+      val recordTime = Time.Timestamp.assertFromInstant(recordTimeInstant)\n+      Timed.future(\n+        Metrics.validateAndCommit, {\n+          val result = Metrics.openEnvelope.time(() => Envelope.open(submissionEnvelope)) match {\n+            case Right(Envelope.SubmissionMessage(submission)) =>\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                singleSubmissionSource(submissionEnvelope, submission, correlationId),\n+                ledgerStateReader,\n+                commitStrategy\n+              )\n+\n+            case Right(Envelope.SubmissionBatchMessage(batch)) =>\n+              logger.trace(s\"Validating a batch of ${batch.getSubmissionsCount} submissions\")\n+              Metrics.batchSizes.update(batch.getSubmissionsCount)\n+              Metrics.receivedBatchSubmissionBytes.update(batch.getSerializedSize)\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                batchSubmissionSource(batch, correlationId),\n+                ledgerStateReader,\n+                commitStrategy)\n+\n+            case Right(other) =>\n+              Future.failed(\n+                ValidationFailed.ValidationError(\n+                  s\"Unexpected message in envelope: ${other.getClass.getSimpleName}\"))\n+\n+            case Left(error) =>\n+              Future.failed(ValidationFailed.ValidationError(s\"Cannot open envelope: $error\"))\n+          }\n+\n+          result\n+            .andThen {\n+              case Failure(exception) =>\n+                logger.error(s\"Validation failure: $exception\")\n+              case Success(_) =>\n+                ()\n+            }\n+        }\n+      )\n+    }\n+\n+  private def singleSubmissionSource(\n+      envelope: ByteString,\n+      submission: DamlSubmission,\n+      correlationId: CorrelationId): Source[Stage1, NotUsed] = {\n+    val logEntryId = bytesToLogEntryId(envelope)\n+    Source.single(Indexed(CorrelatedSubmission(correlationId, logEntryId, submission), 0L))\n+  }\n+\n+  private def batchSubmissionSource(batch: DamlSubmissionBatch, correlationId: CorrelationId)(\n+      implicit executionContext: ExecutionContext): Source[Stage1, NotUsed] =\n+    Source(\n+      Indexed\n+        .fromSeq(batch.getSubmissionsList.asScala\n+          .map(cs => cs.getCorrelationId -> cs.getSubmission))\n+        .to)\n+      .mapAsyncUnordered(params.cpuParallelism) {\n+        _.mapFuture {\n+          case (correlationId, submissionEnvelope) =>\n+            // Decompress and decode the submissions in parallel.\n+            Timed.timedAndTrackedFuture(\n+              Metrics.decode,\n+              Metrics.decodeRunning,\n+              Future {\n+                val submission = Envelope\n+                  .openSubmission(submissionEnvelope)\n+                  .fold(error => throw validator.ValidationFailed.ValidationError(error), identity)\n+                Metrics.receivedSubmissionBytes.update(submission.getSerializedSize)\n+                CorrelatedSubmission(\n+                  correlationId,\n+                  bytesToLogEntryId(submissionEnvelope),\n+                  submission)\n+              }\n+            )\n+        }\n+      }\n+\n+  private type DamlInputState = Map[DamlStateKey, Option[DamlStateValue]]\n+\n+  //\n+  // The following type aliases describe how the batch processing pipeline transforms the data:\n+  //\n+\n+  // The batch pipeline starts with a stream of correlated submissions that carry their original index\n+  // in the batch.\n+  private type Stage1 = Indexed[CorrelatedSubmission]\n+\n+  // The second stage resolves the inputs to each submission.\n+  private type FetchedInput = (CorrelatedSubmission, DamlInputState)\n+  private type Stage2 = Indexed[FetchedInput]\n+\n+  // Third stage validates the submission, adding in the validation results.\n+  private type ValidatedSubmission = (CorrelatedSubmission, DamlInputState, LogEntryAndState)\n+  private type Stage3 = Indexed[ValidatedSubmission]\n+\n+  // Fourth stage collects the results.\n+  private type Stage4 = List[Stage3]\n+\n+  // The fifth stage sorts the results and drops the index.\n+  private type Stage5 = ValidatedSubmission\n+\n+  // Sixth stage performs conflict detection and potentially drops conflicting results.\n+  private type Stage6 = Stage5\n+\n+  // The last stage commits the results.\n+  private type Stage7 = Unit\n+\n+  /** Validate and commit a batch of indexed DAML submissions.\n+    * See the type definitions above to understand the different stages in the\n+    * processing pipeline.\n+    */\n+  private def processBatch(\n+      participantId: ParticipantId,\n+      batchCorrelationId: CorrelationId,\n+      recordTime: Timestamp,\n+      indexedSubmissions: Source[Stage1, NotUsed],\n+      damlLedgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult])(\n+      implicit materializer: Materializer,\n+      executionContext: ExecutionContext,\n+      logCtx: LoggingContext): Future[Unit] =\n+    indexedSubmissions\n+    /** Stage1 => Stage2: Fetch the submission inputs in parallel. */"
  },
  {
    "id" : "088148b6-6794-4e55-a510-a574c6b051e4",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "eb930601-0919-46ae-aa89-2702110dbfd2",
        "parentId" : null,
        "author" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "body" : "No way to avoid this copy?",
        "createdAt" : "2020-05-22T15:42:47Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "b2abcd6f-4d51-4cf8-b72d-d614f1e94258",
        "parentId" : "eb930601-0919-46ae-aa89-2702110dbfd2",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "It's possible but didn't seem to be worth doing, i.e., the log entry ID has fixed length (64 bytes) whereas the submission may be significantly larger (and we don't copy that). `ByteString` does not have a public implementation that would allow working off of a mutable byte array.",
        "createdAt" : "2020-05-25T09:37:08Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : 85,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)"
  },
  {
    "id" : "f2e21b55-e418-42f2-9934-5e346741dee1",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "dba04e13-a9cb-4032-8fa7-9e3110acba69",
        "parentId" : null,
        "author" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "body" : "Should this be immediately (= upon call) or asynchronously (i.e. upon scheduling) determined? It is used in the subsequent future that performs the validation in a Future.",
        "createdAt" : "2020-05-22T15:44:52Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "9ec1d20b-b6f1-4351-aa14-3e6f4beeda0d",
        "parentId" : "dba04e13-a9cb-4032-8fa7-9e3110acba69",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "See comment https://github.com/digital-asset/daml/pull/6004#discussion_r429840574",
        "createdAt" : "2020-05-25T09:48:55Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : 130,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)\n+    DamlLogEntryId.newBuilder\n+      .setEntryId(prefixedHash)\n+      .build\n+  }\n+\n+  private def withCorrelationIdLogged[T](correlationId: CorrelationId)(\n+      f: LoggingContext => T): T = {\n+    newLoggingContext(\"correlationId\" -> correlationId) { logCtx =>\n+      f(logCtx)\n+    }\n+  }\n+\n+  private def withSubmissionLoggingContext[T](correlatedSubmission: CorrelatedSubmission)(\n+      f: LoggingContext => T): T =\n+    withCorrelationIdLogged(correlatedSubmission.correlationId)(f)\n+}\n+\n+/** Batch validator validates and commits DAML submission batches to a DAML ledger. */\n+class BatchedSubmissionValidator[CommitResult] private[validator] (\n+    params: BatchedSubmissionValidatorParameters,\n+    committer: KeyValueCommitting,\n+    engine: Engine,\n+    conflictDetection: ConflictDetection,\n+    metrics: Metrics) {\n+\n+  import BatchedSubmissionValidator._\n+\n+  private val logger = ContextualizedLogger.get(getClass)\n+\n+  /** Validate and commit a submission to the ledger.\n+    *\n+    * On errors the future is completed with [[com.daml.ledger.validator.ValidationFailed]]\n+    * and all unprocessed submissions are discarded. Note that some submissions may have already\n+    * been committed. It is up to the caller to discard, or not to, a partially successful batch.\n+    */\n+  def validateAndCommit(\n+      submissionEnvelope: ByteString,\n+      correlationId: CorrelationId,\n+      recordTimeInstant: Instant,\n+      participantId: ParticipantId,\n+      ledgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult]\n+  )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n+    withCorrelationIdLogged(correlationId) { implicit logCtx =>\n+      val recordTime = Time.Timestamp.assertFromInstant(recordTimeInstant)"
  },
  {
    "id" : "ad1de3e3-a70b-48c1-86e9-dfe379175b42",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "bbe1c7de-14d7-48e5-a0fa-105831c849be",
        "parentId" : null,
        "author" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "body" : "I'd rather use a case class here",
        "createdAt" : "2020-05-22T15:55:56Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "1c9d908e-0bb7-408e-bd4e-70c1dc2ccec4",
        "parentId" : "bbe1c7de-14d7-48e5-a0fa-105831c849be",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Good point -- switched to a case class instead of a type definition.",
        "createdAt" : "2020-05-25T10:52:52Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)\n+    DamlLogEntryId.newBuilder\n+      .setEntryId(prefixedHash)\n+      .build\n+  }\n+\n+  private def withCorrelationIdLogged[T](correlationId: CorrelationId)(\n+      f: LoggingContext => T): T = {\n+    newLoggingContext(\"correlationId\" -> correlationId) { logCtx =>\n+      f(logCtx)\n+    }\n+  }\n+\n+  private def withSubmissionLoggingContext[T](correlatedSubmission: CorrelatedSubmission)(\n+      f: LoggingContext => T): T =\n+    withCorrelationIdLogged(correlatedSubmission.correlationId)(f)\n+}\n+\n+/** Batch validator validates and commits DAML submission batches to a DAML ledger. */\n+class BatchedSubmissionValidator[CommitResult] private[validator] (\n+    params: BatchedSubmissionValidatorParameters,\n+    committer: KeyValueCommitting,\n+    engine: Engine,\n+    conflictDetection: ConflictDetection,\n+    metrics: Metrics) {\n+\n+  import BatchedSubmissionValidator._\n+\n+  private val logger = ContextualizedLogger.get(getClass)\n+\n+  /** Validate and commit a submission to the ledger.\n+    *\n+    * On errors the future is completed with [[com.daml.ledger.validator.ValidationFailed]]\n+    * and all unprocessed submissions are discarded. Note that some submissions may have already\n+    * been committed. It is up to the caller to discard, or not to, a partially successful batch.\n+    */\n+  def validateAndCommit(\n+      submissionEnvelope: ByteString,\n+      correlationId: CorrelationId,\n+      recordTimeInstant: Instant,\n+      participantId: ParticipantId,\n+      ledgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult]\n+  )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n+    withCorrelationIdLogged(correlationId) { implicit logCtx =>\n+      val recordTime = Time.Timestamp.assertFromInstant(recordTimeInstant)\n+      Timed.future(\n+        Metrics.validateAndCommit, {\n+          val result = Metrics.openEnvelope.time(() => Envelope.open(submissionEnvelope)) match {\n+            case Right(Envelope.SubmissionMessage(submission)) =>\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                singleSubmissionSource(submissionEnvelope, submission, correlationId),\n+                ledgerStateReader,\n+                commitStrategy\n+              )\n+\n+            case Right(Envelope.SubmissionBatchMessage(batch)) =>\n+              logger.trace(s\"Validating a batch of ${batch.getSubmissionsCount} submissions\")\n+              Metrics.batchSizes.update(batch.getSubmissionsCount)\n+              Metrics.receivedBatchSubmissionBytes.update(batch.getSerializedSize)\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                batchSubmissionSource(batch, correlationId),\n+                ledgerStateReader,\n+                commitStrategy)\n+\n+            case Right(other) =>\n+              Future.failed(\n+                ValidationFailed.ValidationError(\n+                  s\"Unexpected message in envelope: ${other.getClass.getSimpleName}\"))\n+\n+            case Left(error) =>\n+              Future.failed(ValidationFailed.ValidationError(s\"Cannot open envelope: $error\"))\n+          }\n+\n+          result\n+            .andThen {\n+              case Failure(exception) =>\n+                logger.error(s\"Validation failure: $exception\")\n+              case Success(_) =>\n+                ()\n+            }\n+        }\n+      )\n+    }\n+\n+  private def singleSubmissionSource(\n+      envelope: ByteString,\n+      submission: DamlSubmission,\n+      correlationId: CorrelationId): Source[Inputs, NotUsed] = {\n+    val logEntryId = bytesToLogEntryId(envelope)\n+    Source.single(Indexed(CorrelatedSubmission(correlationId, logEntryId, submission), 0L))\n+  }\n+\n+  private def batchSubmissionSource(batch: DamlSubmissionBatch, correlationId: CorrelationId)(\n+      implicit executionContext: ExecutionContext): Source[Inputs, NotUsed] =\n+    Source(\n+      Indexed\n+        .fromSeq(batch.getSubmissionsList.asScala\n+          .map(cs => cs.getCorrelationId -> cs.getSubmission))\n+        .to)\n+      .mapAsyncUnordered(params.cpuParallelism) {\n+        _.mapFuture {\n+          case (correlationId, submissionEnvelope) =>\n+            // Decompress and decode the submissions in parallel.\n+            Timed.timedAndTrackedFuture(\n+              Metrics.decode,\n+              Metrics.decodeRunning,\n+              Future {\n+                val submission = Envelope\n+                  .openSubmission(submissionEnvelope)\n+                  .fold(error => throw validator.ValidationFailed.ValidationError(error), identity)\n+                Metrics.receivedSubmissionBytes.update(submission.getSerializedSize)\n+                CorrelatedSubmission(\n+                  correlationId,\n+                  bytesToLogEntryId(submissionEnvelope),\n+                  submission)\n+              }\n+            )\n+        }\n+      }\n+\n+  private type DamlInputState = Map[DamlStateKey, Option[DamlStateValue]]\n+\n+  //\n+  // The following type aliases describe how the batch processing pipeline transforms the data:\n+  //\n+\n+  // The batch pipeline starts with a stream of correlated submissions that carry their original index\n+  // in the batch.\n+  private type Inputs = Indexed[CorrelatedSubmission]\n+\n+  // The second stage resolves the inputs to each submission.\n+  private type FetchedInput = (CorrelatedSubmission, DamlInputState)\n+  private type Outputs1 = Indexed[FetchedInput]\n+\n+  // Third stage validates the submission, adding in the validation results.\n+  private type ValidatedSubmission = (CorrelatedSubmission, DamlInputState, LogEntryAndState)\n+  private type Outputs2 = Indexed[ValidatedSubmission]\n+\n+  // Fourth stage collects the results.\n+  private type Outputs3 = List[Outputs2]\n+\n+  // The fifth stage sorts the results and drops the index.\n+  private type Outputs4 = ValidatedSubmission\n+\n+  // Sixth stage performs conflict detection and potentially drops conflicting results.\n+  private type Outputs5 = Outputs4\n+\n+  // The last stage commits the results.\n+  private type Outputs6 = Unit\n+\n+  /** Validate and commit a batch of indexed DAML submissions.\n+    * See the type definitions above to understand the different stages in the\n+    * processing pipeline.\n+    */\n+  private def processBatch(\n+      participantId: ParticipantId,\n+      batchCorrelationId: CorrelationId,\n+      recordTime: Timestamp,\n+      indexedSubmissions: Source[Inputs, NotUsed],\n+      damlLedgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult])(\n+      implicit materializer: Materializer,\n+      executionContext: ExecutionContext,\n+      logCtx: LoggingContext): Future[Unit] =\n+    indexedSubmissions\n+    // Fetch the submission inputs in parallel.\n+      .mapAsyncUnordered[Outputs1](params.readParallelism) {\n+        _.mapFuture(fetchSubmissionInputs(_, damlLedgerStateReader))\n+      }\n+      // Validate the submissions in parallel.\n+      .mapAsyncUnordered[Outputs2](params.cpuParallelism) {\n+        _.mapFuture {\n+          case (correlatedSubmission, inputState) =>\n+            validateSubmission(participantId, recordTime, correlatedSubmission, inputState)\n+        }\n+      }\n+      // Collect the results.\n+      .fold(List.empty[Outputs2]) {\n+        case (results: Outputs3, result: Outputs2) =>\n+          result :: results\n+      }\n+      // Sort the results and drop the index.\n+      .mapConcat[Outputs4] { results: Outputs3 =>\n+        results.sortBy(_.index).map(_.value)\n+      }\n+      // Conflict detect and either recover or drop the result.\n+      .statefulMapConcat[Outputs5] { () =>\n+        val invalidatedKeys = mutable.Set.empty[DamlStateKey]\n+\n+        {\n+          case (correlatedSubmission, inputState, logEntryAndOutputState) =>\n+            detectConflictsAndRecover(\n+              correlatedSubmission,\n+              inputState,\n+              logEntryAndOutputState,\n+              invalidatedKeys)\n+        }\n+      }\n+      // Commit the results.\n+      .mapAsync[Outputs6](params.commitParallelism) {\n+        case (correlatedSubmission, inputState, logEntryAndOutputState) =>\n+          commitResult(\n+            participantId,\n+            correlatedSubmission,\n+            inputState,\n+            logEntryAndOutputState,\n+            commitStrategy)\n+      }\n+      .runWith(Sink.ignore)\n+      .map(_ => ())\n+\n+  private def fetchSubmissionInputs(\n+      correlatedSubmission: CorrelatedSubmission,\n+      ledgerStateReader: DamlLedgerStateReader)(\n+      implicit executionContext: ExecutionContext): Future[FetchedInput] = {\n+    val inputKeys = correlatedSubmission.submission.getInputDamlStateList.asScala\n+    withSubmissionLoggingContext(correlatedSubmission) { implicit logCtx =>\n+      Timed.timedAndTrackedFuture(\n+        Metrics.fetchInputs,\n+        Metrics.fetchInputsRunning,\n+        ledgerStateReader\n+          .readState(inputKeys)\n+          .map { values =>\n+            (correlatedSubmission, inputKeys.zip(values).toMap)\n+          }\n+      )\n+    }\n+  }\n+\n+  private def validateSubmission(\n+      participantId: ParticipantId,\n+      recordTime: Timestamp,\n+      correlatedSubmission: CorrelatedSubmission,\n+      inputState: DamlInputState)(\n+      implicit executionContext: ExecutionContext): Future[ValidatedSubmission] =\n+    withSubmissionLoggingContext(correlatedSubmission) { implicit logCtx =>\n+      Timed.timedAndTrackedFuture(\n+        Metrics.validate,\n+        Metrics.validateRunning,\n+        Future {\n+          val logEntryAndState = committer.processSubmission(\n+            correlatedSubmission.logEntryId,\n+            recordTime,\n+            LedgerReader.DefaultConfiguration,\n+            correlatedSubmission.submission,\n+            participantId,\n+            inputState\n+          )\n+          (correlatedSubmission, inputState, logEntryAndState)"
  },
  {
    "id" : "a753674c-0d13-45c1-93e4-35f84bd405b7",
    "prId" : 6004,
    "comments" : [
      {
        "id" : "c33aa944-c52b-4e79-be24-92888d45bee2",
        "parentId" : null,
        "author" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "body" : "What's the performance impact of using `mapAsyncUnordered` VS. `mapAsync` in the validator? If not significant, we could use the latter and be fairer with submissions (i.e. earlier arrived ones have more chances of no conflicts and less risk of being dropped).",
        "createdAt" : "2020-05-22T16:45:27Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "fabiotudone-da",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/59609563?u=a3a8ac844c9aacd1d1bd319a77d1d0ac60d701a3&v=4"
        },
        "tags" : [
        ]
      },
      {
        "id" : "7e3ff5b2-7f8d-4d5f-8686-584d594b2513",
        "parentId" : "c33aa944-c52b-4e79-be24-92888d45bee2",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "`mapAsyncUnordered` allows simple submissions in the batch to go through the pipeline fast even if there are a few slower submissions being processed at the same time. We reorder submissions before conflict detection anyway.",
        "createdAt" : "2020-05-25T10:43:52Z",
        "updatedAt" : "2020-05-25T16:06:53Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
        ]
      }
    ],
    "commit" : "f5039a2c00da681659f3cc8423f9ddfc9d993996",
    "line" : 191,
    "diffHunk" : "@@ -0,0 +1,439 @@\n+// Copyright (c) 2020 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.validator.batch\n+\n+import java.security.MessageDigest\n+import java.time.Instant\n+\n+import akka.NotUsed\n+import akka.stream.Materializer\n+import akka.stream.scaladsl.{Sink, Source}\n+import com.codahale.metrics.{Counter, Histogram, Timer}\n+import com.daml.ledger.participant.state.kvutils.DamlKvutils._\n+import com.daml.ledger.participant.state.kvutils.api.LedgerReader\n+import com.daml.ledger.participant.state.kvutils.{Envelope, KeyValueCommitting}\n+import com.daml.ledger.participant.state.v1.ParticipantId\n+import com.daml.ledger.validator\n+import com.daml.ledger.validator.SubmissionValidator.LogEntryAndState\n+import com.daml.ledger.validator._\n+import com.daml.lf.data.Time\n+import com.daml.lf.data.Time.Timestamp\n+import com.daml.lf.engine.Engine\n+import com.daml.logging.LoggingContext.newLoggingContext\n+import com.daml.logging.{ContextualizedLogger, LoggingContext}\n+import com.daml.metrics.{MetricName, Metrics, Timed}\n+import com.google.protobuf.ByteString\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.concurrent.{ExecutionContext, Future}\n+import scala.util.{Failure, Success}\n+\n+object BatchedSubmissionValidator {\n+  def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      committer: KeyValueCommitting,\n+      conflictDetection: ConflictDetection,\n+      metrics: Metrics,\n+      engine: Engine)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      committer,\n+      engine,\n+      conflictDetection,\n+      metrics\n+    )\n+\n+  private[validator] def apply[CommitResult](\n+      params: BatchedSubmissionValidatorParameters,\n+      engine: Engine,\n+      metrics: Metrics)(\n+      implicit executionContext: ExecutionContext): BatchedSubmissionValidator[CommitResult] =\n+    new BatchedSubmissionValidator[CommitResult](\n+      params,\n+      new KeyValueCommitting(engine, metrics),\n+      engine,\n+      new ConflictDetection(metrics),\n+      metrics)\n+\n+  private type CorrelationId = String\n+\n+  /** A [[DamlSubmission]] with an associated correlation id and a log entry id computed\n+    * from the envelope. */\n+  private case class CorrelatedSubmission(\n+      correlationId: CorrelationId,\n+      logEntryId: DamlLogEntryId,\n+      submission: DamlSubmission)\n+\n+  private val LogEntryIdPrefix = \"0\"\n+\n+  // While the log entry ID is no longer the basis for deriving absolute contract IDs,\n+  // it is used for keying log entries / fragments. We may want to consider content addressing\n+  // instead and remove the whole concept of log entry identifiers.\n+  // For now this implementation uses a sha256 hash of the submission envelope in order to generate\n+  // deterministic log entry IDs.\n+  private def bytesToLogEntryId(bytes: ByteString): DamlLogEntryId = {\n+    val messageDigest = MessageDigest\n+      .getInstance(\"SHA-256\")\n+    messageDigest.update(bytes.asReadOnlyByteBuffer())\n+    val hash = messageDigest\n+      .digest()\n+      .map(\"%02x\" format _)\n+      .mkString\n+    val prefixedHash = ByteString.copyFromUtf8(LogEntryIdPrefix + hash)\n+    DamlLogEntryId.newBuilder\n+      .setEntryId(prefixedHash)\n+      .build\n+  }\n+\n+  private def withCorrelationIdLogged[T](correlationId: CorrelationId)(\n+      f: LoggingContext => T): T = {\n+    newLoggingContext(\"correlationId\" -> correlationId) { logCtx =>\n+      f(logCtx)\n+    }\n+  }\n+\n+  private def withSubmissionLoggingContext[T](correlatedSubmission: CorrelatedSubmission)(\n+      f: LoggingContext => T): T =\n+    withCorrelationIdLogged(correlatedSubmission.correlationId)(f)\n+}\n+\n+/** Batch validator validates and commits DAML submission batches to a DAML ledger. */\n+class BatchedSubmissionValidator[CommitResult] private[validator] (\n+    params: BatchedSubmissionValidatorParameters,\n+    committer: KeyValueCommitting,\n+    engine: Engine,\n+    conflictDetection: ConflictDetection,\n+    metrics: Metrics) {\n+\n+  import BatchedSubmissionValidator._\n+\n+  private val logger = ContextualizedLogger.get(getClass)\n+\n+  /** Validate and commit a submission to the ledger.\n+    *\n+    * On errors the future is completed with [[com.daml.ledger.validator.ValidationFailed]]\n+    * and all unprocessed submissions are discarded. Note that some submissions may have already\n+    * been committed. It is up to the caller to discard, or not to, a partially successful batch.\n+    */\n+  def validateAndCommit(\n+      submissionEnvelope: ByteString,\n+      correlationId: CorrelationId,\n+      recordTimeInstant: Instant,\n+      participantId: ParticipantId,\n+      ledgerStateReader: DamlLedgerStateReader,\n+      commitStrategy: CommitStrategy[CommitResult]\n+  )(implicit materializer: Materializer, executionContext: ExecutionContext): Future[Unit] =\n+    withCorrelationIdLogged(correlationId) { implicit logCtx =>\n+      val recordTime = Time.Timestamp.assertFromInstant(recordTimeInstant)\n+      Timed.future(\n+        Metrics.validateAndCommit, {\n+          val result = Metrics.openEnvelope.time(() => Envelope.open(submissionEnvelope)) match {\n+            case Right(Envelope.SubmissionMessage(submission)) =>\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                singleSubmissionSource(submissionEnvelope, submission, correlationId),\n+                ledgerStateReader,\n+                commitStrategy\n+              )\n+\n+            case Right(Envelope.SubmissionBatchMessage(batch)) =>\n+              logger.trace(s\"Validating a batch of ${batch.getSubmissionsCount} submissions\")\n+              Metrics.batchSizes.update(batch.getSubmissionsCount)\n+              Metrics.receivedBatchSubmissionBytes.update(batch.getSerializedSize)\n+              processBatch(\n+                participantId,\n+                correlationId,\n+                recordTime,\n+                batchSubmissionSource(batch, correlationId),\n+                ledgerStateReader,\n+                commitStrategy)\n+\n+            case Right(other) =>\n+              Future.failed(\n+                ValidationFailed.ValidationError(\n+                  s\"Unexpected message in envelope: ${other.getClass.getSimpleName}\"))\n+\n+            case Left(error) =>\n+              Future.failed(ValidationFailed.ValidationError(s\"Cannot open envelope: $error\"))\n+          }\n+\n+          result\n+            .andThen {\n+              case Failure(exception) =>\n+                logger.error(s\"Validation failure: $exception\")\n+              case Success(_) =>\n+                ()\n+            }\n+        }\n+      )\n+    }\n+\n+  private def singleSubmissionSource(\n+      envelope: ByteString,\n+      submission: DamlSubmission,\n+      correlationId: CorrelationId): Source[Inputs, NotUsed] = {\n+    val logEntryId = bytesToLogEntryId(envelope)\n+    Source.single(Indexed(CorrelatedSubmission(correlationId, logEntryId, submission), 0L))\n+  }\n+\n+  private def batchSubmissionSource(batch: DamlSubmissionBatch, correlationId: CorrelationId)(\n+      implicit executionContext: ExecutionContext): Source[Inputs, NotUsed] =\n+    Source(\n+      Indexed\n+        .fromSeq(batch.getSubmissionsList.asScala\n+          .map(cs => cs.getCorrelationId -> cs.getSubmission))\n+        .to)\n+      .mapAsyncUnordered(params.cpuParallelism) {"
  }
]