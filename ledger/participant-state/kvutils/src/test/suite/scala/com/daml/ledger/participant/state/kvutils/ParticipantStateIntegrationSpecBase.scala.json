[
  {
    "id" : "737ee192-a1c3-47d9-a35b-e6131d198601",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "fb758c57-f006-44d3-bf19-083ce7e0defc",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "Why not make these `abstract`?",
        "createdAt" : "2019-12-23T10:15:08Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "9582e552-e39a-4f55-986f-e0de61704c99",
        "parentId" : "fb758c57-f006-44d3-bf19-083ce7e0defc",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Fixed.",
        "createdAt" : "2020-01-06T17:28:26Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase\n+    extends AsyncWordSpec\n+    with BeforeAndAfterEach\n+    with AkkaBeforeAndAfterAll {\n+\n+  var ledgerId: LedgerString = _\n+  var ps: ReadService with WriteService = _\n+  var rt: Timestamp = _\n+\n+  def participantStateFactory(\n+      participantId: ParticipantId,\n+      ledgerId: LedgerString): ReadService with WriteService = ???\n+\n+  def currentRecordTime(): Timestamp = ???"
  },
  {
    "id" : "a7831c78-7933-4678-8520-fe3a25f30c3d",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "3536e024-c9c8-48a0-961e-5e7a648d1406",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "I ended up moving this to a _src/test/lib/scala_ directory so I can use it outside the module. Happy to push this to this branch if you like.",
        "createdAt" : "2019-12-23T10:25:23Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "f33dc010-6a59-4c3f-aad0-bd0d0320708c",
        "parentId" : "3536e024-c9c8-48a0-961e-5e7a648d1406",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "That's great, thank you!",
        "createdAt" : "2020-01-06T17:29:08Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase"
  },
  {
    "id" : "6f9bb114-a13e-43a1-9bf2-69d550bcd0dc",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "050c8490-f617-4c76-96cb-c7dc89838680",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "This string should probably be a parameter.",
        "createdAt" : "2019-12-23T10:25:39Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "0e16285e-1199-4d37-b41d-93dc974363c1",
        "parentId" : "050c8490-f617-4c76-96cb-c7dc89838680",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Done.",
        "createdAt" : "2020-01-06T17:34:55Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase\n+    extends AsyncWordSpec\n+    with BeforeAndAfterEach\n+    with AkkaBeforeAndAfterAll {\n+\n+  var ledgerId: LedgerString = _\n+  var ps: ReadService with WriteService = _\n+  var rt: Timestamp = _\n+\n+  def participantStateFactory(\n+      participantId: ParticipantId,\n+      ledgerId: LedgerString): ReadService with WriteService = ???\n+\n+  def currentRecordTime(): Timestamp = ???\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    ledgerId = Ref.LedgerString.assertFromString(s\"ledger-${UUID.randomUUID()}\")\n+    ps = participantStateFactory(participantId, ledgerId)\n+    rt = currentRecordTime()\n+  }\n+\n+  private val alice = Ref.Party.assertFromString(\"alice\")\n+  private def randomLedgerString(): Ref.LedgerString =\n+    Ref.LedgerString.assertFromString(UUID.randomUUID().toString)\n+\n+  // TODO(BH): Many of these tests for transformation from DamlLogEntry to Update better belong as\n+  // a KeyValueConsumptionSpec as the heart of the logic is there\n+\n+  \"In-memory implementation\" should {"
  },
  {
    "id" : "5b33b9a0-348a-4247-8915-886c4ec25485",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "4e7e04af-d0fc-4097-a04d-f95b9f750100",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "If `ps extends AutoCloseable`, we should close it in `afterEach`.",
        "createdAt" : "2019-12-23T11:01:51Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "2aa52b93-6a58-4f5b-9e32-0944262452a2",
        "parentId" : "4e7e04af-d0fc-4097-a04d-f95b9f750100",
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "Alternatively, we could expect a `Resource[T]` where `T <: ReadService with WriteService`.",
        "createdAt" : "2019-12-23T11:27:24Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "dc8ebfb0-ca26-4cdb-810c-70eb2eee8ce4",
        "parentId" : "4e7e04af-d0fc-4097-a04d-f95b9f750100",
        "author" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "body" : "Now the participant state integration test fixture closes these resources.",
        "createdAt" : "2020-01-06T17:27:18Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "miklos-da",
          "name" : "Miklos",
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/57664299?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase\n+    extends AsyncWordSpec\n+    with BeforeAndAfterEach\n+    with AkkaBeforeAndAfterAll {\n+\n+  var ledgerId: LedgerString = _\n+  var ps: ReadService with WriteService = _\n+  var rt: Timestamp = _\n+\n+  def participantStateFactory(\n+      participantId: ParticipantId,\n+      ledgerId: LedgerString): ReadService with WriteService = ???\n+\n+  def currentRecordTime(): Timestamp = ???\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    ledgerId = Ref.LedgerString.assertFromString(s\"ledger-${UUID.randomUUID()}\")\n+    ps = participantStateFactory(participantId, ledgerId)"
  },
  {
    "id" : "2cbc0fc8-d109-4361-970c-dfdd3ad83e34",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "9c9f89c9-2ef7-4d36-a161-3fc2d30219a4",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "Courtesy of IntelliJ:\r\n\r\n```suggestion\r\n            assert(update.submissionId.contains(submissionIds._2))\r\n```",
        "createdAt" : "2019-12-23T11:02:43Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase\n+    extends AsyncWordSpec\n+    with BeforeAndAfterEach\n+    with AkkaBeforeAndAfterAll {\n+\n+  var ledgerId: LedgerString = _\n+  var ps: ReadService with WriteService = _\n+  var rt: Timestamp = _\n+\n+  def participantStateFactory(\n+      participantId: ParticipantId,\n+      ledgerId: LedgerString): ReadService with WriteService = ???\n+\n+  def currentRecordTime(): Timestamp = ???\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    ledgerId = Ref.LedgerString.assertFromString(s\"ledger-${UUID.randomUUID()}\")\n+    ps = participantStateFactory(participantId, ledgerId)\n+    rt = currentRecordTime()\n+  }\n+\n+  private val alice = Ref.Party.assertFromString(\"alice\")\n+  private def randomLedgerString(): Ref.LedgerString =\n+    Ref.LedgerString.assertFromString(UUID.randomUUID().toString)\n+\n+  // TODO(BH): Many of these tests for transformation from DamlLogEntry to Update better belong as\n+  // a KeyValueConsumptionSpec as the heart of the logic is there\n+\n+  \"In-memory implementation\" should {\n+\n+    \"return initial conditions\" in {\n+      for {\n+        conditions <- ps\n+          .getLedgerInitialConditions()\n+          .runWith(Sink.head)\n+      } yield {\n+        assert(conditions.ledgerId == ledgerId)\n+      }\n+    }\n+\n+    \"provide update after uploadPackages\" in {\n+      val submissionId = randomLedgerString()\n+      for {\n+        _ <- ps.uploadPackages(submissionId, List(archives.head), sourceDescription).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        matchPackageUpload(\n+          updateTuple,\n+          submissionId,\n+          Offset(Array(0L, 0L)),\n+          List(archives.head),\n+          rt)\n+      }\n+    }\n+\n+    \"provide two updates after uploadPackages with two archives\" in {\n+      val archive1 :: archive2 :: _ = archives\n+      val submissionId = randomLedgerString()\n+      for {\n+        _ <- ps.uploadPackages(submissionId, archives, sourceDescription).toScala\n+        update1 <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        matchPackageUpload(update1, submissionId, Offset(Array(0L, 0L)), archives, rt)\n+      }\n+    }\n+\n+    \"remove duplicate package from update after uploadPackages\" in {\n+      val archive1 :: archive2 :: _ = archives\n+      val (subId1, subId2, subId3) =\n+        (randomLedgerString(), randomLedgerString(), randomLedgerString())\n+\n+      for {\n+        _ <- ps.uploadPackages(subId1, List(archive1), sourceDescription).toScala\n+        _ <- ps.uploadPackages(subId2, List(archive1), sourceDescription).toScala\n+        _ <- ps.uploadPackages(subId3, List(archive2), sourceDescription).toScala\n+        Seq(update1, update2, update3) <- ps\n+          .stateUpdates(beginAfter = None)\n+          .take(3)\n+          .runWith(Sink.seq)\n+      } yield {\n+        // first upload arrives as head update:\n+        matchPackageUpload(update1, subId1, Offset(Array(0L, 0L)), List(archive1), rt)\n+        matchPackageUpload(update2, subId2, Offset(Array(1L, 0L)), List(), rt)\n+        matchPackageUpload(update3, subId3, Offset(Array(2L, 0L)), List(archive2), rt)\n+      }\n+    }\n+\n+    \"reject uploadPackages when archive is empty\" in {\n+\n+      val badArchive = DamlLf.Archive.newBuilder\n+        .setHash(\"asdf\")\n+        .build\n+\n+      val submissionId = randomLedgerString()\n+\n+      for {\n+        _ <- ps.uploadPackages(submissionId, List(badArchive), sourceDescription).toScala\n+        updateTuple <- ps\n+          .stateUpdates(beginAfter = None)\n+          .idleTimeout(DefaultIdleTimeout)\n+          .runWith(Sink.head)\n+      } yield {\n+        updateTuple match {\n+          case (offset: Offset, update: PublicPackageUploadRejected) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.submissionId == submissionId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(s\"unexpected update message after package upload: $updateTuple\")\n+        }\n+      }\n+    }\n+\n+    \"reject duplicate submission in uploadPackage\" in {\n+      val submissionIds = (randomLedgerString(), randomLedgerString())\n+      val archive1 :: archive2 :: _ = archives\n+\n+      for {\n+        result1 <- ps.uploadPackages(submissionIds._1, List(archive1), sourceDescription).toScala\n+        result2 <- ps.uploadPackages(submissionIds._1, List(archive1), sourceDescription).toScala\n+        result3 <- ps.uploadPackages(submissionIds._2, List(archive2), sourceDescription).toScala\n+        // second submission is a duplicate, it fails silently\n+        Seq(_, update2) <- ps\n+          .stateUpdates(beginAfter = None)\n+          .take(2)\n+          .runWith(Sink.seq)\n+      } yield {\n+        List(result1, result2, result3).map(\n+          result =>\n+            assert(result == SubmissionResult.Acknowledged, \"unexpected response to package upload\")\n+        )\n+        update2 match {\n+          case (offset: Offset, update: PublicPackageUpload) =>\n+            assert(offset == Offset(Array(2L, 0L)))\n+            assert(Some(submissionIds._2) == update.submissionId)"
  },
  {
    "id" : "669450e7-f060-4c2c-992f-d0634581ff0b",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "2364d8ca-1797-4e7b-bd51-58ca9e8e6054",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "Courtesy of IntelliJ:\r\n\r\n```suggestion\r\n            assert(update.submissionId.contains(submissionIds._2))\r\n```",
        "createdAt" : "2019-12-23T11:02:57Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase\n+    extends AsyncWordSpec\n+    with BeforeAndAfterEach\n+    with AkkaBeforeAndAfterAll {\n+\n+  var ledgerId: LedgerString = _\n+  var ps: ReadService with WriteService = _\n+  var rt: Timestamp = _\n+\n+  def participantStateFactory(\n+      participantId: ParticipantId,\n+      ledgerId: LedgerString): ReadService with WriteService = ???\n+\n+  def currentRecordTime(): Timestamp = ???\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    ledgerId = Ref.LedgerString.assertFromString(s\"ledger-${UUID.randomUUID()}\")\n+    ps = participantStateFactory(participantId, ledgerId)\n+    rt = currentRecordTime()\n+  }\n+\n+  private val alice = Ref.Party.assertFromString(\"alice\")\n+  private def randomLedgerString(): Ref.LedgerString =\n+    Ref.LedgerString.assertFromString(UUID.randomUUID().toString)\n+\n+  // TODO(BH): Many of these tests for transformation from DamlLogEntry to Update better belong as\n+  // a KeyValueConsumptionSpec as the heart of the logic is there\n+\n+  \"In-memory implementation\" should {\n+\n+    \"return initial conditions\" in {\n+      for {\n+        conditions <- ps\n+          .getLedgerInitialConditions()\n+          .runWith(Sink.head)\n+      } yield {\n+        assert(conditions.ledgerId == ledgerId)\n+      }\n+    }\n+\n+    \"provide update after uploadPackages\" in {\n+      val submissionId = randomLedgerString()\n+      for {\n+        _ <- ps.uploadPackages(submissionId, List(archives.head), sourceDescription).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        matchPackageUpload(\n+          updateTuple,\n+          submissionId,\n+          Offset(Array(0L, 0L)),\n+          List(archives.head),\n+          rt)\n+      }\n+    }\n+\n+    \"provide two updates after uploadPackages with two archives\" in {\n+      val archive1 :: archive2 :: _ = archives\n+      val submissionId = randomLedgerString()\n+      for {\n+        _ <- ps.uploadPackages(submissionId, archives, sourceDescription).toScala\n+        update1 <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        matchPackageUpload(update1, submissionId, Offset(Array(0L, 0L)), archives, rt)\n+      }\n+    }\n+\n+    \"remove duplicate package from update after uploadPackages\" in {\n+      val archive1 :: archive2 :: _ = archives\n+      val (subId1, subId2, subId3) =\n+        (randomLedgerString(), randomLedgerString(), randomLedgerString())\n+\n+      for {\n+        _ <- ps.uploadPackages(subId1, List(archive1), sourceDescription).toScala\n+        _ <- ps.uploadPackages(subId2, List(archive1), sourceDescription).toScala\n+        _ <- ps.uploadPackages(subId3, List(archive2), sourceDescription).toScala\n+        Seq(update1, update2, update3) <- ps\n+          .stateUpdates(beginAfter = None)\n+          .take(3)\n+          .runWith(Sink.seq)\n+      } yield {\n+        // first upload arrives as head update:\n+        matchPackageUpload(update1, subId1, Offset(Array(0L, 0L)), List(archive1), rt)\n+        matchPackageUpload(update2, subId2, Offset(Array(1L, 0L)), List(), rt)\n+        matchPackageUpload(update3, subId3, Offset(Array(2L, 0L)), List(archive2), rt)\n+      }\n+    }\n+\n+    \"reject uploadPackages when archive is empty\" in {\n+\n+      val badArchive = DamlLf.Archive.newBuilder\n+        .setHash(\"asdf\")\n+        .build\n+\n+      val submissionId = randomLedgerString()\n+\n+      for {\n+        _ <- ps.uploadPackages(submissionId, List(badArchive), sourceDescription).toScala\n+        updateTuple <- ps\n+          .stateUpdates(beginAfter = None)\n+          .idleTimeout(DefaultIdleTimeout)\n+          .runWith(Sink.head)\n+      } yield {\n+        updateTuple match {\n+          case (offset: Offset, update: PublicPackageUploadRejected) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.submissionId == submissionId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(s\"unexpected update message after package upload: $updateTuple\")\n+        }\n+      }\n+    }\n+\n+    \"reject duplicate submission in uploadPackage\" in {\n+      val submissionIds = (randomLedgerString(), randomLedgerString())\n+      val archive1 :: archive2 :: _ = archives\n+\n+      for {\n+        result1 <- ps.uploadPackages(submissionIds._1, List(archive1), sourceDescription).toScala\n+        result2 <- ps.uploadPackages(submissionIds._1, List(archive1), sourceDescription).toScala\n+        result3 <- ps.uploadPackages(submissionIds._2, List(archive2), sourceDescription).toScala\n+        // second submission is a duplicate, it fails silently\n+        Seq(_, update2) <- ps\n+          .stateUpdates(beginAfter = None)\n+          .take(2)\n+          .runWith(Sink.seq)\n+      } yield {\n+        List(result1, result2, result3).map(\n+          result =>\n+            assert(result == SubmissionResult.Acknowledged, \"unexpected response to package upload\")\n+        )\n+        update2 match {\n+          case (offset: Offset, update: PublicPackageUpload) =>\n+            assert(offset == Offset(Array(2L, 0L)))\n+            assert(Some(submissionIds._2) == update.submissionId)\n+          case _ =>\n+            fail(\n+              \"unexpected update message after a package upload.  Error : \" + result2.description)\n+        }\n+      }\n+    }\n+\n+    \"provide update after allocateParty\" in {\n+      val hint = Some(Ref.Party.assertFromString(\"Alice\"))\n+      val displayName = Some(\"Alice Cooper\")\n+\n+      for {\n+        allocResult <- ps.allocateParty(hint, displayName, randomLedgerString()).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        assert(\n+          allocResult == SubmissionResult.Acknowledged,\n+          s\"unexpected response to party allocation: $allocResult\")\n+        updateTuple match {\n+          case (offset: Offset, update: PartyAddedToParticipant) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.party == hint.get)\n+            assert(update.displayName == displayName.get)\n+            assert(update.participantId == participantId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(s\"unexpected update message after a party allocation: $updateTuple\")\n+        }\n+      }\n+    }\n+\n+    \"accept allocateParty when hint is empty\" in {\n+      val displayName = Some(\"Alice Cooper\")\n+\n+      for {\n+        result <- ps.allocateParty(hint = None, displayName, randomLedgerString()).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        assert(result == SubmissionResult.Acknowledged, \"unexpected response to party allocation\")\n+        updateTuple match {\n+          case (offset: Offset, update: PartyAddedToParticipant) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.party.nonEmpty)\n+            assert(update.displayName == displayName.get)\n+            assert(update.participantId == participantId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(\n+              \"unexpected update message after a party allocation.  Error : \" + result.description)\n+        }\n+\n+      }\n+    }\n+\n+    \"reject duplicate submission in allocateParty\" in {\n+      val hints =\n+        (Some(Ref.Party.assertFromString(\"Alice\")), Some(Ref.Party.assertFromString(\"Bob\")))\n+      val displayNames = (Some(\"Alice Cooper\"), Some(\"Bob de Boumaa\"))\n+\n+      val submissionIds = (randomLedgerString(), randomLedgerString())\n+\n+      for {\n+        result1 <- ps.allocateParty(hints._1, displayNames._1, submissionIds._1).toScala\n+        result2 <- ps.allocateParty(hints._2, displayNames._2, submissionIds._1).toScala\n+        result3 <- ps.allocateParty(hints._2, displayNames._2, submissionIds._2).toScala\n+        // second submission is a duplicate, it fails silently\n+        Seq(_, update2) <- ps.stateUpdates(beginAfter = None).take(2).runWith(Sink.seq)\n+      } yield {\n+        List(result1, result2, result3).map(\n+          result =>\n+            assert(\n+              result == SubmissionResult.Acknowledged,\n+              \"unexpected response to party allocation\")\n+        )\n+        update2 match {\n+          case (offset: Offset, update: PartyAddedToParticipant) =>\n+            assert(offset == Offset(Array(2L, 0L)))\n+            assert(Some(submissionIds._2) == update.submissionId)"
  },
  {
    "id" : "7e9d28c4-1295-4cd9-a840-949573176364",
    "prId" : 3923,
    "comments" : [
      {
        "id" : "d250a4b0-8581-4323-8c26-0f7c30092c83",
        "parentId" : null,
        "author" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "body" : "Perhaps assert the size of `updates` then deconstruct it:\r\n\r\n(This won't compile.)\r\n\r\n```suggestion\r\n        updates should have size 3\r\n        val Seq(update0, update1, update2) = offsets\r\n```",
        "createdAt" : "2019-12-23T11:04:14Z",
        "updatedAt" : "2020-01-10T10:31:04Z",
        "lastEditedBy" : {
          "login" : "SamirTalwar",
          "name" : "Samir Talwar",
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/47582?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "c820159bc8cad55858939f177705f0a8bab0fd13",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,564 @@\n+// Copyright (c) 2019 The DAML Authors. All rights reserved.\n+// SPDX-License-Identifier: Apache-2.0\n+\n+package com.daml.ledger.participant.state.kvutils\n+\n+import java.io.File\n+import java.time.Duration\n+import java.util.UUID\n+import java.util.concurrent.TimeUnit\n+\n+import akka.stream.scaladsl.Sink\n+import com.daml.ledger.participant.state.kvutils.ParticipantStateIntegrationSpecBase._\n+import com.daml.ledger.participant.state.v1.Update._\n+import com.daml.ledger.participant.state.v1._\n+import com.digitalasset.daml.bazeltools.BazelRunfiles._\n+import com.digitalasset.daml.lf.archive.DarReader\n+import com.digitalasset.daml.lf.data.Ref.LedgerString\n+import com.digitalasset.daml.lf.data.Time.Timestamp\n+import com.digitalasset.daml.lf.data.{ImmArray, InsertOrdSet, Ref}\n+import com.digitalasset.daml.lf.transaction.GenTransaction\n+import com.digitalasset.daml_lf_dev.DamlLf\n+import com.digitalasset.ledger.api.testing.utils.AkkaBeforeAndAfterAll\n+import org.scalatest.Assertions._\n+import org.scalatest.{Assertion, AsyncWordSpec, BeforeAndAfterEach}\n+\n+import scala.collection.immutable.SortedMap\n+import scala.compat.java8.FutureConverters._\n+import scala.concurrent.duration.FiniteDuration\n+import scala.util.Try\n+\n+abstract class ParticipantStateIntegrationSpecBase\n+    extends AsyncWordSpec\n+    with BeforeAndAfterEach\n+    with AkkaBeforeAndAfterAll {\n+\n+  var ledgerId: LedgerString = _\n+  var ps: ReadService with WriteService = _\n+  var rt: Timestamp = _\n+\n+  def participantStateFactory(\n+      participantId: ParticipantId,\n+      ledgerId: LedgerString): ReadService with WriteService = ???\n+\n+  def currentRecordTime(): Timestamp = ???\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    ledgerId = Ref.LedgerString.assertFromString(s\"ledger-${UUID.randomUUID()}\")\n+    ps = participantStateFactory(participantId, ledgerId)\n+    rt = currentRecordTime()\n+  }\n+\n+  private val alice = Ref.Party.assertFromString(\"alice\")\n+  private def randomLedgerString(): Ref.LedgerString =\n+    Ref.LedgerString.assertFromString(UUID.randomUUID().toString)\n+\n+  // TODO(BH): Many of these tests for transformation from DamlLogEntry to Update better belong as\n+  // a KeyValueConsumptionSpec as the heart of the logic is there\n+\n+  \"In-memory implementation\" should {\n+\n+    \"return initial conditions\" in {\n+      for {\n+        conditions <- ps\n+          .getLedgerInitialConditions()\n+          .runWith(Sink.head)\n+      } yield {\n+        assert(conditions.ledgerId == ledgerId)\n+      }\n+    }\n+\n+    \"provide update after uploadPackages\" in {\n+      val submissionId = randomLedgerString()\n+      for {\n+        _ <- ps.uploadPackages(submissionId, List(archives.head), sourceDescription).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        matchPackageUpload(\n+          updateTuple,\n+          submissionId,\n+          Offset(Array(0L, 0L)),\n+          List(archives.head),\n+          rt)\n+      }\n+    }\n+\n+    \"provide two updates after uploadPackages with two archives\" in {\n+      val archive1 :: archive2 :: _ = archives\n+      val submissionId = randomLedgerString()\n+      for {\n+        _ <- ps.uploadPackages(submissionId, archives, sourceDescription).toScala\n+        update1 <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        matchPackageUpload(update1, submissionId, Offset(Array(0L, 0L)), archives, rt)\n+      }\n+    }\n+\n+    \"remove duplicate package from update after uploadPackages\" in {\n+      val archive1 :: archive2 :: _ = archives\n+      val (subId1, subId2, subId3) =\n+        (randomLedgerString(), randomLedgerString(), randomLedgerString())\n+\n+      for {\n+        _ <- ps.uploadPackages(subId1, List(archive1), sourceDescription).toScala\n+        _ <- ps.uploadPackages(subId2, List(archive1), sourceDescription).toScala\n+        _ <- ps.uploadPackages(subId3, List(archive2), sourceDescription).toScala\n+        Seq(update1, update2, update3) <- ps\n+          .stateUpdates(beginAfter = None)\n+          .take(3)\n+          .runWith(Sink.seq)\n+      } yield {\n+        // first upload arrives as head update:\n+        matchPackageUpload(update1, subId1, Offset(Array(0L, 0L)), List(archive1), rt)\n+        matchPackageUpload(update2, subId2, Offset(Array(1L, 0L)), List(), rt)\n+        matchPackageUpload(update3, subId3, Offset(Array(2L, 0L)), List(archive2), rt)\n+      }\n+    }\n+\n+    \"reject uploadPackages when archive is empty\" in {\n+\n+      val badArchive = DamlLf.Archive.newBuilder\n+        .setHash(\"asdf\")\n+        .build\n+\n+      val submissionId = randomLedgerString()\n+\n+      for {\n+        _ <- ps.uploadPackages(submissionId, List(badArchive), sourceDescription).toScala\n+        updateTuple <- ps\n+          .stateUpdates(beginAfter = None)\n+          .idleTimeout(DefaultIdleTimeout)\n+          .runWith(Sink.head)\n+      } yield {\n+        updateTuple match {\n+          case (offset: Offset, update: PublicPackageUploadRejected) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.submissionId == submissionId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(s\"unexpected update message after package upload: $updateTuple\")\n+        }\n+      }\n+    }\n+\n+    \"reject duplicate submission in uploadPackage\" in {\n+      val submissionIds = (randomLedgerString(), randomLedgerString())\n+      val archive1 :: archive2 :: _ = archives\n+\n+      for {\n+        result1 <- ps.uploadPackages(submissionIds._1, List(archive1), sourceDescription).toScala\n+        result2 <- ps.uploadPackages(submissionIds._1, List(archive1), sourceDescription).toScala\n+        result3 <- ps.uploadPackages(submissionIds._2, List(archive2), sourceDescription).toScala\n+        // second submission is a duplicate, it fails silently\n+        Seq(_, update2) <- ps\n+          .stateUpdates(beginAfter = None)\n+          .take(2)\n+          .runWith(Sink.seq)\n+      } yield {\n+        List(result1, result2, result3).map(\n+          result =>\n+            assert(result == SubmissionResult.Acknowledged, \"unexpected response to package upload\")\n+        )\n+        update2 match {\n+          case (offset: Offset, update: PublicPackageUpload) =>\n+            assert(offset == Offset(Array(2L, 0L)))\n+            assert(Some(submissionIds._2) == update.submissionId)\n+          case _ =>\n+            fail(\n+              \"unexpected update message after a package upload.  Error : \" + result2.description)\n+        }\n+      }\n+    }\n+\n+    \"provide update after allocateParty\" in {\n+      val hint = Some(Ref.Party.assertFromString(\"Alice\"))\n+      val displayName = Some(\"Alice Cooper\")\n+\n+      for {\n+        allocResult <- ps.allocateParty(hint, displayName, randomLedgerString()).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        assert(\n+          allocResult == SubmissionResult.Acknowledged,\n+          s\"unexpected response to party allocation: $allocResult\")\n+        updateTuple match {\n+          case (offset: Offset, update: PartyAddedToParticipant) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.party == hint.get)\n+            assert(update.displayName == displayName.get)\n+            assert(update.participantId == participantId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(s\"unexpected update message after a party allocation: $updateTuple\")\n+        }\n+      }\n+    }\n+\n+    \"accept allocateParty when hint is empty\" in {\n+      val displayName = Some(\"Alice Cooper\")\n+\n+      for {\n+        result <- ps.allocateParty(hint = None, displayName, randomLedgerString()).toScala\n+        updateTuple <- ps.stateUpdates(beginAfter = None).runWith(Sink.head)\n+      } yield {\n+        assert(result == SubmissionResult.Acknowledged, \"unexpected response to party allocation\")\n+        updateTuple match {\n+          case (offset: Offset, update: PartyAddedToParticipant) =>\n+            assert(offset == Offset(Array(0L, 0L)))\n+            assert(update.party.nonEmpty)\n+            assert(update.displayName == displayName.get)\n+            assert(update.participantId == participantId)\n+            assert(update.recordTime >= rt)\n+          case _ =>\n+            fail(\n+              \"unexpected update message after a party allocation.  Error : \" + result.description)\n+        }\n+\n+      }\n+    }\n+\n+    \"reject duplicate submission in allocateParty\" in {\n+      val hints =\n+        (Some(Ref.Party.assertFromString(\"Alice\")), Some(Ref.Party.assertFromString(\"Bob\")))\n+      val displayNames = (Some(\"Alice Cooper\"), Some(\"Bob de Boumaa\"))\n+\n+      val submissionIds = (randomLedgerString(), randomLedgerString())\n+\n+      for {\n+        result1 <- ps.allocateParty(hints._1, displayNames._1, submissionIds._1).toScala\n+        result2 <- ps.allocateParty(hints._2, displayNames._2, submissionIds._1).toScala\n+        result3 <- ps.allocateParty(hints._2, displayNames._2, submissionIds._2).toScala\n+        // second submission is a duplicate, it fails silently\n+        Seq(_, update2) <- ps.stateUpdates(beginAfter = None).take(2).runWith(Sink.seq)\n+      } yield {\n+        List(result1, result2, result3).map(\n+          result =>\n+            assert(\n+              result == SubmissionResult.Acknowledged,\n+              \"unexpected response to party allocation\")\n+        )\n+        update2 match {\n+          case (offset: Offset, update: PartyAddedToParticipant) =>\n+            assert(offset == Offset(Array(2L, 0L)))\n+            assert(Some(submissionIds._2) == update.submissionId)\n+          case _ =>\n+            fail(\n+              \"unexpected update message after a party allocation.  Error : \" + result2.description)\n+        }\n+      }\n+    }\n+\n+    \"reject duplicate party in allocateParty\" in {\n+      val hint = Some(Ref.Party.assertFromString(\"Alice\"))\n+      val displayName = Some(\"Alice Cooper\")\n+\n+      for {\n+        result1 <- ps.allocateParty(hint, displayName, randomLedgerString()).toScala\n+        result2 <- ps.allocateParty(hint, displayName, randomLedgerString()).toScala\n+        Seq(_, update2) <- ps.stateUpdates(beginAfter = None).take(2).runWith(Sink.seq)\n+      } yield {\n+        assert(result1 == SubmissionResult.Acknowledged, \"unexpected response to party allocation\")\n+        assert(result2 == SubmissionResult.Acknowledged, \"unexpected response to party allocation\")\n+        update2 match {\n+          case (offset: Offset, update: PartyAllocationRejected) =>\n+            assert(offset == Offset(Array(1L, 0L)))\n+            assert(update.rejectionReason equalsIgnoreCase \"Party already exists\")\n+          case _ =>\n+            fail(\n+              \"unexpected update message after a party allocation.  Error : \" + result2.description)\n+        }\n+      }\n+    }\n+\n+    \"provide update after transaction submission\" in {\n+      val rt = currentRecordTime()\n+      for {\n+        _ <- ps.allocateParty(hint = Some(alice), None, randomLedgerString()).toScala\n+        _ <- ps\n+          .submitTransaction(submitterInfo(rt, alice), transactionMeta(rt), emptyTransaction)\n+          .toScala\n+        update <- ps.stateUpdates(beginAfter = None).drop(1).runWith(Sink.head)\n+      } yield {\n+        assert(update._1 == Offset(Array(1L, 0L)))\n+      }\n+    }\n+\n+    \"reject duplicate commands\" in {\n+      val rt = currentRecordTime()\n+      val commandIds = (\"X1\", \"X2\")\n+\n+      for {\n+        _ <- ps.allocateParty(hint = Some(alice), None, randomLedgerString()).toScala\n+        _ <- ps\n+          .submitTransaction(\n+            submitterInfo(rt, alice, commandIds._1),\n+            transactionMeta(rt),\n+            emptyTransaction)\n+          .toScala\n+        _ <- ps\n+          .submitTransaction(\n+            submitterInfo(rt, alice, commandIds._1),\n+            transactionMeta(rt),\n+            emptyTransaction)\n+          .toScala\n+        _ <- ps\n+          .submitTransaction(\n+            submitterInfo(rt, alice, commandIds._2),\n+            transactionMeta(rt),\n+            emptyTransaction)\n+          .toScala\n+        updates <- ps.stateUpdates(beginAfter = None).take(3).runWith(Sink.seq)\n+      } yield {\n+        val (offset0, update0) = updates(0)"
  }
]